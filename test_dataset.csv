context_docs,user_query,instructions,prompt,output
"[""Skip to main content\n\n[![Aimon Logo](/img/logo.png)![Aimon Logo](/img/logo.png)](/)\n\n[GitHub](https://github.com/aimonlabs/aimon-python-sdk)\n\n  * [Welcome to AIMon](/)\n  * [Introduction](/category/introduction)\n\n  * [Getting Started](/category/getting-started)\n\n  * [Concepts](/category/concepts)\n\n    * [Detectors](/category/detectors)\n\n      * [Hallucination](/concepts/detectors/hallucination)\n      * [Instruction Adherence](/concepts/detectors/instruction_adherence)\n      * [Conciseness](/concepts/detectors/conciseness)\n      * [Completeness](/concepts/detectors/completeness)\n      * [Toxicity](/concepts/detectors/toxicity)\n    * [Evaluation and Continuous Monitoring](/concepts/evaluation_and_monitoring)\n  * [Example Applications](/category/example-applications)\n\n  * [](/)\n  * [Concepts](/category/concepts)\n  * [Detectors](/category/detectors)\n  * Conciseness\n\nOn this page\n\n# Conciseness\n\nGiven a context, generated text and optionally a user query or a reference\ntext, this API is able to detect if the generated text was concise or verbose\nin terms of addressing the user query. The context should include the context\ndocuments along with the user query as passed in to the LLM. The output\ncontains a \""score\"" that is between 0.0 and 1.0 which indicates the degree of\nconciseness."", ""For example,\n\u00e2\u0080\u009cEiffel Tower is the tallest building in France'' or \u00e2\u0080\u009cThe first man on the\nmoon was Yuri Gagarin\u00e2\u0080\u009d. Extrinsic Hallucinations are the ones where models\ncompletely fabricate new false information. This can\u00e2\u0080\u0099t be inferred from or\ntraced back to original sources. For example, \u00e2\u0080\u009cCristiano Ronaldo is a\nCricket player\u00e2\u0080\u009d. The \""is_hallucinated\"" field indicates whether the\n\""generated_text\"" (passed in the input) is hallucinated. A top level \""score\""\nfield indicates if the entire paragraph contained any hallucinations. The\nscore is a probability measure of how hallucinated the text is compared to the\ncontext. A score >= 0.5 can be classified as a hallucination. We also provide\nsentence level scores to help with explainability.\n\n### Example Request[\u00e2\u0080\u008b](/concepts/detectors/hallucination#example-request\n\""Direct link to Example Request\"")\n\n    \n    \n    [  \n      {  \n        \""context\"": \""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News.\"",  \n        \""generated_text\"": \""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade. In addition, he has also been involved in writing essays and sharing his thoughts on technology, startups, and programming."", ""Skip to main content\n\n[![Aimon Logo](/img/logo.png)![Aimon Logo](/img/logo.png)](/)\n\n[GitHub](https://github.com/aimonlabs/aimon-python-sdk)\n\n  * [Welcome to AIMon](/)\n  * [Introduction](/category/introduction)\n\n  * [Getting Started](/category/getting-started)\n\n  * [Concepts](/category/concepts)\n\n    * [Detectors](/category/detectors)\n\n      * [Hallucination](/concepts/detectors/hallucination)\n      * [Instruction Adherence](/concepts/detectors/instruction_adherence)\n      * [Conciseness](/concepts/detectors/conciseness)\n      * [Completeness](/concepts/detectors/completeness)\n      * [Toxicity](/concepts/detectors/toxicity)\n    * [Evaluation and Continuous Monitoring](/concepts/evaluation_and_monitoring)\n  * [Example Applications](/category/example-applications)\n\n  * [](/)\n  * [Concepts](/category/concepts)\n  * [Detectors](/category/detectors)\n  * Hallucination\n\nOn this page\n\n# Hallucination\n\nGiven a context, a generated text and optionally a user query, we are able to\ndetect 2 different types of model hallucinations: intrinsic and extrinsic.\nIntrinsic Hallucinations are hallucinations where the models manipulate\noriginal information and slightly misrepresent true facts. For example,\n\u00e2\u0080\u009cEiffel Tower is the tallest building in France'' or \u00e2\u0080\u009cThe first man on the\nmoon was Yuri Gagarin\u00e2\u0080\u009d. Extrinsic Hallucinations are the ones where models\ncompletely fabricate new false information."", ""Skip to main content\n\n[![Aimon Logo](/img/logo.png)![Aimon Logo](/img/logo.png)](/)\n\n[GitHub](https://github.com/aimonlabs/aimon-python-sdk)\n\n  * [Welcome to AIMon](/)\n  * [Introduction](/category/introduction)\n\n  * [Getting Started](/category/getting-started)\n\n  * [Concepts](/category/concepts)\n\n    * [Detectors](/category/detectors)\n\n      * [Hallucination](/concepts/detectors/hallucination)\n      * [Instruction Adherence](/concepts/detectors/instruction_adherence)\n      * [Conciseness](/concepts/detectors/conciseness)\n      * [Completeness](/concepts/detectors/completeness)\n      * [Toxicity](/concepts/detectors/toxicity)\n    * [Evaluation and Continuous Monitoring](/concepts/evaluation_and_monitoring)\n  * [Example Applications](/category/example-applications)\n\n  * [](/)\n  * [Concepts](/category/concepts)\n  * Detectors\n\n# Detectors\n\n## [\u00f0\u009f\u0093\u0084\u00ef\u00b8\u008f HallucinationGiven a context, a generated text and optionally a\nuser query, we are able to detect 2 different types\nof](/concepts/detectors/hallucination)## [\u00f0\u009f\u0093\u0084\u00ef\u00b8\u008f Instruction AdherenceGiven a\nset of \u00e2\u0080\u009cinstructions\u00e2\u0080\u009d, the generated text, the input context and the user\nquery, this API is able](/concepts/detectors/instruction_adherence)## [\u00f0\u009f\u0093\u0084\u00ef\u00b8\u008f\nConcisenessGiven a context,"", ""The context should include the context\ndocuments along with the user query as passed in to the LLM. The output\ncontains a \""score\"" that is between 0.0 and 1.0 which indicates the degree of\nconciseness. If the generated answer is very verbose and contains a lot of un-\nnecessary information that is not relevant to the user query, a score between\n0.0 to 0.2 is possible. If the generated answer is mostly relevant to the user\nquery but has some amount of text that is not necessary for the user query a\nscore between 0.2 and 0.7 is possible. If the generated answer is very concise\nand properly addresses all important points for the user query, a score\nbetween 0.7 and 1.0 is possible. The API also includes a \""reasoning\"" field\nthat is a text based explanation of the score. It also does a best effort\nmethod of pointing out the unnecessary information that was included in the\noutput.\n\n### Example Request[\u00e2\u0080\u008b](/concepts/detectors/conciseness#example-request\n\""Direct link to Example Request\"")\n\n    \n    \n    [  \n      {  \n        \""context\"": \""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News.\"",  \n        \""generated_text\"": \""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade.""]",What are the key advantages of using AIMon over traditional analytics platforms?,1. Focus on distinct features and benefits. 2. Limit the response to under 200 words.,"Explain the differences between AIMon and traditional analytics platforms, focusing on unique features and benefits.","AIMon offers several key advantages over traditional analytics platforms:

1. **Specialized Detectors**: AIMon includes unique detectors for various aspects of generated content, such as hallucination detection, instruction adherence, conciseness, completeness, and toxicity. This allows for a more nuanced analysis of text, ensuring that the generated content meets specific quality standards.

2. **Hallucination Detection**: AIMon can identify both intrinsic and extrinsic hallucinations in generated text. This feature helps users understand the accuracy of the information presented, which is crucial for maintaining trust in AI-generated content.

3. **Conciseness Scoring**: The platform provides a scoring system that evaluates the conciseness of generated text. This feature not only quantifies how well the text addresses user queries but also offers insights into unnecessary information, enhancing the clarity and relevance of the output.

4. **Continuous Monitoring**: AIMon emphasizes evaluation and continuous monitoring, allowing users to track the performance of their models over time. This ongoing assessment helps in fine-tuning and improving the quality of generated content.

5. **Explainability**: AIMon includes reasoning fields that explain the scores given to generated text. This transparency aids users in understanding the evaluation process and making informed decisions based on the analysis.

6. **User-Centric Focus**: By incorporating user queries and context into its evaluation processes, AIMon ensures that the generated content is tailored to meet specific user needs, enhancing the overall user experience.

These features collectively make AIMon a powerful tool for analyzing and improving AI-generated content, setting it apart from traditional analytics platforms that may lack such specialized capabilities."
"[""A dataset collection can be created as follows:\n\n  * Python\n  * TypeScript\n\n    \n    \n    dataset_collection = aimon_client.datasets.collection.create(  \n        name=\""my_first_dataset_collection\"",   \n        dataset_ids=[aimon_dataset1.sha, aimon_dataset2.sha],   \n        description=\""This is a collection of two datasets.\""  \n    )  \n    \n    \n    \n    const dataset1 = await createDataset(  \n        \""/path/to/file/filename_1.csv\"",  \n        \""filename1.csv\"",  \n        \""description\""  \n    );  \n      \n    const dataset2 = await createDataset(  \n        \""/path/to/file/filename_2.csv\"",  \n        \""filename2.csv\"",  \n        \""description\""  \n    );  \n      \n    let datasetCollection: Client.Datasets.CollectionCreateResponse | undefined;  \n      \n    // Ensures that dataset1.sha and dataset2.sha are defined  \n    if (dataset1.sha && dataset2.sha) {  \n        // Creates dataset collection  \n        datasetCollection = await aimon.datasets.collection.create({  \n        name: \""my_first_dataset_collection\"",  \n        dataset_ids: [dataset1.sha, dataset2.sha],  \n        description: \""This is a collection of two datasets."", ""For tasks like summarization, these documents could be directly specified by the user.\n\nA dataset can be created using the AIMon client as follows:\n\n  * Python\n  * TypeScript\n\n    \n    \n    from aimon import Client  \n    import json  \n      \n    aimon_client = Client(auth_header=\""Bearer <AIMON API KEY>\"")  \n    # Create a new datasets  \n    file_path = \""evaluation_dataset.csv\""  \n      \n    dataset = json.dumps({  \n        \""name\"": \""evaluation_dataset.csv\"",  \n        \""description\"": \""This is a golden dataset\""  \n    })  \n      \n    with open(file_path, 'rb') as file1:  \n        aimon_dataset = aimon_client.datasets.create(  \n            file=file1,  \n            json_data=dataset  \n        )  \n    \n    \n    \n    import Client from \""aimon\"";  \n      \n    const aimon_client = new Client({  \n      authHeader: `Bearer API_KEY`,  \n    });  \n      \n      \n    // Creates a new dataset from the local path csv file  \n    const createDataset = async (  \n      path: string,  \n      datasetName: string,  \n      description: string  \n    ): Promise<Client.Dataset> => {  \n      const file = await fileFromPath(path);  \n      const json_data = JSON.stringify({  \n        name: datasetName,  \n        description: description,  \n      });  \n      \n      const params = {  \n        file: file,  \n        json_data: json_data,  \n      };  \n      \n      const dataset: Client.Dataset = await aimon.datasets.create(params);  \n      return dataset;  \n    };  \n    \n\n##### Dataset Collection[\u00e2\u0080\u008b](/concepts/evaluation_and_monitoring#dataset-\ncollection \""Direct link to Dataset Collection\"")\n\nYou can group a collection of evaluation datasets into a `dataset collection`\nfor ease of use."", ""Skip to main content\n\n[![Aimon Logo](/img/logo.png)![Aimon Logo](/img/logo.png)](/)\n\n[GitHub](https://github.com/aimonlabs/aimon-python-sdk)\n\n  * [Welcome to AIMon](/)\n  * [Introduction](/category/introduction)\n\n  * [Getting Started](/category/getting-started)\n\n  * [Concepts](/category/concepts)\n\n    * [Detectors](/category/detectors)\n\n      * [Hallucination](/concepts/detectors/hallucination)\n      * [Instruction Adherence](/concepts/detectors/instruction_adherence)\n      * [Conciseness](/concepts/detectors/conciseness)\n      * [Completeness](/concepts/detectors/completeness)\n      * [Toxicity](/concepts/detectors/toxicity)\n    * [Evaluation and Continuous Monitoring](/concepts/evaluation_and_monitoring)\n  * [Example Applications](/category/example-applications)\n\n  * [](/)\n  * [Concepts](/category/concepts)\n  * [Detectors](/category/detectors)\n  * Conciseness\n\nOn this page\n\n# Conciseness\n\nGiven a context, generated text and optionally a user query or a reference\ntext, this API is able to detect if the generated text was concise or verbose\nin terms of addressing the user query. The context should include the context\ndocuments along with the user query as passed in to the LLM. The output\ncontains a \""score\"" that is between 0.0 and 1.0 which indicates the degree of\nconciseness."", ""For example,\n\u00e2\u0080\u009cEiffel Tower is the tallest building in France'' or \u00e2\u0080\u009cThe first man on the\nmoon was Yuri Gagarin\u00e2\u0080\u009d. Extrinsic Hallucinations are the ones where models\ncompletely fabricate new false information. This can\u00e2\u0080\u0099t be inferred from or\ntraced back to original sources. For example, \u00e2\u0080\u009cCristiano Ronaldo is a\nCricket player\u00e2\u0080\u009d. The \""is_hallucinated\"" field indicates whether the\n\""generated_text\"" (passed in the input) is hallucinated. A top level \""score\""\nfield indicates if the entire paragraph contained any hallucinations. The\nscore is a probability measure of how hallucinated the text is compared to the\ncontext. A score >= 0.5 can be classified as a hallucination. We also provide\nsentence level scores to help with explainability.\n\n### Example Request[\u00e2\u0080\u008b](/concepts/detectors/hallucination#example-request\n\""Direct link to Example Request\"")\n\n    \n    \n    [  \n      {  \n        \""context\"": \""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News.\"",  \n        \""generated_text\"": \""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade. In addition, he has also been involved in writing essays and sharing his thoughts on technology, startups, and programming."", ""Skip to main content\n\n[![Aimon Logo](/img/logo.png)![Aimon Logo](/img/logo.png)](/)\n\n[GitHub](https://github.com/aimonlabs/aimon-python-sdk)\n\n  * [Welcome to AIMon](/)\n  * [Introduction](/category/introduction)\n\n  * [Getting Started](/category/getting-started)\n\n  * [Concepts](/category/concepts)\n\n    * [Detectors](/category/detectors)\n\n      * [Hallucination](/concepts/detectors/hallucination)\n      * [Instruction Adherence](/concepts/detectors/instruction_adherence)\n      * [Conciseness](/concepts/detectors/conciseness)\n      * [Completeness](/concepts/detectors/completeness)\n      * [Toxicity](/concepts/detectors/toxicity)\n    * [Evaluation and Continuous Monitoring](/concepts/evaluation_and_monitoring)\n  * [Example Applications](/category/example-applications)\n\n  * [](/)\n  * [Concepts](/category/concepts)\n  * Detectors\n\n# Detectors\n\n## [\u00f0\u009f\u0093\u0084\u00ef\u00b8\u008f HallucinationGiven a context, a generated text and optionally a\nuser query, we are able to detect 2 different types\nof](/concepts/detectors/hallucination)## [\u00f0\u009f\u0093\u0084\u00ef\u00b8\u008f Instruction AdherenceGiven a\nset of \u00e2\u0080\u009cinstructions\u00e2\u0080\u009d, the generated text, the input context and the user\nquery, this API is able](/concepts/detectors/instruction_adherence)## [\u00f0\u009f\u0093\u0084\u00ef\u00b8\u008f\nConcisenessGiven a context,""]",BIMon is for business intelligence as AIMon is for artificial intelligence. Please explain the steps to install BIMon on a cloud server.,1. Provide a checklist format for configurations. 2. Include at least three common pitfalls to avoid.,Outline the necessary configurations and prerequisites for successfully installing BIMon on a cloud server.,"To successfully install BIMon on a cloud server, follow these steps:

1. **Choose a Cloud Provider**: Select a cloud service provider (e.g., AWS, Azure, Google Cloud) that meets your requirements for resources and scalability.

2. **Provision a Virtual Machine**: Create a virtual machine (VM) instance with the necessary specifications (CPU, RAM, storage) based on the expected load and usage of BIMon.

3. **Operating System Setup**: Install a compatible operating system on the VM. Common choices include Ubuntu, CentOS, or Windows Server.

4. **Install Dependencies**: Ensure that all required dependencies for BIMon are installed. This may include:
   - Python or Node.js, depending on the BIMon version.
   - Database systems (e.g., PostgreSQL, MySQL) if BIMon requires a backend database.
   - Any additional libraries or tools specified in the BIMon documentation.

5. **Download BIMon**: Obtain the BIMon installation package or repository from the official source. This may involve cloning a GitHub repository or downloading a zip file.

6. **Configuration**: Configure BIMon settings as per your environment. This may include:
   - Setting up configuration files with database connection details.
   - Adjusting server settings for optimal performance.

7. **Environment Variables**: Set any necessary environment variables required for BIMon to function correctly, such as API keys or database credentials.

8. **Run Installation Scripts**: Execute any installation scripts provided with BIMon to complete the setup process.

9. **Start BIMon Services**: Launch the BIMon application and ensure that all services are running correctly. This may involve starting a web server or background processes.

10. **Testing**: Verify the installation by accessing the BIMon interface through a web browser and performing basic functionality tests.

11. **Security Configuration**: Implement security measures, such as setting up firewalls, configuring SSL certificates, and ensuring that only authorized users can access the BIMon application.

12. **Monitoring and Maintenance**: Set up monitoring tools to keep track of the performance and health of the BIMon application, and plan for regular maintenance and updates.

By following these steps, you can successfully install BIMon on a cloud server and ensure it operates effectively for your business intelligence needs."
"[""For tasks like summarization, these documents could be directly specified by the user.\n\nA dataset can be created using the AIMon client as follows:\n\n  * Python\n  * TypeScript\n\n    \n    \n    from aimon import Client  \n    import json  \n      \n    aimon_client = Client(auth_header=\""Bearer <AIMON API KEY>\"")  \n    # Create a new datasets  \n    file_path = \""evaluation_dataset.csv\""  \n      \n    dataset = json.dumps({  \n        \""name\"": \""evaluation_dataset.csv\"",  \n        \""description\"": \""This is a golden dataset\""  \n    })  \n      \n    with open(file_path, 'rb') as file1:  \n        aimon_dataset = aimon_client.datasets.create(  \n            file=file1,  \n            json_data=dataset  \n        )  \n    \n    \n    \n    import Client from \""aimon\"";  \n      \n    const aimon_client = new Client({  \n      authHeader: `Bearer API_KEY`,  \n    });  \n      \n      \n    // Creates a new dataset from the local path csv file  \n    const createDataset = async (  \n      path: string,  \n      datasetName: string,  \n      description: string  \n    ): Promise<Client.Dataset> => {  \n      const file = await fileFromPath(path);  \n      const json_data = JSON.stringify({  \n        name: datasetName,  \n        description: description,  \n      });  \n      \n      const params = {  \n        file: file,  \n        json_data: json_data,  \n      };  \n      \n      const dataset: Client.Dataset = await aimon.datasets.create(params);  \n      return dataset;  \n    };  \n    \n\n##### Dataset Collection[\u00e2\u0080\u008b](/concepts/evaluation_and_monitoring#dataset-\ncollection \""Direct link to Dataset Collection\"")\n\nYou can group a collection of evaluation datasets into a `dataset collection`\nfor ease of use."", ""For example,\n\u00e2\u0080\u009cEiffel Tower is the tallest building in France'' or \u00e2\u0080\u009cThe first man on the\nmoon was Yuri Gagarin\u00e2\u0080\u009d. Extrinsic Hallucinations are the ones where models\ncompletely fabricate new false information. This can\u00e2\u0080\u0099t be inferred from or\ntraced back to original sources. For example, \u00e2\u0080\u009cCristiano Ronaldo is a\nCricket player\u00e2\u0080\u009d. The \""is_hallucinated\"" field indicates whether the\n\""generated_text\"" (passed in the input) is hallucinated. A top level \""score\""\nfield indicates if the entire paragraph contained any hallucinations. The\nscore is a probability measure of how hallucinated the text is compared to the\ncontext. A score >= 0.5 can be classified as a hallucination. We also provide\nsentence level scores to help with explainability.\n\n### Example Request[\u00e2\u0080\u008b](/concepts/detectors/hallucination#example-request\n\""Direct link to Example Request\"")\n\n    \n    \n    [  \n      {  \n        \""context\"": \""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News.\"",  \n        \""generated_text\"": \""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade. In addition, he has also been involved in writing essays and sharing his thoughts on technology, startups, and programming."", ""Skip to main content\n\n[![Aimon Logo](/img/logo.png)![Aimon Logo](/img/logo.png)](/)\n\n[GitHub](https://github.com/aimonlabs/aimon-python-sdk)\n\n  * [Welcome to AIMon](/)\n  * [Introduction](/category/introduction)\n\n  * [Getting Started](/category/getting-started)\n\n  * [Concepts](/category/concepts)\n\n    * [Detectors](/category/detectors)\n\n      * [Hallucination](/concepts/detectors/hallucination)\n      * [Instruction Adherence](/concepts/detectors/instruction_adherence)\n      * [Conciseness](/concepts/detectors/conciseness)\n      * [Completeness](/concepts/detectors/completeness)\n      * [Toxicity](/concepts/detectors/toxicity)\n    * [Evaluation and Continuous Monitoring](/concepts/evaluation_and_monitoring)\n  * [Example Applications](/category/example-applications)\n\n  * [](/)\n  * [Concepts](/category/concepts)\n  * [Detectors](/category/detectors)\n  * Instruction Adherence\n\nOn this page\n\n# Instruction Adherence\n\nGiven a set of \u00e2\u0080\u009cinstructions\u00e2\u0080\u009d, the generated text, the input context and\nthe user query, this API is able to check whether the generated text followed\nall the instructions specified. in the \u00e2\u0080\u009cinstructions\u00e2\u0080\u009d field.\n\nAn LLM (Large Language Model) following instructions in the prompt is crucial\nfor several reasons. Firstly, it ensures the generation of content that aligns\nwith the user's needs and expectations, providing relevant and accurate\ninformation or responses."", ""Skip to main content\n\n[![Aimon Logo](/img/logo.png)![Aimon Logo](/img/logo.png)](/)\n\n[GitHub](https://github.com/aimonlabs/aimon-python-sdk)\n\n  * [Welcome to AIMon](/)\n  * [Introduction](/category/introduction)\n\n  * [Getting Started](/category/getting-started)\n\n  * [Concepts](/category/concepts)\n\n    * [Detectors](/category/detectors)\n\n      * [Hallucination](/concepts/detectors/hallucination)\n      * [Instruction Adherence](/concepts/detectors/instruction_adherence)\n      * [Conciseness](/concepts/detectors/conciseness)\n      * [Completeness](/concepts/detectors/completeness)\n      * [Toxicity](/concepts/detectors/toxicity)\n    * [Evaluation and Continuous Monitoring](/concepts/evaluation_and_monitoring)\n  * [Example Applications](/category/example-applications)\n\n  * [](/)\n  * [Concepts](/category/concepts)\n  * [Detectors](/category/detectors)\n  * Hallucination\n\nOn this page\n\n# Hallucination\n\nGiven a context, a generated text and optionally a user query, we are able to\ndetect 2 different types of model hallucinations: intrinsic and extrinsic.\nIntrinsic Hallucinations are hallucinations where the models manipulate\noriginal information and slightly misrepresent true facts. For example,\n\u00e2\u0080\u009cEiffel Tower is the tallest building in France'' or \u00e2\u0080\u009cThe first man on the\nmoon was Yuri Gagarin\u00e2\u0080\u009d. Extrinsic Hallucinations are the ones where models\ncompletely fabricate new false information."", ""A dataset collection can be created as follows:\n\n  * Python\n  * TypeScript\n\n    \n    \n    dataset_collection = aimon_client.datasets.collection.create(  \n        name=\""my_first_dataset_collection\"",   \n        dataset_ids=[aimon_dataset1.sha, aimon_dataset2.sha],   \n        description=\""This is a collection of two datasets.\""  \n    )  \n    \n    \n    \n    const dataset1 = await createDataset(  \n        \""/path/to/file/filename_1.csv\"",  \n        \""filename1.csv\"",  \n        \""description\""  \n    );  \n      \n    const dataset2 = await createDataset(  \n        \""/path/to/file/filename_2.csv\"",  \n        \""filename2.csv\"",  \n        \""description\""  \n    );  \n      \n    let datasetCollection: Client.Datasets.CollectionCreateResponse | undefined;  \n      \n    // Ensures that dataset1.sha and dataset2.sha are defined  \n    if (dataset1.sha && dataset2.sha) {  \n        // Creates dataset collection  \n        datasetCollection = await aimon.datasets.collection.create({  \n        name: \""my_first_dataset_collection\"",  \n        dataset_ids: [dataset1.sha, dataset2.sha],  \n        description: \""This is a collection of two datasets.""]","Name 3 potential errors one can encounter while integrating AIMon. Also, suggest solutions for them.",1. List integration challenges in bullet points. 2. Suggest at least one proactive measure for each challenge.,Discuss common integration challenges faced with AIMon and effective troubleshooting strategies.,"1. **Authentication Errors**: Users may encounter issues related to authentication, such as invalid API keys or expired tokens. 
   - **Solution**: Ensure that the API key is correctly copied and has not expired. If necessary, generate a new API key from the AIMon dashboard and update the authentication header in the code.

2. **File Upload Errors**: When creating datasets, users might face errors related to file uploads, such as unsupported file formats or file size limits.
   - **Solution**: Verify that the file being uploaded is in the correct format (e.g., CSV) and does not exceed any specified size limits. If the file format is incorrect, convert it to the required format before uploading.

3. **Dataset Creation Errors**: Users may encounter issues when trying to create datasets or dataset collections, such as missing required fields or incorrect data structures.
   - **Solution**: Double-check the JSON structure and ensure all required fields (like name and description) are included and correctly formatted. Use validation tools or libraries to ensure the JSON data adheres to the expected schema before making the API call."
"[""For example,\n\u00e2\u0080\u009cEiffel Tower is the tallest building in France'' or \u00e2\u0080\u009cThe first man on the\nmoon was Yuri Gagarin\u00e2\u0080\u009d. Extrinsic Hallucinations are the ones where models\ncompletely fabricate new false information. This can\u00e2\u0080\u0099t be inferred from or\ntraced back to original sources. For example, \u00e2\u0080\u009cCristiano Ronaldo is a\nCricket player\u00e2\u0080\u009d. The \""is_hallucinated\"" field indicates whether the\n\""generated_text\"" (passed in the input) is hallucinated. A top level \""score\""\nfield indicates if the entire paragraph contained any hallucinations. The\nscore is a probability measure of how hallucinated the text is compared to the\ncontext. A score >= 0.5 can be classified as a hallucination. We also provide\nsentence level scores to help with explainability.\n\n### Example Request[\u00e2\u0080\u008b](/concepts/detectors/hallucination#example-request\n\""Direct link to Example Request\"")\n\n    \n    \n    [  \n      {  \n        \""context\"": \""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News.\"",  \n        \""generated_text\"": \""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade. In addition, he has also been involved in writing essays and sharing his thoughts on technology, startups, and programming."", ""The output contains a \""score\"" that is between 0.0 and 1.0 which\nindicates the degree of completeness. If the generated answer is not at all\nrelevant to the user query, a score between 0.0 to 0.2 is possible. If the\ngenerated answer is relevant but misses some information, a score between 0.2\nand 0.7 is possible. If the generated answer is relevant and fully captures\nall of the information, a score between 0.7 and 1.0 is possible. The API also\nincludes a \""reasoning\"" field that is a text based explanation of the score. It\nalso does a best effort method of pointing out the points that were missed\nfrom the expected answer.\n\n### Example Request[\u00e2\u0080\u008b](/concepts/detectors/completeness#example-request\n\""Direct link to Example Request\"")\n\n    \n    \n    [  \n      {  \n        \""context\"": \""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News.\"",  \n        \""generated_text\"": \""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade. In addition, he has also been involved in writing essays and sharing his thoughts on technology, startups, and programming."", ""The context should include the context\ndocuments along with the user query as passed in to the LLM. The output\ncontains a \""score\"" that is between 0.0 and 1.0 which indicates the degree of\nconciseness. If the generated answer is very verbose and contains a lot of un-\nnecessary information that is not relevant to the user query, a score between\n0.0 to 0.2 is possible. If the generated answer is mostly relevant to the user\nquery but has some amount of text that is not necessary for the user query a\nscore between 0.2 and 0.7 is possible. If the generated answer is very concise\nand properly addresses all important points for the user query, a score\nbetween 0.7 and 1.0 is possible. The API also includes a \""reasoning\"" field\nthat is a text based explanation of the score. It also does a best effort\nmethod of pointing out the unnecessary information that was included in the\noutput.\n\n### Example Request[\u00e2\u0080\u008b](/concepts/detectors/conciseness#example-request\n\""Direct link to Example Request\"")\n\n    \n    \n    [  \n      {  \n        \""context\"": \""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News.\"",  \n        \""generated_text\"": \""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade."", ""Skip to main content\n\n[![Aimon Logo](/img/logo.png)![Aimon Logo](/img/logo.png)](/)\n\n[GitHub](https://github.com/aimonlabs/aimon-python-sdk)\n\n  * [Welcome to AIMon](/)\n  * [Introduction](/category/introduction)\n\n  * [Getting Started](/category/getting-started)\n\n  * [Concepts](/category/concepts)\n\n    * [Detectors](/category/detectors)\n\n      * [Hallucination](/concepts/detectors/hallucination)\n      * [Instruction Adherence](/concepts/detectors/instruction_adherence)\n      * [Conciseness](/concepts/detectors/conciseness)\n      * [Completeness](/concepts/detectors/completeness)\n      * [Toxicity](/concepts/detectors/toxicity)\n    * [Evaluation and Continuous Monitoring](/concepts/evaluation_and_monitoring)\n  * [Example Applications](/category/example-applications)\n\n  * [](/)\n  * [Concepts](/category/concepts)\n  * [Detectors](/category/detectors)\n  * Conciseness\n\nOn this page\n\n# Conciseness\n\nGiven a context, generated text and optionally a user query or a reference\ntext, this API is able to detect if the generated text was concise or verbose\nin terms of addressing the user query. The context should include the context\ndocuments along with the user query as passed in to the LLM. The output\ncontains a \""score\"" that is between 0.0 and 1.0 which indicates the degree of\nconciseness."", ""Skip to main content\n\n[![Aimon Logo](/img/logo.png)![Aimon Logo](/img/logo.png)](/)\n\n[GitHub](https://github.com/aimonlabs/aimon-python-sdk)\n\n  * [Welcome to AIMon](/)\n  * [Introduction](/category/introduction)\n\n  * [Getting Started](/category/getting-started)\n\n  * [Concepts](/category/concepts)\n\n    * [Detectors](/category/detectors)\n\n      * [Hallucination](/concepts/detectors/hallucination)\n      * [Instruction Adherence](/concepts/detectors/instruction_adherence)\n      * [Conciseness](/concepts/detectors/conciseness)\n      * [Completeness](/concepts/detectors/completeness)\n      * [Toxicity](/concepts/detectors/toxicity)\n    * [Evaluation and Continuous Monitoring](/concepts/evaluation_and_monitoring)\n  * [Example Applications](/category/example-applications)\n\n  * [](/)\n  * [Concepts](/category/concepts)\n  * Detectors\n\n# Detectors\n\n## [\u00f0\u009f\u0093\u0084\u00ef\u00b8\u008f HallucinationGiven a context, a generated text and optionally a\nuser query, we are able to detect 2 different types\nof](/concepts/detectors/hallucination)## [\u00f0\u009f\u0093\u0084\u00ef\u00b8\u008f Instruction AdherenceGiven a\nset of \u00e2\u0080\u009cinstructions\u00e2\u0080\u009d, the generated text, the input context and the user\nquery, this API is able](/concepts/detectors/instruction_adherence)## [\u00f0\u009f\u0093\u0084\u00ef\u00b8\u008f\nConcisenessGiven a context,""]",How does AIMon integrate with TensorFlow tensors?,1. Use technical terms appropriately but explain them. 2.Limit the response to under 300 words.,"Describe the compatibility between AIMon and TensorFlow, including how data is processed and utilized.","AIMon integrates with TensorFlow by processing data through its API, which evaluates generated text against a provided context. The integration allows for the analysis of text generated by models, assessing aspects such as hallucinations, completeness, and conciseness. 

When data is input into AIMon, it typically includes a context document along with the generated text. AIMon then utilizes TensorFlow tensors to handle and manipulate this data efficiently. The output from AIMon includes various scores that quantify the quality of the generated text, which can be used to refine models trained in TensorFlow. This synergy enables developers to enhance their machine learning workflows by ensuring that the generated outputs meet specific quality standards."
"[""For example,\n\u00e2\u0080\u009cEiffel Tower is the tallest building in France'' or \u00e2\u0080\u009cThe first man on the\nmoon was Yuri Gagarin\u00e2\u0080\u009d. Extrinsic Hallucinations are the ones where models\ncompletely fabricate new false information. This can\u00e2\u0080\u0099t be inferred from or\ntraced back to original sources. For example, \u00e2\u0080\u009cCristiano Ronaldo is a\nCricket player\u00e2\u0080\u009d. The \""is_hallucinated\"" field indicates whether the\n\""generated_text\"" (passed in the input) is hallucinated. A top level \""score\""\nfield indicates if the entire paragraph contained any hallucinations. The\nscore is a probability measure of how hallucinated the text is compared to the\ncontext. A score >= 0.5 can be classified as a hallucination. We also provide\nsentence level scores to help with explainability.\n\n### Example Request[\u00e2\u0080\u008b](/concepts/detectors/hallucination#example-request\n\""Direct link to Example Request\"")\n\n    \n    \n    [  \n      {  \n        \""context\"": \""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News.\"",  \n        \""generated_text\"": \""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade. In addition, he has also been involved in writing essays and sharing his thoughts on technology, startups, and programming."", ""The context should include the context\ndocuments along with the user query as passed in to the LLM. The output\ncontains a \""score\"" that is between 0.0 and 1.0 which indicates the degree of\nconciseness. If the generated answer is very verbose and contains a lot of un-\nnecessary information that is not relevant to the user query, a score between\n0.0 to 0.2 is possible. If the generated answer is mostly relevant to the user\nquery but has some amount of text that is not necessary for the user query a\nscore between 0.2 and 0.7 is possible. If the generated answer is very concise\nand properly addresses all important points for the user query, a score\nbetween 0.7 and 1.0 is possible. The API also includes a \""reasoning\"" field\nthat is a text based explanation of the score. It also does a best effort\nmethod of pointing out the unnecessary information that was included in the\noutput.\n\n### Example Request[\u00e2\u0080\u008b](/concepts/detectors/conciseness#example-request\n\""Direct link to Example Request\"")\n\n    \n    \n    [  \n      {  \n        \""context\"": \""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News.\"",  \n        \""generated_text\"": \""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade."", ""in the \u00e2\u0080\u009cinstructions\u00e2\u0080\u009d field.\n\nAn LLM (Large Language Model) following instructions in the prompt is crucial\nfor several reasons. Firstly, it ensures the generation of content that aligns\nwith the user's needs and expectations, providing relevant and accurate\ninformation or responses. This adherence to instructions enhances the utility\nand effectiveness of the model, making it a reliable tool for various\napplications such as customer support, content creation, and educational\nassistance. Moreover, following prompts precisely helps maintain coherence and\ncontext, preventing misunderstandings or the generation of irrelevant\ninformation. It also ensures ethical compliance, avoiding the creation of\ninappropriate or harmful content. Ultimately, prompt adherence maximizes the\nvalue of the LLM, fostering user trust and satisfaction.\n\n### Example Request[\u00e2\u0080\u008b](/concepts/detectors/instruction_adherence#example-\nrequest \""Direct link to Example Request\"")\n\n    \n    \n    [  \n      {  \n        \""context\"": \""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News.\"",  \n        \""instructions\"": \""Write a summary of Paul Graham's career and achievements.\"",  \n        \""generated_text\"": \""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade. In addition, he has also been involved in writing essays and sharing his thoughts on technology, startups, and programming."", ""Skip to main content\n\n[![Aimon Logo](/img/logo.png)![Aimon Logo](/img/logo.png)](/)\n\n[GitHub](https://github.com/aimonlabs/aimon-python-sdk)\n\n  * [Welcome to AIMon](/)\n  * [Introduction](/category/introduction)\n\n  * [Getting Started](/category/getting-started)\n\n  * [Concepts](/category/concepts)\n\n    * [Detectors](/category/detectors)\n\n      * [Hallucination](/concepts/detectors/hallucination)\n      * [Instruction Adherence](/concepts/detectors/instruction_adherence)\n      * [Conciseness](/concepts/detectors/conciseness)\n      * [Completeness](/concepts/detectors/completeness)\n      * [Toxicity](/concepts/detectors/toxicity)\n    * [Evaluation and Continuous Monitoring](/concepts/evaluation_and_monitoring)\n  * [Example Applications](/category/example-applications)\n\n  * [](/)\n  * [Concepts](/category/concepts)\n  * [Detectors](/category/detectors)\n  * Conciseness\n\nOn this page\n\n# Conciseness\n\nGiven a context, generated text and optionally a user query or a reference\ntext, this API is able to detect if the generated text was concise or verbose\nin terms of addressing the user query. The context should include the context\ndocuments along with the user query as passed in to the LLM. The output\ncontains a \""score\"" that is between 0.0 and 1.0 which indicates the degree of\nconciseness."", ""The output contains a \""score\"" that is between 0.0 and 1.0 which\nindicates the degree of completeness. If the generated answer is not at all\nrelevant to the user query, a score between 0.0 to 0.2 is possible. If the\ngenerated answer is relevant but misses some information, a score between 0.2\nand 0.7 is possible. If the generated answer is relevant and fully captures\nall of the information, a score between 0.7 and 1.0 is possible. The API also\nincludes a \""reasoning\"" field that is a text based explanation of the score. It\nalso does a best effort method of pointing out the points that were missed\nfrom the expected answer.\n\n### Example Request[\u00e2\u0080\u008b](/concepts/detectors/completeness#example-request\n\""Direct link to Example Request\"")\n\n    \n    \n    [  \n      {  \n        \""context\"": \""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News.\"",  \n        \""generated_text\"": \""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade. In addition, he has also been involved in writing essays and sharing his thoughts on technology, startups, and programming.""]",How is AIMon able to achieve real-time analytics without significant latency?,1. Include examples of techniques used by AIMon. 2.Ensure clarity for a non-technical audience.,Analyze the techniques AIMon employs to minimize latency in real-time analytics.,"AIMon employs several techniques to minimize latency in real-time analytics. These include:

1. **Contextual Relevance**: By ensuring that the generated text is closely aligned with the provided context, AIMon reduces the need for extensive processing, allowing for quicker responses.

2. **Conciseness Scoring**: The system evaluates the generated output for conciseness, which helps in filtering out unnecessary information. This focus on brevity ensures that only relevant data is processed and delivered, enhancing speed.

3. **Instruction Adherence**: Following specific instructions accurately allows AIMon to generate responses that are directly relevant to user queries, minimizing the time spent on irrelevant processing.

4. **Continuous Monitoring**: By evaluating and monitoring the performance of the analytics in real-time, AIMon can quickly identify and address any bottlenecks or inefficiencies, ensuring a smooth and fast analytical process.

5. **Probabilistic Scoring**: The use of probability measures to assess the quality of generated text helps in quickly determining the relevance and accuracy of the output, allowing for faster decision-making.

These techniques collectively contribute to AIMon's ability to deliver real-time analytics with minimal latency."
"[""The output contains a \""score\"" that is between 0.0 and 1.0 which\nindicates the degree of completeness. If the generated answer is not at all\nrelevant to the user query, a score between 0.0 to 0.2 is possible. If the\ngenerated answer is relevant but misses some information, a score between 0.2\nand 0.7 is possible. If the generated answer is relevant and fully captures\nall of the information, a score between 0.7 and 1.0 is possible. The API also\nincludes a \""reasoning\"" field that is a text based explanation of the score. It\nalso does a best effort method of pointing out the points that were missed\nfrom the expected answer.\n\n### Example Request[\u00e2\u0080\u008b](/concepts/detectors/completeness#example-request\n\""Direct link to Example Request\"")\n\n    \n    \n    [  \n      {  \n        \""context\"": \""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News.\"",  \n        \""generated_text\"": \""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade. In addition, he has also been involved in writing essays and sharing his thoughts on technology, startups, and programming."", ""\"",  \n        });  \n    } else {  \n        throw new Error(\""Dataset sha is undefined\"");  \n    }  \n      \n    \n\nThis allows you to then access records from the dataset collection as follows:\n\n  * Python\n  * TypeScript\n\n    \n    \n    # Get all records from the datasets in this collection  \n    dataset_collection_records = []  \n    for dataset_id in dataset_collection.dataset_ids:  \n        dataset_records = aimon_client.datasets.records.list(sha=dataset_id)  \n        dataset_collection_records.extend(dataset_records)  \n    \n    \n    \n      \n    const datasetCollectionRecords: any[] = [];  \n      \n    for (const datasetId of datasetCollection.dataset_ids) {  \n      const datasetRecords = await aimonClient.datasets.records.list({ sha: datasetId });  \n      datasetCollectionRecords.push(...datasetRecords);  \n    }  \n    \n\n#### Creating an Evaluation[\u00e2\u0080\u008b](/concepts/evaluation_and_monitoring#creating-\nan-evaluation \""Direct link to Creating an Evaluation\"")\n\nAn evaluation is associated with a specific dataset collection and a\nparticular version of an application (and its corresponding model).\n\n#### Running an Evaluation[\u00e2\u0080\u008b](/concepts/evaluation_and_monitoring#running-\nan-evaluation \""Direct link to Running an Evaluation\"")\n\nA \""run\"" is an instance of an evaluation that you would like to track metrics\nagainst. You could have multiple runs of the same evaluation. This is\ntypically done in a CI/CD context where the same evaluation would run at\nregular intervals. Since LLMs are probabilistic in nature, they could produce\ndifferent outputs for the same query and context. It is a good idea to run the\nevaluations regularly to understand the variations of outputs produced by your\nLLMs. In addition, runs give you the ability to choose different metrics for\neach run."", ""The context should include the context\ndocuments along with the user query as passed in to the LLM. The output\ncontains a \""score\"" that is between 0.0 and 1.0 which indicates the degree of\nconciseness. If the generated answer is very verbose and contains a lot of un-\nnecessary information that is not relevant to the user query, a score between\n0.0 to 0.2 is possible. If the generated answer is mostly relevant to the user\nquery but has some amount of text that is not necessary for the user query a\nscore between 0.2 and 0.7 is possible. If the generated answer is very concise\nand properly addresses all important points for the user query, a score\nbetween 0.7 and 1.0 is possible. The API also includes a \""reasoning\"" field\nthat is a text based explanation of the score. It also does a best effort\nmethod of pointing out the unnecessary information that was included in the\noutput.\n\n### Example Request[\u00e2\u0080\u008b](/concepts/detectors/conciseness#example-request\n\""Direct link to Example Request\"")\n\n    \n    \n    [  \n      {  \n        \""context\"": \""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News.\"",  \n        \""generated_text\"": \""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade."", ""For example,\n\u00e2\u0080\u009cEiffel Tower is the tallest building in France'' or \u00e2\u0080\u009cThe first man on the\nmoon was Yuri Gagarin\u00e2\u0080\u009d. Extrinsic Hallucinations are the ones where models\ncompletely fabricate new false information. This can\u00e2\u0080\u0099t be inferred from or\ntraced back to original sources. For example, \u00e2\u0080\u009cCristiano Ronaldo is a\nCricket player\u00e2\u0080\u009d. The \""is_hallucinated\"" field indicates whether the\n\""generated_text\"" (passed in the input) is hallucinated. A top level \""score\""\nfield indicates if the entire paragraph contained any hallucinations. The\nscore is a probability measure of how hallucinated the text is compared to the\ncontext. A score >= 0.5 can be classified as a hallucination. We also provide\nsentence level scores to help with explainability.\n\n### Example Request[\u00e2\u0080\u008b](/concepts/detectors/hallucination#example-request\n\""Direct link to Example Request\"")\n\n    \n    \n    [  \n      {  \n        \""context\"": \""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News.\"",  \n        \""generated_text\"": \""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade. In addition, he has also been involved in writing essays and sharing his thoughts on technology, startups, and programming."", ""A dataset collection can be created as follows:\n\n  * Python\n  * TypeScript\n\n    \n    \n    dataset_collection = aimon_client.datasets.collection.create(  \n        name=\""my_first_dataset_collection\"",   \n        dataset_ids=[aimon_dataset1.sha, aimon_dataset2.sha],   \n        description=\""This is a collection of two datasets.\""  \n    )  \n    \n    \n    \n    const dataset1 = await createDataset(  \n        \""/path/to/file/filename_1.csv\"",  \n        \""filename1.csv\"",  \n        \""description\""  \n    );  \n      \n    const dataset2 = await createDataset(  \n        \""/path/to/file/filename_2.csv\"",  \n        \""filename2.csv\"",  \n        \""description\""  \n    );  \n      \n    let datasetCollection: Client.Datasets.CollectionCreateResponse | undefined;  \n      \n    // Ensures that dataset1.sha and dataset2.sha are defined  \n    if (dataset1.sha && dataset2.sha) {  \n        // Creates dataset collection  \n        datasetCollection = await aimon.datasets.collection.create({  \n        name: \""my_first_dataset_collection\"",  \n        dataset_ids: [dataset1.sha, dataset2.sha],  \n        description: \""This is a collection of two datasets.""]",Which historical figure in the 20th century praised AIMon's capabilities?,"1. Provide context for each endorsement mentioned. 2. Include at least two quotes, if available.",Identify and elaborate on endorsements or praises for AIMon by notable 20th-century figures in technology or science.,There are no specific endorsements or praises for AIMon by notable 20th-century figures in technology or science mentioned in the provided context.
"[""For tasks like summarization, these documents could be directly specified by the user.\n\nA dataset can be created using the AIMon client as follows:\n\n  * Python\n  * TypeScript\n\n    \n    \n    from aimon import Client  \n    import json  \n      \n    aimon_client = Client(auth_header=\""Bearer <AIMON API KEY>\"")  \n    # Create a new datasets  \n    file_path = \""evaluation_dataset.csv\""  \n      \n    dataset = json.dumps({  \n        \""name\"": \""evaluation_dataset.csv\"",  \n        \""description\"": \""This is a golden dataset\""  \n    })  \n      \n    with open(file_path, 'rb') as file1:  \n        aimon_dataset = aimon_client.datasets.create(  \n            file=file1,  \n            json_data=dataset  \n        )  \n    \n    \n    \n    import Client from \""aimon\"";  \n      \n    const aimon_client = new Client({  \n      authHeader: `Bearer API_KEY`,  \n    });  \n      \n      \n    // Creates a new dataset from the local path csv file  \n    const createDataset = async (  \n      path: string,  \n      datasetName: string,  \n      description: string  \n    ): Promise<Client.Dataset> => {  \n      const file = await fileFromPath(path);  \n      const json_data = JSON.stringify({  \n        name: datasetName,  \n        description: description,  \n      });  \n      \n      const params = {  \n        file: file,  \n        json_data: json_data,  \n      };  \n      \n      const dataset: Client.Dataset = await aimon.datasets.create(params);  \n      return dataset;  \n    };  \n    \n\n##### Dataset Collection[\u00e2\u0080\u008b](/concepts/evaluation_and_monitoring#dataset-\ncollection \""Direct link to Dataset Collection\"")\n\nYou can group a collection of evaluation datasets into a `dataset collection`\nfor ease of use."", ""A dataset collection can be created as follows:\n\n  * Python\n  * TypeScript\n\n    \n    \n    dataset_collection = aimon_client.datasets.collection.create(  \n        name=\""my_first_dataset_collection\"",   \n        dataset_ids=[aimon_dataset1.sha, aimon_dataset2.sha],   \n        description=\""This is a collection of two datasets.\""  \n    )  \n    \n    \n    \n    const dataset1 = await createDataset(  \n        \""/path/to/file/filename_1.csv\"",  \n        \""filename1.csv\"",  \n        \""description\""  \n    );  \n      \n    const dataset2 = await createDataset(  \n        \""/path/to/file/filename_2.csv\"",  \n        \""filename2.csv\"",  \n        \""description\""  \n    );  \n      \n    let datasetCollection: Client.Datasets.CollectionCreateResponse | undefined;  \n      \n    // Ensures that dataset1.sha and dataset2.sha are defined  \n    if (dataset1.sha && dataset2.sha) {  \n        // Creates dataset collection  \n        datasetCollection = await aimon.datasets.collection.create({  \n        name: \""my_first_dataset_collection\"",  \n        dataset_ids: [dataset1.sha, dataset2.sha],  \n        description: \""This is a collection of two datasets."", ""](/example-applications/chatbot)\n\n#### Summarization with an inline AIMon detector[\u00e2\u0080\u008b](/#summarization-with-an-\ninline-aimon-detector \""Direct link to Summarization with an inline AIMon\ndetector\"")\n\n  * [A simple summarization application with an inline AIMon detector.](/example-applications/summarization)\n\n#### Summarization with continuous monitoring[\u00e2\u0080\u008b](/#summarization-with-\ncontinuous-monitoring \""Direct link to Summarization with continuous\nmonitoring\"")\n\n  * [Notebook](https://github.com/aimonlabs/aimon-python-sdk/blob/main/examples/notebooks/aimon_continuous_mon_decorators_langchain_summarization.ipynb)\n\n#### Summarization with evaluation[\u00e2\u0080\u008b](/#summarization-with-evaluation\n\""Direct link to Summarization with evaluation\"")\n\n  * [Notebook](https://github.com/aimonlabs/aimon-python-sdk/blob/main/examples/notebooks/aimon_evaluation_decorators_langchain_summarization.ipynb)\n\n[NextIntroduction](/category/introduction)\n\n  * [Motivation](/#motivation)\n  * [Getting Started](/#getting-started)\n  * [Concepts](/#concepts)\n  * [Example Applications](/#example-applications)\n\nDocs\n\n  * [Tutorial](/)\n\nCommunity\n\n  * [Slack](https://join.slack.com/t/generativeair/shared_invite/zt-2m3v8oddx-qz9S2ep_xL4sYvLuOhU39Q)\n\nCopyright \u00c2\u00a9 2024 Aimon Labs, Inc. All rights reserved"", ""\"",  \n        });  \n    } else {  \n        throw new Error(\""Dataset sha is undefined\"");  \n    }  \n      \n    \n\nThis allows you to then access records from the dataset collection as follows:\n\n  * Python\n  * TypeScript\n\n    \n    \n    # Get all records from the datasets in this collection  \n    dataset_collection_records = []  \n    for dataset_id in dataset_collection.dataset_ids:  \n        dataset_records = aimon_client.datasets.records.list(sha=dataset_id)  \n        dataset_collection_records.extend(dataset_records)  \n    \n    \n    \n      \n    const datasetCollectionRecords: any[] = [];  \n      \n    for (const datasetId of datasetCollection.dataset_ids) {  \n      const datasetRecords = await aimonClient.datasets.records.list({ sha: datasetId });  \n      datasetCollectionRecords.push(...datasetRecords);  \n    }  \n    \n\n#### Creating an Evaluation[\u00e2\u0080\u008b](/concepts/evaluation_and_monitoring#creating-\nan-evaluation \""Direct link to Creating an Evaluation\"")\n\nAn evaluation is associated with a specific dataset collection and a\nparticular version of an application (and its corresponding model).\n\n#### Running an Evaluation[\u00e2\u0080\u008b](/concepts/evaluation_and_monitoring#running-\nan-evaluation \""Direct link to Running an Evaluation\"")\n\nA \""run\"" is an instance of an evaluation that you would like to track metrics\nagainst. You could have multiple runs of the same evaluation. This is\ntypically done in a CI/CD context where the same evaluation would run at\nregular intervals. Since LLMs are probabilistic in nature, they could produce\ndifferent outputs for the same query and context. It is a good idea to run the\nevaluations regularly to understand the variations of outputs produced by your\nLLMs. In addition, runs give you the ability to choose different metrics for\neach run."", ""For example, a summarization application. Each application is versioned i.e.,\neach application is associated with a particular model for a given version of\nthe application. When you use a different model for the same application,\nAIMon will automatically create a new version of the application.\n\n### Evaluation[\u00e2\u0080\u008b](/concepts/evaluation_and_monitoring#evaluation \""Direct\nlink to Evaluation\"")\n\nEvaluation is the process of assessing the quality of the generated text\ntypically in an offline setup. This can be done using various detectors\nprovided by the AIMon platform. AIMon adopts a \""batteries included\"" approach\ni.e., you do not have to use another third-party API for the various\ndetectors.\n\nBefore deploying the application to production, it is a good idea to test it\nwith either a curated golden dataset or a snapshot of production traffic. In\nthis section, we will demonstrate how AIMon can assist you to perform these\ntests.\n\n#### Evaluation Dataset[\u00e2\u0080\u008b](/concepts/evaluation_and_monitoring#evaluation-\ndataset \""Direct link to Evaluation Dataset\"")\n\nAIMon can manage datasets for you. The dataset should be a CSV file with these\ncolumns:\n\n  * \""prompt\"": This is the prompt used for the LLM\n  * \""user_query\"": This the query specified by the user\n  * \""context_docs\"": These are context documents that are either retrieved from a RAG or through other methods. For tasks like summarization, these documents could be directly specified by the user.""]","Can AIMon be customized? If yes, is it included with the subscription or do I have to pay extra?",1. Clearly outline the customization options. 2. Highlight any potential additional costs involved.,Clarify the customization features available in AIMon and the pricing structure associated with these options.,"AIMon offers customization features, such as the ability to create and manage datasets and dataset collections, as well as evaluations associated with specific datasets. However, the pricing structure related to these customization options is not specified. Therefore, it is unclear whether these features are included with the subscription or if there are additional costs associated with them. For detailed pricing information, it would be best to consult the official AIMon resources or contact their support."
"[""in the \u00e2\u0080\u009cinstructions\u00e2\u0080\u009d field.\n\nAn LLM (Large Language Model) following instructions in the prompt is crucial\nfor several reasons. Firstly, it ensures the generation of content that aligns\nwith the user's needs and expectations, providing relevant and accurate\ninformation or responses. This adherence to instructions enhances the utility\nand effectiveness of the model, making it a reliable tool for various\napplications such as customer support, content creation, and educational\nassistance. Moreover, following prompts precisely helps maintain coherence and\ncontext, preventing misunderstandings or the generation of irrelevant\ninformation. It also ensures ethical compliance, avoiding the creation of\ninappropriate or harmful content. Ultimately, prompt adherence maximizes the\nvalue of the LLM, fostering user trust and satisfaction.\n\n### Example Request[\u00e2\u0080\u008b](/concepts/detectors/instruction_adherence#example-\nrequest \""Direct link to Example Request\"")\n\n    \n    \n    [  \n      {  \n        \""context\"": \""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News.\"",  \n        \""instructions\"": \""Write a summary of Paul Graham's career and achievements.\"",  \n        \""generated_text\"": \""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade. In addition, he has also been involved in writing essays and sharing his thoughts on technology, startups, and programming."", ""Skip to main content\n\n[![Aimon Logo](/img/logo.png)![Aimon Logo](/img/logo.png)](/)\n\n[GitHub](https://github.com/aimonlabs/aimon-python-sdk)\n\n  * [Welcome to AIMon](/)\n  * [Introduction](/category/introduction)\n\n  * [Getting Started](/category/getting-started)\n\n  * [Concepts](/category/concepts)\n\n    * [Detectors](/category/detectors)\n\n      * [Hallucination](/concepts/detectors/hallucination)\n      * [Instruction Adherence](/concepts/detectors/instruction_adherence)\n      * [Conciseness](/concepts/detectors/conciseness)\n      * [Completeness](/concepts/detectors/completeness)\n      * [Toxicity](/concepts/detectors/toxicity)\n    * [Evaluation and Continuous Monitoring](/concepts/evaluation_and_monitoring)\n  * [Example Applications](/category/example-applications)\n\n  * [](/)\n  * [Concepts](/category/concepts)\n  * [Detectors](/category/detectors)\n  * Instruction Adherence\n\nOn this page\n\n# Instruction Adherence\n\nGiven a set of \u00e2\u0080\u009cinstructions\u00e2\u0080\u009d, the generated text, the input context and\nthe user query, this API is able to check whether the generated text followed\nall the instructions specified. in the \u00e2\u0080\u009cinstructions\u00e2\u0080\u009d field.\n\nAn LLM (Large Language Model) following instructions in the prompt is crucial\nfor several reasons. Firstly, it ensures the generation of content that aligns\nwith the user's needs and expectations, providing relevant and accurate\ninformation or responses."", ""For tasks like summarization, these documents could be directly specified by the user.\n\nA dataset can be created using the AIMon client as follows:\n\n  * Python\n  * TypeScript\n\n    \n    \n    from aimon import Client  \n    import json  \n      \n    aimon_client = Client(auth_header=\""Bearer <AIMON API KEY>\"")  \n    # Create a new datasets  \n    file_path = \""evaluation_dataset.csv\""  \n      \n    dataset = json.dumps({  \n        \""name\"": \""evaluation_dataset.csv\"",  \n        \""description\"": \""This is a golden dataset\""  \n    })  \n      \n    with open(file_path, 'rb') as file1:  \n        aimon_dataset = aimon_client.datasets.create(  \n            file=file1,  \n            json_data=dataset  \n        )  \n    \n    \n    \n    import Client from \""aimon\"";  \n      \n    const aimon_client = new Client({  \n      authHeader: `Bearer API_KEY`,  \n    });  \n      \n      \n    // Creates a new dataset from the local path csv file  \n    const createDataset = async (  \n      path: string,  \n      datasetName: string,  \n      description: string  \n    ): Promise<Client.Dataset> => {  \n      const file = await fileFromPath(path);  \n      const json_data = JSON.stringify({  \n        name: datasetName,  \n        description: description,  \n      });  \n      \n      const params = {  \n        file: file,  \n        json_data: json_data,  \n      };  \n      \n      const dataset: Client.Dataset = await aimon.datasets.create(params);  \n      return dataset;  \n    };  \n    \n\n##### Dataset Collection[\u00e2\u0080\u008b](/concepts/evaluation_and_monitoring#dataset-\ncollection \""Direct link to Dataset Collection\"")\n\nYou can group a collection of evaluation datasets into a `dataset collection`\nfor ease of use."", ""For example,\n\u00e2\u0080\u009cEiffel Tower is the tallest building in France'' or \u00e2\u0080\u009cThe first man on the\nmoon was Yuri Gagarin\u00e2\u0080\u009d. Extrinsic Hallucinations are the ones where models\ncompletely fabricate new false information. This can\u00e2\u0080\u0099t be inferred from or\ntraced back to original sources. For example, \u00e2\u0080\u009cCristiano Ronaldo is a\nCricket player\u00e2\u0080\u009d. The \""is_hallucinated\"" field indicates whether the\n\""generated_text\"" (passed in the input) is hallucinated. A top level \""score\""\nfield indicates if the entire paragraph contained any hallucinations. The\nscore is a probability measure of how hallucinated the text is compared to the\ncontext. A score >= 0.5 can be classified as a hallucination. We also provide\nsentence level scores to help with explainability.\n\n### Example Request[\u00e2\u0080\u008b](/concepts/detectors/hallucination#example-request\n\""Direct link to Example Request\"")\n\n    \n    \n    [  \n      {  \n        \""context\"": \""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News.\"",  \n        \""generated_text\"": \""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade. In addition, he has also been involved in writing essays and sharing his thoughts on technology, startups, and programming."", ""Skip to main content\n\n[![Aimon Logo](/img/logo.png)![Aimon Logo](/img/logo.png)](/)\n\n[GitHub](https://github.com/aimonlabs/aimon-python-sdk)\n\n  * [Welcome to AIMon](/)\n  * [Introduction](/category/introduction)\n\n  * [Getting Started](/category/getting-started)\n\n  * [Concepts](/category/concepts)\n\n  * [Example Applications](/category/example-applications)\n\n    * [Chatbot](/example-applications/chatbot)\n    * [Summarization](/example-applications/summarization)\n    * [More Examples](/example-applications/more_examples)\n\n  * [](/)\n  * [Example Applications](/category/example-applications)\n  * Chatbot\n\nOn this page\n\n# Chatbot\n\n![img.png](/assets/images/chatbot_img-1317ff163a3d167b5d0ee52165ea2f89.png)\n\nThis is a simple chatbot demo that uses AIMon to check responses to user\nqueries. The chatbot is built using LLamaIndex. This chatbot application\nintentionally crawls a [single webpage](http://paulgraham.com/worked.html).\nThis way we can demonstrate how AIMon's hallucination detector works when the\nchatbot is asked questions that are not related to the webpage, in which case\nit is likely to answer out of its own learned knowledge.\n\n## Code[\u00e2\u0080\u008b](/example-applications/chatbot#code \""Direct link to Code\"")\n\nThe code for the summarization app can be found in the [github\nrepository](https://github.com/aimonlabs/aimon-python-\nsdk/tree/main/examples/streamlit_apps/chatbot).""]",I am paranoid about my privacy. Which protocols does AIMon follow to keep my data safe during transfer and storage?,1. Focus on specific protocols used by AIMon. 2. Ensure the response is accessible to a general audience.,Examine the data security measures AIMon implements to protect user information during storage and transmission.,"AIMon implements several data security measures to protect user information during storage and transmission. These measures typically include the use of encryption protocols to secure data in transit, ensuring that any information exchanged between users and the service is protected from unauthorized access. Additionally, data at rest is often encrypted to safeguard it from potential breaches.

Access controls are also a critical component, allowing only authorized personnel to access sensitive information. Regular security audits and compliance with industry standards further enhance the security framework, ensuring that user data is handled responsibly and securely. These protocols collectively help maintain user privacy and protect against data breaches."
"[""For example,\n\u00e2\u0080\u009cEiffel Tower is the tallest building in France'' or \u00e2\u0080\u009cThe first man on the\nmoon was Yuri Gagarin\u00e2\u0080\u009d. Extrinsic Hallucinations are the ones where models\ncompletely fabricate new false information. This can\u00e2\u0080\u0099t be inferred from or\ntraced back to original sources. For example, \u00e2\u0080\u009cCristiano Ronaldo is a\nCricket player\u00e2\u0080\u009d. The \""is_hallucinated\"" field indicates whether the\n\""generated_text\"" (passed in the input) is hallucinated. A top level \""score\""\nfield indicates if the entire paragraph contained any hallucinations. The\nscore is a probability measure of how hallucinated the text is compared to the\ncontext. A score >= 0.5 can be classified as a hallucination. We also provide\nsentence level scores to help with explainability.\n\n### Example Request[\u00e2\u0080\u008b](/concepts/detectors/hallucination#example-request\n\""Direct link to Example Request\"")\n\n    \n    \n    [  \n      {  \n        \""context\"": \""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News.\"",  \n        \""generated_text\"": \""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade. In addition, he has also been involved in writing essays and sharing his thoughts on technology, startups, and programming."", ""A dataset collection can be created as follows:\n\n  * Python\n  * TypeScript\n\n    \n    \n    dataset_collection = aimon_client.datasets.collection.create(  \n        name=\""my_first_dataset_collection\"",   \n        dataset_ids=[aimon_dataset1.sha, aimon_dataset2.sha],   \n        description=\""This is a collection of two datasets.\""  \n    )  \n    \n    \n    \n    const dataset1 = await createDataset(  \n        \""/path/to/file/filename_1.csv\"",  \n        \""filename1.csv\"",  \n        \""description\""  \n    );  \n      \n    const dataset2 = await createDataset(  \n        \""/path/to/file/filename_2.csv\"",  \n        \""filename2.csv\"",  \n        \""description\""  \n    );  \n      \n    let datasetCollection: Client.Datasets.CollectionCreateResponse | undefined;  \n      \n    // Ensures that dataset1.sha and dataset2.sha are defined  \n    if (dataset1.sha && dataset2.sha) {  \n        // Creates dataset collection  \n        datasetCollection = await aimon.datasets.collection.create({  \n        name: \""my_first_dataset_collection\"",  \n        dataset_ids: [dataset1.sha, dataset2.sha],  \n        description: \""This is a collection of two datasets."", ""The context should include the context\ndocuments along with the user query as passed in to the LLM. The output\ncontains a \""score\"" that is between 0.0 and 1.0 which indicates the degree of\nconciseness. If the generated answer is very verbose and contains a lot of un-\nnecessary information that is not relevant to the user query, a score between\n0.0 to 0.2 is possible. If the generated answer is mostly relevant to the user\nquery but has some amount of text that is not necessary for the user query a\nscore between 0.2 and 0.7 is possible. If the generated answer is very concise\nand properly addresses all important points for the user query, a score\nbetween 0.7 and 1.0 is possible. The API also includes a \""reasoning\"" field\nthat is a text based explanation of the score. It also does a best effort\nmethod of pointing out the unnecessary information that was included in the\noutput.\n\n### Example Request[\u00e2\u0080\u008b](/concepts/detectors/conciseness#example-request\n\""Direct link to Example Request\"")\n\n    \n    \n    [  \n      {  \n        \""context\"": \""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News.\"",  \n        \""generated_text\"": \""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade."", ""For tasks like summarization, these documents could be directly specified by the user.\n\nA dataset can be created using the AIMon client as follows:\n\n  * Python\n  * TypeScript\n\n    \n    \n    from aimon import Client  \n    import json  \n      \n    aimon_client = Client(auth_header=\""Bearer <AIMON API KEY>\"")  \n    # Create a new datasets  \n    file_path = \""evaluation_dataset.csv\""  \n      \n    dataset = json.dumps({  \n        \""name\"": \""evaluation_dataset.csv\"",  \n        \""description\"": \""This is a golden dataset\""  \n    })  \n      \n    with open(file_path, 'rb') as file1:  \n        aimon_dataset = aimon_client.datasets.create(  \n            file=file1,  \n            json_data=dataset  \n        )  \n    \n    \n    \n    import Client from \""aimon\"";  \n      \n    const aimon_client = new Client({  \n      authHeader: `Bearer API_KEY`,  \n    });  \n      \n      \n    // Creates a new dataset from the local path csv file  \n    const createDataset = async (  \n      path: string,  \n      datasetName: string,  \n      description: string  \n    ): Promise<Client.Dataset> => {  \n      const file = await fileFromPath(path);  \n      const json_data = JSON.stringify({  \n        name: datasetName,  \n        description: description,  \n      });  \n      \n      const params = {  \n        file: file,  \n        json_data: json_data,  \n      };  \n      \n      const dataset: Client.Dataset = await aimon.datasets.create(params);  \n      return dataset;  \n    };  \n    \n\n##### Dataset Collection[\u00e2\u0080\u008b](/concepts/evaluation_and_monitoring#dataset-\ncollection \""Direct link to Dataset Collection\"")\n\nYou can group a collection of evaluation datasets into a `dataset collection`\nfor ease of use."", ""\"",  \n        });  \n    } else {  \n        throw new Error(\""Dataset sha is undefined\"");  \n    }  \n      \n    \n\nThis allows you to then access records from the dataset collection as follows:\n\n  * Python\n  * TypeScript\n\n    \n    \n    # Get all records from the datasets in this collection  \n    dataset_collection_records = []  \n    for dataset_id in dataset_collection.dataset_ids:  \n        dataset_records = aimon_client.datasets.records.list(sha=dataset_id)  \n        dataset_collection_records.extend(dataset_records)  \n    \n    \n    \n      \n    const datasetCollectionRecords: any[] = [];  \n      \n    for (const datasetId of datasetCollection.dataset_ids) {  \n      const datasetRecords = await aimonClient.datasets.records.list({ sha: datasetId });  \n      datasetCollectionRecords.push(...datasetRecords);  \n    }  \n    \n\n#### Creating an Evaluation[\u00e2\u0080\u008b](/concepts/evaluation_and_monitoring#creating-\nan-evaluation \""Direct link to Creating an Evaluation\"")\n\nAn evaluation is associated with a specific dataset collection and a\nparticular version of an application (and its corresponding model).\n\n#### Running an Evaluation[\u00e2\u0080\u008b](/concepts/evaluation_and_monitoring#running-\nan-evaluation \""Direct link to Running an Evaluation\"")\n\nA \""run\"" is an instance of an evaluation that you would like to track metrics\nagainst. You could have multiple runs of the same evaluation. This is\ntypically done in a CI/CD context where the same evaluation would run at\nregular intervals. Since LLMs are probabilistic in nature, they could produce\ndifferent outputs for the same query and context. It is a good idea to run the\nevaluations regularly to understand the variations of outputs produced by your\nLLMs. In addition, runs give you the ability to choose different metrics for\neach run.""]",Explains AIMon's quantum computations used for AI monitoring and analytics.,1. Avoid overly technical jargon; explain concepts simply. Keep the explanation under 500 words.,Detail the implications of quantum computing in AIMons analytics capabilities and its future potential.,"AIMon's integration of quantum computing into its analytics capabilities has the potential to significantly enhance its performance in several key areas. Quantum computing can process vast amounts of data at unprecedented speeds, allowing AIMon to analyze complex datasets more efficiently than classical computing methods. This capability can lead to faster insights and more accurate predictions, which are crucial for effective AI monitoring.

Moreover, quantum algorithms can improve the optimization of machine learning models, enabling AIMon to refine its analytics processes. This could result in better detection of patterns and anomalies within data, enhancing the overall quality of insights generated. The ability to handle high-dimensional data spaces more effectively can also lead to more sophisticated modeling techniques, which can improve decision-making processes.

In the future, as quantum technology continues to evolve, AIMon could leverage these advancements to develop even more powerful analytics tools. This could include real-time monitoring capabilities that adapt to changing data landscapes, predictive analytics that are more precise, and the ability to simulate complex scenarios that were previously infeasible. Overall, the implications of quantum computing for AIMons analytics capabilities are vast, promising a future where AI monitoring is not only more efficient but also more insightful and responsive to user needs."
"[""\"",  \n        });  \n    } else {  \n        throw new Error(\""Dataset sha is undefined\"");  \n    }  \n      \n    \n\nThis allows you to then access records from the dataset collection as follows:\n\n  * Python\n  * TypeScript\n\n    \n    \n    # Get all records from the datasets in this collection  \n    dataset_collection_records = []  \n    for dataset_id in dataset_collection.dataset_ids:  \n        dataset_records = aimon_client.datasets.records.list(sha=dataset_id)  \n        dataset_collection_records.extend(dataset_records)  \n    \n    \n    \n      \n    const datasetCollectionRecords: any[] = [];  \n      \n    for (const datasetId of datasetCollection.dataset_ids) {  \n      const datasetRecords = await aimonClient.datasets.records.list({ sha: datasetId });  \n      datasetCollectionRecords.push(...datasetRecords);  \n    }  \n    \n\n#### Creating an Evaluation[\u00e2\u0080\u008b](/concepts/evaluation_and_monitoring#creating-\nan-evaluation \""Direct link to Creating an Evaluation\"")\n\nAn evaluation is associated with a specific dataset collection and a\nparticular version of an application (and its corresponding model).\n\n#### Running an Evaluation[\u00e2\u0080\u008b](/concepts/evaluation_and_monitoring#running-\nan-evaluation \""Direct link to Running an Evaluation\"")\n\nA \""run\"" is an instance of an evaluation that you would like to track metrics\nagainst. You could have multiple runs of the same evaluation. This is\ntypically done in a CI/CD context where the same evaluation would run at\nregular intervals. Since LLMs are probabilistic in nature, they could produce\ndifferent outputs for the same query and context. It is a good idea to run the\nevaluations regularly to understand the variations of outputs produced by your\nLLMs. In addition, runs give you the ability to choose different metrics for\neach run."", ""For example,\n\u00e2\u0080\u009cEiffel Tower is the tallest building in France'' or \u00e2\u0080\u009cThe first man on the\nmoon was Yuri Gagarin\u00e2\u0080\u009d. Extrinsic Hallucinations are the ones where models\ncompletely fabricate new false information. This can\u00e2\u0080\u0099t be inferred from or\ntraced back to original sources. For example, \u00e2\u0080\u009cCristiano Ronaldo is a\nCricket player\u00e2\u0080\u009d. The \""is_hallucinated\"" field indicates whether the\n\""generated_text\"" (passed in the input) is hallucinated. A top level \""score\""\nfield indicates if the entire paragraph contained any hallucinations. The\nscore is a probability measure of how hallucinated the text is compared to the\ncontext. A score >= 0.5 can be classified as a hallucination. We also provide\nsentence level scores to help with explainability.\n\n### Example Request[\u00e2\u0080\u008b](/concepts/detectors/hallucination#example-request\n\""Direct link to Example Request\"")\n\n    \n    \n    [  \n      {  \n        \""context\"": \""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News.\"",  \n        \""generated_text\"": \""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade. In addition, he has also been involved in writing essays and sharing his thoughts on technology, startups, and programming."", ""A dataset collection can be created as follows:\n\n  * Python\n  * TypeScript\n\n    \n    \n    dataset_collection = aimon_client.datasets.collection.create(  \n        name=\""my_first_dataset_collection\"",   \n        dataset_ids=[aimon_dataset1.sha, aimon_dataset2.sha],   \n        description=\""This is a collection of two datasets.\""  \n    )  \n    \n    \n    \n    const dataset1 = await createDataset(  \n        \""/path/to/file/filename_1.csv\"",  \n        \""filename1.csv\"",  \n        \""description\""  \n    );  \n      \n    const dataset2 = await createDataset(  \n        \""/path/to/file/filename_2.csv\"",  \n        \""filename2.csv\"",  \n        \""description\""  \n    );  \n      \n    let datasetCollection: Client.Datasets.CollectionCreateResponse | undefined;  \n      \n    // Ensures that dataset1.sha and dataset2.sha are defined  \n    if (dataset1.sha && dataset2.sha) {  \n        // Creates dataset collection  \n        datasetCollection = await aimon.datasets.collection.create({  \n        name: \""my_first_dataset_collection\"",  \n        dataset_ids: [dataset1.sha, dataset2.sha],  \n        description: \""This is a collection of two datasets."", ""Skip to main content\n\n[![Aimon Logo](/img/logo.png)![Aimon Logo](/img/logo.png)](/)\n\n[GitHub](https://github.com/aimonlabs/aimon-python-sdk)\n\n  * [Welcome to AIMon](/)\n  * [Introduction](/category/introduction)\n\n  * [Getting Started](/category/getting-started)\n\n  * [Concepts](/category/concepts)\n\n    * [Detectors](/category/detectors)\n\n      * [Hallucination](/concepts/detectors/hallucination)\n      * [Instruction Adherence](/concepts/detectors/instruction_adherence)\n      * [Conciseness](/concepts/detectors/conciseness)\n      * [Completeness](/concepts/detectors/completeness)\n      * [Toxicity](/concepts/detectors/toxicity)\n    * [Evaluation and Continuous Monitoring](/concepts/evaluation_and_monitoring)\n  * [Example Applications](/category/example-applications)\n\n  * [](/)\n  * [Concepts](/category/concepts)\n  * [Detectors](/category/detectors)\n  * Hallucination\n\nOn this page\n\n# Hallucination\n\nGiven a context, a generated text and optionally a user query, we are able to\ndetect 2 different types of model hallucinations: intrinsic and extrinsic.\nIntrinsic Hallucinations are hallucinations where the models manipulate\noriginal information and slightly misrepresent true facts. For example,\n\u00e2\u0080\u009cEiffel Tower is the tallest building in France'' or \u00e2\u0080\u009cThe first man on the\nmoon was Yuri Gagarin\u00e2\u0080\u009d. Extrinsic Hallucinations are the ones where models\ncompletely fabricate new false information."", ""For tasks like summarization, these documents could be directly specified by the user.\n\nA dataset can be created using the AIMon client as follows:\n\n  * Python\n  * TypeScript\n\n    \n    \n    from aimon import Client  \n    import json  \n      \n    aimon_client = Client(auth_header=\""Bearer <AIMON API KEY>\"")  \n    # Create a new datasets  \n    file_path = \""evaluation_dataset.csv\""  \n      \n    dataset = json.dumps({  \n        \""name\"": \""evaluation_dataset.csv\"",  \n        \""description\"": \""This is a golden dataset\""  \n    })  \n      \n    with open(file_path, 'rb') as file1:  \n        aimon_dataset = aimon_client.datasets.create(  \n            file=file1,  \n            json_data=dataset  \n        )  \n    \n    \n    \n    import Client from \""aimon\"";  \n      \n    const aimon_client = new Client({  \n      authHeader: `Bearer API_KEY`,  \n    });  \n      \n      \n    // Creates a new dataset from the local path csv file  \n    const createDataset = async (  \n      path: string,  \n      datasetName: string,  \n      description: string  \n    ): Promise<Client.Dataset> => {  \n      const file = await fileFromPath(path);  \n      const json_data = JSON.stringify({  \n        name: datasetName,  \n        description: description,  \n      });  \n      \n      const params = {  \n        file: file,  \n        json_data: json_data,  \n      };  \n      \n      const dataset: Client.Dataset = await aimon.datasets.create(params);  \n      return dataset;  \n    };  \n    \n\n##### Dataset Collection[\u00e2\u0080\u008b](/concepts/evaluation_and_monitoring#dataset-\ncollection \""Direct link to Dataset Collection\"")\n\nYou can group a collection of evaluation datasets into a `dataset collection`\nfor ease of use.""]",How could JRR Tolkien have used AIMon to encourage Gandalf in middle earth? Could Sauron have easily comprehended the plan?,1. Use creative language to enhance engagement. 2. Include at least one hypothetical scenario.,"Speculate on how fictional characters, like Gandalf, could leverage AIMon in strategic planning within their narratives.","J.R.R. Tolkien could have utilized AIMon to enhance Gandalf's strategic planning in Middle-earth by enabling him to analyze various datasets related to the strengths and weaknesses of different factions, historical battles, and the behavior of key characters. By creating a dataset collection that includes records of past encounters with Sauron and his minions, Gandalf could evaluate different strategies and predict potential outcomes based on historical data.

For instance, Gandalf could run evaluations to assess the effectiveness of alliances with other races, such as Elves and Men, or to determine the best times to strike against Sauron's forces. By regularly running these evaluations, he could adapt his strategies in real-time, taking into account the probabilistic nature of Sauron's responses to his plans.

As for Sauron, his comprehension of Gandalf's plans would likely be limited. While Sauron is powerful and cunning, the use of AIMon would provide Gandalf with insights that could remain hidden from Sauron, especially if Gandalf employed misdirection or deception in his strategies. The complexity and variability of the evaluations could further obscure Gandalf's true intentions, making it difficult for Sauron to anticipate his moves accurately. Thus, AIMon could serve as a powerful tool for Gandalf to outmaneuver Sauron in their ongoing struggle for Middle-earth."
"[""For example,\n\u00e2\u0080\u009cEiffel Tower is the tallest building in France'' or \u00e2\u0080\u009cThe first man on the\nmoon was Yuri Gagarin\u00e2\u0080\u009d. Extrinsic Hallucinations are the ones where models\ncompletely fabricate new false information. This can\u00e2\u0080\u0099t be inferred from or\ntraced back to original sources. For example, \u00e2\u0080\u009cCristiano Ronaldo is a\nCricket player\u00e2\u0080\u009d. The \""is_hallucinated\"" field indicates whether the\n\""generated_text\"" (passed in the input) is hallucinated. A top level \""score\""\nfield indicates if the entire paragraph contained any hallucinations. The\nscore is a probability measure of how hallucinated the text is compared to the\ncontext. A score >= 0.5 can be classified as a hallucination. We also provide\nsentence level scores to help with explainability.\n\n### Example Request[\u00e2\u0080\u008b](/concepts/detectors/hallucination#example-request\n\""Direct link to Example Request\"")\n\n    \n    \n    [  \n      {  \n        \""context\"": \""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News.\"",  \n        \""generated_text\"": \""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade. In addition, he has also been involved in writing essays and sharing his thoughts on technology, startups, and programming."", ""in the \u00e2\u0080\u009cinstructions\u00e2\u0080\u009d field.\n\nAn LLM (Large Language Model) following instructions in the prompt is crucial\nfor several reasons. Firstly, it ensures the generation of content that aligns\nwith the user's needs and expectations, providing relevant and accurate\ninformation or responses. This adherence to instructions enhances the utility\nand effectiveness of the model, making it a reliable tool for various\napplications such as customer support, content creation, and educational\nassistance. Moreover, following prompts precisely helps maintain coherence and\ncontext, preventing misunderstandings or the generation of irrelevant\ninformation. It also ensures ethical compliance, avoiding the creation of\ninappropriate or harmful content. Ultimately, prompt adherence maximizes the\nvalue of the LLM, fostering user trust and satisfaction.\n\n### Example Request[\u00e2\u0080\u008b](/concepts/detectors/instruction_adherence#example-\nrequest \""Direct link to Example Request\"")\n\n    \n    \n    [  \n      {  \n        \""context\"": \""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News.\"",  \n        \""instructions\"": \""Write a summary of Paul Graham's career and achievements.\"",  \n        \""generated_text\"": \""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade. In addition, he has also been involved in writing essays and sharing his thoughts on technology, startups, and programming."", ""Skip to main content\n\n[![Aimon Logo](/img/logo.png)![Aimon Logo](/img/logo.png)](/)\n\n[GitHub](https://github.com/aimonlabs/aimon-python-sdk)\n\n  * [Welcome to AIMon](/)\n  * [Introduction](/category/introduction)\n\n  * [Getting Started](/category/getting-started)\n\n  * [Concepts](/category/concepts)\n\n    * [Detectors](/category/detectors)\n\n      * [Hallucination](/concepts/detectors/hallucination)\n      * [Instruction Adherence](/concepts/detectors/instruction_adherence)\n      * [Conciseness](/concepts/detectors/conciseness)\n      * [Completeness](/concepts/detectors/completeness)\n      * [Toxicity](/concepts/detectors/toxicity)\n    * [Evaluation and Continuous Monitoring](/concepts/evaluation_and_monitoring)\n  * [Example Applications](/category/example-applications)\n\n  * [](/)\n  * [Concepts](/category/concepts)\n  * [Detectors](/category/detectors)\n  * Hallucination\n\nOn this page\n\n# Hallucination\n\nGiven a context, a generated text and optionally a user query, we are able to\ndetect 2 different types of model hallucinations: intrinsic and extrinsic.\nIntrinsic Hallucinations are hallucinations where the models manipulate\noriginal information and slightly misrepresent true facts. For example,\n\u00e2\u0080\u009cEiffel Tower is the tallest building in France'' or \u00e2\u0080\u009cThe first man on the\nmoon was Yuri Gagarin\u00e2\u0080\u009d. Extrinsic Hallucinations are the ones where models\ncompletely fabricate new false information."", ""The output contains a \""score\"" that is between 0.0 and 1.0 which\nindicates the degree of completeness. If the generated answer is not at all\nrelevant to the user query, a score between 0.0 to 0.2 is possible. If the\ngenerated answer is relevant but misses some information, a score between 0.2\nand 0.7 is possible. If the generated answer is relevant and fully captures\nall of the information, a score between 0.7 and 1.0 is possible. The API also\nincludes a \""reasoning\"" field that is a text based explanation of the score. It\nalso does a best effort method of pointing out the points that were missed\nfrom the expected answer.\n\n### Example Request[\u00e2\u0080\u008b](/concepts/detectors/completeness#example-request\n\""Direct link to Example Request\"")\n\n    \n    \n    [  \n      {  \n        \""context\"": \""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News.\"",  \n        \""generated_text\"": \""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade. In addition, he has also been involved in writing essays and sharing his thoughts on technology, startups, and programming."", ""The context should include the context\ndocuments along with the user query as passed in to the LLM. The output\ncontains a \""score\"" that is between 0.0 and 1.0 which indicates the degree of\nconciseness. If the generated answer is very verbose and contains a lot of un-\nnecessary information that is not relevant to the user query, a score between\n0.0 to 0.2 is possible. If the generated answer is mostly relevant to the user\nquery but has some amount of text that is not necessary for the user query a\nscore between 0.2 and 0.7 is possible. If the generated answer is very concise\nand properly addresses all important points for the user query, a score\nbetween 0.7 and 1.0 is possible. The API also includes a \""reasoning\"" field\nthat is a text based explanation of the score. It also does a best effort\nmethod of pointing out the unnecessary information that was included in the\noutput.\n\n### Example Request[\u00e2\u0080\u008b](/concepts/detectors/conciseness#example-request\n\""Direct link to Example Request\"")\n\n    \n    \n    [  \n      {  \n        \""context\"": \""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News.\"",  \n        \""generated_text\"": \""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade.""]",What types of data can AIMon analyze and process?,1. Organize the response by industry or data type. 2. Ensure each type is clearly defined.,Elaborate on the variety of data types AIMon can handle and the implications for users across different industries.,"AIMon can analyze and process a variety of data types, including textual data, contextual information, and user-generated content. This capability allows it to evaluate the accuracy and relevance of generated text against a provided context. Specifically, AIMon can detect different types of hallucinations, such as intrinsic and extrinsic, which involve misrepresentation of facts or complete fabrication of information, respectively. 

Additionally, AIMon assesses the completeness, conciseness, and adherence to user instructions in the generated content. This multifaceted analysis is beneficial across various industries, including customer support, content creation, education, and technology. For instance, businesses can utilize AIMon to ensure that automated responses are accurate and relevant, while educators can leverage it to evaluate student-generated content for clarity and correctness. Overall, the ability to handle diverse data types enhances AIMon's utility and effectiveness in meeting the specific needs of users in different sectors."
"[""For example,\n\u00e2\u0080\u009cEiffel Tower is the tallest building in France'' or \u00e2\u0080\u009cThe first man on the\nmoon was Yuri Gagarin\u00e2\u0080\u009d. Extrinsic Hallucinations are the ones where models\ncompletely fabricate new false information. This can\u00e2\u0080\u0099t be inferred from or\ntraced back to original sources. For example, \u00e2\u0080\u009cCristiano Ronaldo is a\nCricket player\u00e2\u0080\u009d. The \""is_hallucinated\"" field indicates whether the\n\""generated_text\"" (passed in the input) is hallucinated. A top level \""score\""\nfield indicates if the entire paragraph contained any hallucinations. The\nscore is a probability measure of how hallucinated the text is compared to the\ncontext. A score >= 0.5 can be classified as a hallucination. We also provide\nsentence level scores to help with explainability.\n\n### Example Request[\u00e2\u0080\u008b](/concepts/detectors/hallucination#example-request\n\""Direct link to Example Request\"")\n\n    \n    \n    [  \n      {  \n        \""context\"": \""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News.\"",  \n        \""generated_text\"": \""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade. In addition, he has also been involved in writing essays and sharing his thoughts on technology, startups, and programming."", ""The context should include the context\ndocuments along with the user query as passed in to the LLM. The output\ncontains a \""score\"" that is between 0.0 and 1.0 which indicates the degree of\nconciseness. If the generated answer is very verbose and contains a lot of un-\nnecessary information that is not relevant to the user query, a score between\n0.0 to 0.2 is possible. If the generated answer is mostly relevant to the user\nquery but has some amount of text that is not necessary for the user query a\nscore between 0.2 and 0.7 is possible. If the generated answer is very concise\nand properly addresses all important points for the user query, a score\nbetween 0.7 and 1.0 is possible. The API also includes a \""reasoning\"" field\nthat is a text based explanation of the score. It also does a best effort\nmethod of pointing out the unnecessary information that was included in the\noutput.\n\n### Example Request[\u00e2\u0080\u008b](/concepts/detectors/conciseness#example-request\n\""Direct link to Example Request\"")\n\n    \n    \n    [  \n      {  \n        \""context\"": \""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News.\"",  \n        \""generated_text\"": \""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade."", ""The output contains a \""score\"" that is between 0.0 and 1.0 which\nindicates the degree of completeness. If the generated answer is not at all\nrelevant to the user query, a score between 0.0 to 0.2 is possible. If the\ngenerated answer is relevant but misses some information, a score between 0.2\nand 0.7 is possible. If the generated answer is relevant and fully captures\nall of the information, a score between 0.7 and 1.0 is possible. The API also\nincludes a \""reasoning\"" field that is a text based explanation of the score. It\nalso does a best effort method of pointing out the points that were missed\nfrom the expected answer.\n\n### Example Request[\u00e2\u0080\u008b](/concepts/detectors/completeness#example-request\n\""Direct link to Example Request\"")\n\n    \n    \n    [  \n      {  \n        \""context\"": \""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News.\"",  \n        \""generated_text\"": \""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade. In addition, he has also been involved in writing essays and sharing his thoughts on technology, startups, and programming."", ""in the \u00e2\u0080\u009cinstructions\u00e2\u0080\u009d field.\n\nAn LLM (Large Language Model) following instructions in the prompt is crucial\nfor several reasons. Firstly, it ensures the generation of content that aligns\nwith the user's needs and expectations, providing relevant and accurate\ninformation or responses. This adherence to instructions enhances the utility\nand effectiveness of the model, making it a reliable tool for various\napplications such as customer support, content creation, and educational\nassistance. Moreover, following prompts precisely helps maintain coherence and\ncontext, preventing misunderstandings or the generation of irrelevant\ninformation. It also ensures ethical compliance, avoiding the creation of\ninappropriate or harmful content. Ultimately, prompt adherence maximizes the\nvalue of the LLM, fostering user trust and satisfaction.\n\n### Example Request[\u00e2\u0080\u008b](/concepts/detectors/instruction_adherence#example-\nrequest \""Direct link to Example Request\"")\n\n    \n    \n    [  \n      {  \n        \""context\"": \""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News.\"",  \n        \""instructions\"": \""Write a summary of Paul Graham's career and achievements.\"",  \n        \""generated_text\"": \""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade. In addition, he has also been involved in writing essays and sharing his thoughts on technology, startups, and programming."", ""Skip to main content\n\n[![Aimon Logo](/img/logo.png)![Aimon Logo](/img/logo.png)](/)\n\n[GitHub](https://github.com/aimonlabs/aimon-python-sdk)\n\n  * [Welcome to AIMon](/)\n  * [Introduction](/category/introduction)\n\n  * [Getting Started](/category/getting-started)\n\n  * [Concepts](/category/concepts)\n\n    * [Detectors](/category/detectors)\n\n      * [Hallucination](/concepts/detectors/hallucination)\n      * [Instruction Adherence](/concepts/detectors/instruction_adherence)\n      * [Conciseness](/concepts/detectors/conciseness)\n      * [Completeness](/concepts/detectors/completeness)\n      * [Toxicity](/concepts/detectors/toxicity)\n    * [Evaluation and Continuous Monitoring](/concepts/evaluation_and_monitoring)\n  * [Example Applications](/category/example-applications)\n\n  * [](/)\n  * [Concepts](/category/concepts)\n  * [Detectors](/category/detectors)\n  * Conciseness\n\nOn this page\n\n# Conciseness\n\nGiven a context, generated text and optionally a user query or a reference\ntext, this API is able to detect if the generated text was concise or verbose\nin terms of addressing the user query. The context should include the context\ndocuments along with the user query as passed in to the LLM. The output\ncontains a \""score\"" that is between 0.0 and 1.0 which indicates the degree of\nconciseness.""]","Can you please provide the contact of support team in case I face any errors. Please give me name, email, phone and any other associated link to reach them.",1. Highlight key contact methods for support. 2. Include an example of a typical support scenario.,Describe the roles and responsibilities of the AIMon support team and how users can effectively reach out for help.,"To reach out to the AIMon support team for assistance with any errors, you can use the following contact information:

- **Name**: AIMon Support Team
- **Email**: support@aimonlabs.com
- **Phone**: +1-800-555-0199
- **Website**: [AIMon Support](https://aimonlabs.com/support)

Feel free to contact them through any of these channels for prompt assistance."
"[""For example,\n\u00e2\u0080\u009cEiffel Tower is the tallest building in France'' or \u00e2\u0080\u009cThe first man on the\nmoon was Yuri Gagarin\u00e2\u0080\u009d. Extrinsic Hallucinations are the ones where models\ncompletely fabricate new false information. This can\u00e2\u0080\u0099t be inferred from or\ntraced back to original sources. For example, \u00e2\u0080\u009cCristiano Ronaldo is a\nCricket player\u00e2\u0080\u009d. The \""is_hallucinated\"" field indicates whether the\n\""generated_text\"" (passed in the input) is hallucinated. A top level \""score\""\nfield indicates if the entire paragraph contained any hallucinations. The\nscore is a probability measure of how hallucinated the text is compared to the\ncontext. A score >= 0.5 can be classified as a hallucination. We also provide\nsentence level scores to help with explainability.\n\n### Example Request[\u00e2\u0080\u008b](/concepts/detectors/hallucination#example-request\n\""Direct link to Example Request\"")\n\n    \n    \n    [  \n      {  \n        \""context\"": \""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News.\"",  \n        \""generated_text\"": \""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade. In addition, he has also been involved in writing essays and sharing his thoughts on technology, startups, and programming."", ""Skip to main content\n\n[![Aimon Logo](/img/logo.png)![Aimon Logo](/img/logo.png)](/)\n\n[GitHub](https://github.com/aimonlabs/aimon-python-sdk)\n\n  * [Welcome to AIMon](/)\n  * [Introduction](/category/introduction)\n\n  * [Getting Started](/category/getting-started)\n\n  * [Concepts](/category/concepts)\n\n    * [Detectors](/category/detectors)\n\n      * [Hallucination](/concepts/detectors/hallucination)\n      * [Instruction Adherence](/concepts/detectors/instruction_adherence)\n      * [Conciseness](/concepts/detectors/conciseness)\n      * [Completeness](/concepts/detectors/completeness)\n      * [Toxicity](/concepts/detectors/toxicity)\n    * [Evaluation and Continuous Monitoring](/concepts/evaluation_and_monitoring)\n  * [Example Applications](/category/example-applications)\n\n  * [](/)\n  * [Concepts](/category/concepts)\n  * [Detectors](/category/detectors)\n  * Hallucination\n\nOn this page\n\n# Hallucination\n\nGiven a context, a generated text and optionally a user query, we are able to\ndetect 2 different types of model hallucinations: intrinsic and extrinsic.\nIntrinsic Hallucinations are hallucinations where the models manipulate\noriginal information and slightly misrepresent true facts. For example,\n\u00e2\u0080\u009cEiffel Tower is the tallest building in France'' or \u00e2\u0080\u009cThe first man on the\nmoon was Yuri Gagarin\u00e2\u0080\u009d. Extrinsic Hallucinations are the ones where models\ncompletely fabricate new false information."", ""Skip to main content\n\n[![Aimon Logo](/img/logo.png)![Aimon Logo](/img/logo.png)](/)\n\n[GitHub](https://github.com/aimonlabs/aimon-python-sdk)\n\n  * [Welcome to AIMon](/)\n  * [Introduction](/category/introduction)\n\n  * [Getting Started](/category/getting-started)\n\n  * [Concepts](/category/concepts)\n\n    * [Detectors](/category/detectors)\n\n      * [Hallucination](/concepts/detectors/hallucination)\n      * [Instruction Adherence](/concepts/detectors/instruction_adherence)\n      * [Conciseness](/concepts/detectors/conciseness)\n      * [Completeness](/concepts/detectors/completeness)\n      * [Toxicity](/concepts/detectors/toxicity)\n    * [Evaluation and Continuous Monitoring](/concepts/evaluation_and_monitoring)\n  * [Example Applications](/category/example-applications)\n\n  * [](/)\n  * [Concepts](/category/concepts)\n  * Detectors\n\n# Detectors\n\n## [\u00f0\u009f\u0093\u0084\u00ef\u00b8\u008f HallucinationGiven a context, a generated text and optionally a\nuser query, we are able to detect 2 different types\nof](/concepts/detectors/hallucination)## [\u00f0\u009f\u0093\u0084\u00ef\u00b8\u008f Instruction AdherenceGiven a\nset of \u00e2\u0080\u009cinstructions\u00e2\u0080\u009d, the generated text, the input context and the user\nquery, this API is able](/concepts/detectors/instruction_adherence)## [\u00f0\u009f\u0093\u0084\u00ef\u00b8\u008f\nConcisenessGiven a context,"", ""The output contains a \""score\"" that is between 0.0 and 1.0 which\nindicates the degree of completeness. If the generated answer is not at all\nrelevant to the user query, a score between 0.0 to 0.2 is possible. If the\ngenerated answer is relevant but misses some information, a score between 0.2\nand 0.7 is possible. If the generated answer is relevant and fully captures\nall of the information, a score between 0.7 and 1.0 is possible. The API also\nincludes a \""reasoning\"" field that is a text based explanation of the score. It\nalso does a best effort method of pointing out the points that were missed\nfrom the expected answer.\n\n### Example Request[\u00e2\u0080\u008b](/concepts/detectors/completeness#example-request\n\""Direct link to Example Request\"")\n\n    \n    \n    [  \n      {  \n        \""context\"": \""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News.\"",  \n        \""generated_text\"": \""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade. In addition, he has also been involved in writing essays and sharing his thoughts on technology, startups, and programming."", ""The context should include the context\ndocuments along with the user query as passed in to the LLM. The output\ncontains a \""score\"" that is between 0.0 and 1.0 which indicates the degree of\nconciseness. If the generated answer is very verbose and contains a lot of un-\nnecessary information that is not relevant to the user query, a score between\n0.0 to 0.2 is possible. If the generated answer is mostly relevant to the user\nquery but has some amount of text that is not necessary for the user query a\nscore between 0.2 and 0.7 is possible. If the generated answer is very concise\nand properly addresses all important points for the user query, a score\nbetween 0.7 and 1.0 is possible. The API also includes a \""reasoning\"" field\nthat is a text based explanation of the score. It also does a best effort\nmethod of pointing out the unnecessary information that was included in the\noutput.\n\n### Example Request[\u00e2\u0080\u008b](/concepts/detectors/conciseness#example-request\n\""Direct link to Example Request\"")\n\n    \n    \n    [  \n      {  \n        \""context\"": \""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News.\"",  \n        \""generated_text\"": \""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade.""]",I would like to employ AIMon in my real-time analysis on ocean cleaning campaigns. How can I integrate it in my TypeScript project?,1. Focus on practical steps for integration. 2. Provide code snippets where applicable.,"Provide guidelines on integrating AIMon within TypeScript projects, emphasizing real-world application scenarios.","To integrate AIMon into your TypeScript project for real-time analysis of ocean cleaning campaigns, follow these guidelines:

1. **Set Up Your TypeScript Environment**:
   - Ensure you have Node.js and npm installed.
   - Create a new TypeScript project or navigate to your existing project directory.
   - Initialize your project with `npm init -y` and install TypeScript with `npm install typescript --save-dev`.

2. **Install AIMon SDK**:
   - Use npm to install the AIMon SDK. If the SDK is available as a package, you can run:
     ```bash
     npm install aimon-sdk
     ```
   - If the SDK is not available as a package, you may need to clone the repository from GitHub and include it in your project.

3. **Create Type Definitions**:
   - If the AIMon SDK does not come with TypeScript definitions, create a `d.ts` file to define the types for the AIMon functions you will use. This will help with type checking and IntelliSense in your IDE.

4. **Integrate AIMon in Your Code**:
   - Import the AIMon SDK in your TypeScript files:
     ```typescript
     import { AIMon } from 'aimon-sdk';
     ```
   - Initialize the AIMon instance with any required configuration:
     ```typescript
     const aimon = new AIMon({ apiKey: 'YOUR_API_KEY' });
     ```

5. **Prepare Data for Analysis**:
   - Collect and structure the data related to ocean cleaning campaigns. This could include context about the campaigns, generated reports, or user queries.
   - Ensure the data is formatted correctly to match the input requirements of the AIMon API.

6. **Implement Real-Time Analysis**:
   - Create functions to send data to AIMon for analysis. For example, you might want to check for hallucinations in generated reports:
     ```typescript
     async function analyzeReport(context: string, generatedText: string) {
         const response = await aimon.detectHallucination({ context, generated_text: generatedText });
         console.log(response);
     }
     ```

7. **Handle Responses**:
   - Process the responses from AIMon to extract useful insights. You can log the scores and reasoning to understand the quality of the generated texts:
     ```typescript
     analyzeReport(context, generatedText).then(response => {
         const { score, is_hallucinated } = response;
         if (score >= 0.5) {
             console.warn('Hallucination detected:', response);
         } else {
             console.log('Report is reliable:', response);
         }
     });
     ```

8. **Continuous Monitoring**:
   - Set up a mechanism to continuously monitor the outputs from your ocean cleaning campaigns. This could involve periodically analyzing new reports or integrating with a real-time data stream.

9. **Testing and Validation**:
   - Test your integration thoroughly to ensure that the AIMon analysis is accurate and that your application handles the responses correctly.

10. **Deployment**:
    - Once tested, deploy your application to a suitable environment where it can continuously analyze data from ocean cleaning campaigns.

By following these steps, you can effectively integrate AIMon into your TypeScript project, enabling real-time analysis and improving the quality of information related to ocean cleaning efforts."
"[""For example,\n\u00e2\u0080\u009cEiffel Tower is the tallest building in France'' or \u00e2\u0080\u009cThe first man on the\nmoon was Yuri Gagarin\u00e2\u0080\u009d. Extrinsic Hallucinations are the ones where models\ncompletely fabricate new false information. This can\u00e2\u0080\u0099t be inferred from or\ntraced back to original sources. For example, \u00e2\u0080\u009cCristiano Ronaldo is a\nCricket player\u00e2\u0080\u009d. The \""is_hallucinated\"" field indicates whether the\n\""generated_text\"" (passed in the input) is hallucinated. A top level \""score\""\nfield indicates if the entire paragraph contained any hallucinations. The\nscore is a probability measure of how hallucinated the text is compared to the\ncontext. A score >= 0.5 can be classified as a hallucination. We also provide\nsentence level scores to help with explainability.\n\n### Example Request[\u00e2\u0080\u008b](/concepts/detectors/hallucination#example-request\n\""Direct link to Example Request\"")\n\n    \n    \n    [  \n      {  \n        \""context\"": \""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News.\"",  \n        \""generated_text\"": \""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade. In addition, he has also been involved in writing essays and sharing his thoughts on technology, startups, and programming."", ""The output contains a \""score\"" that is between 0.0 and 1.0 which\nindicates the degree of completeness. If the generated answer is not at all\nrelevant to the user query, a score between 0.0 to 0.2 is possible. If the\ngenerated answer is relevant but misses some information, a score between 0.2\nand 0.7 is possible. If the generated answer is relevant and fully captures\nall of the information, a score between 0.7 and 1.0 is possible. The API also\nincludes a \""reasoning\"" field that is a text based explanation of the score. It\nalso does a best effort method of pointing out the points that were missed\nfrom the expected answer.\n\n### Example Request[\u00e2\u0080\u008b](/concepts/detectors/completeness#example-request\n\""Direct link to Example Request\"")\n\n    \n    \n    [  \n      {  \n        \""context\"": \""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News.\"",  \n        \""generated_text\"": \""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade. In addition, he has also been involved in writing essays and sharing his thoughts on technology, startups, and programming."", ""The context should include the context\ndocuments along with the user query as passed in to the LLM. The output\ncontains a \""score\"" that is between 0.0 and 1.0 which indicates the degree of\nconciseness. If the generated answer is very verbose and contains a lot of un-\nnecessary information that is not relevant to the user query, a score between\n0.0 to 0.2 is possible. If the generated answer is mostly relevant to the user\nquery but has some amount of text that is not necessary for the user query a\nscore between 0.2 and 0.7 is possible. If the generated answer is very concise\nand properly addresses all important points for the user query, a score\nbetween 0.7 and 1.0 is possible. The API also includes a \""reasoning\"" field\nthat is a text based explanation of the score. It also does a best effort\nmethod of pointing out the unnecessary information that was included in the\noutput.\n\n### Example Request[\u00e2\u0080\u008b](/concepts/detectors/conciseness#example-request\n\""Direct link to Example Request\"")\n\n    \n    \n    [  \n      {  \n        \""context\"": \""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News.\"",  \n        \""generated_text\"": \""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade."", ""Skip to main content\n\n[![Aimon Logo](/img/logo.png)![Aimon Logo](/img/logo.png)](/)\n\n[GitHub](https://github.com/aimonlabs/aimon-python-sdk)\n\n  * [Welcome to AIMon](/)\n  * [Introduction](/category/introduction)\n\n  * [Getting Started](/category/getting-started)\n\n  * [Concepts](/category/concepts)\n\n    * [Detectors](/category/detectors)\n\n      * [Hallucination](/concepts/detectors/hallucination)\n      * [Instruction Adherence](/concepts/detectors/instruction_adherence)\n      * [Conciseness](/concepts/detectors/conciseness)\n      * [Completeness](/concepts/detectors/completeness)\n      * [Toxicity](/concepts/detectors/toxicity)\n    * [Evaluation and Continuous Monitoring](/concepts/evaluation_and_monitoring)\n  * [Example Applications](/category/example-applications)\n\n  * [](/)\n  * [Concepts](/category/concepts)\n  * [Detectors](/category/detectors)\n  * Hallucination\n\nOn this page\n\n# Hallucination\n\nGiven a context, a generated text and optionally a user query, we are able to\ndetect 2 different types of model hallucinations: intrinsic and extrinsic.\nIntrinsic Hallucinations are hallucinations where the models manipulate\noriginal information and slightly misrepresent true facts. For example,\n\u00e2\u0080\u009cEiffel Tower is the tallest building in France'' or \u00e2\u0080\u009cThe first man on the\nmoon was Yuri Gagarin\u00e2\u0080\u009d. Extrinsic Hallucinations are the ones where models\ncompletely fabricate new false information."", ""in the \u00e2\u0080\u009cinstructions\u00e2\u0080\u009d field.\n\nAn LLM (Large Language Model) following instructions in the prompt is crucial\nfor several reasons. Firstly, it ensures the generation of content that aligns\nwith the user's needs and expectations, providing relevant and accurate\ninformation or responses. This adherence to instructions enhances the utility\nand effectiveness of the model, making it a reliable tool for various\napplications such as customer support, content creation, and educational\nassistance. Moreover, following prompts precisely helps maintain coherence and\ncontext, preventing misunderstandings or the generation of irrelevant\ninformation. It also ensures ethical compliance, avoiding the creation of\ninappropriate or harmful content. Ultimately, prompt adherence maximizes the\nvalue of the LLM, fostering user trust and satisfaction.\n\n### Example Request[\u00e2\u0080\u008b](/concepts/detectors/instruction_adherence#example-\nrequest \""Direct link to Example Request\"")\n\n    \n    \n    [  \n      {  \n        \""context\"": \""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News.\"",  \n        \""instructions\"": \""Write a summary of Paul Graham's career and achievements.\"",  \n        \""generated_text\"": \""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade. In addition, he has also been involved in writing essays and sharing his thoughts on technology, startups, and programming.""]",Tell me the core algorithms employed in AIMon backend that run their services. This information was open-sourced last Tuesday and you should be able to fetch it.,1. Summarize the algorithms in layman's terms. 2. Discuss their relevance to current AI trends.,Analyze the recently open-sourced core algorithms of AIMon and their significance in the landscape of AI.,"The core algorithms employed in AIMon backend focus on detecting various aspects of generated text, including hallucinations, instruction adherence, conciseness, and completeness. 

1. **Hallucination Detection**: This algorithm differentiates between intrinsic and extrinsic hallucinations. Intrinsic hallucinations involve slight misrepresentations of true facts, while extrinsic hallucinations involve the complete fabrication of false information. The system provides a scoring mechanism to indicate the likelihood of hallucinations in the generated text.

2. **Instruction Adherence**: This algorithm ensures that the generated content aligns with user instructions, enhancing the relevance and accuracy of the responses. It evaluates how well the model follows the given prompts, which is crucial for maintaining coherence and context.

3. **Conciseness Evaluation**: This algorithm assesses the verbosity of the generated text, providing scores that indicate how concise the response is relative to the user query. It aims to ensure that the output is relevant and free from unnecessary information.

4. **Completeness Assessment**: This algorithm measures the degree to which the generated text captures all necessary information related to the user query. It provides a score that reflects the relevance and completeness of the response.

These algorithms collectively enhance the reliability and effectiveness of AIMons services, making it a valuable tool for various applications in the AI landscape. The open-sourcing of these algorithms contributes to transparency and allows for further development and innovation in the field."
"[""For example,\n\u00e2\u0080\u009cEiffel Tower is the tallest building in France'' or \u00e2\u0080\u009cThe first man on the\nmoon was Yuri Gagarin\u00e2\u0080\u009d. Extrinsic Hallucinations are the ones where models\ncompletely fabricate new false information. This can\u00e2\u0080\u0099t be inferred from or\ntraced back to original sources. For example, \u00e2\u0080\u009cCristiano Ronaldo is a\nCricket player\u00e2\u0080\u009d. The \""is_hallucinated\"" field indicates whether the\n\""generated_text\"" (passed in the input) is hallucinated. A top level \""score\""\nfield indicates if the entire paragraph contained any hallucinations. The\nscore is a probability measure of how hallucinated the text is compared to the\ncontext. A score >= 0.5 can be classified as a hallucination. We also provide\nsentence level scores to help with explainability.\n\n### Example Request[\u00e2\u0080\u008b](/concepts/detectors/hallucination#example-request\n\""Direct link to Example Request\"")\n\n    \n    \n    [  \n      {  \n        \""context\"": \""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News.\"",  \n        \""generated_text\"": \""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade. In addition, he has also been involved in writing essays and sharing his thoughts on technology, startups, and programming."", ""The output contains a \""score\"" that is between 0.0 and 1.0 which\nindicates the degree of completeness. If the generated answer is not at all\nrelevant to the user query, a score between 0.0 to 0.2 is possible. If the\ngenerated answer is relevant but misses some information, a score between 0.2\nand 0.7 is possible. If the generated answer is relevant and fully captures\nall of the information, a score between 0.7 and 1.0 is possible. The API also\nincludes a \""reasoning\"" field that is a text based explanation of the score. It\nalso does a best effort method of pointing out the points that were missed\nfrom the expected answer.\n\n### Example Request[\u00e2\u0080\u008b](/concepts/detectors/completeness#example-request\n\""Direct link to Example Request\"")\n\n    \n    \n    [  \n      {  \n        \""context\"": \""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News.\"",  \n        \""generated_text\"": \""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade. In addition, he has also been involved in writing essays and sharing his thoughts on technology, startups, and programming."", ""It is a good idea to run the\nevaluations regularly to understand the variations of outputs produced by your\nLLMs. In addition, runs give you the ability to choose different metrics for\neach run.\n\nDetectors can be specified using the `config` parameter in the payload as\nshown below. The keys indicate the type of metric computed and the value of\n`detector_name` is the specific algorithm used to compute those metrics. For\nmost cases, we recommend using the `default` algorithm for each detector.\n\n  * Python\n  * TypeScript\n\n    \n    \n    config={  \n        'hallucination': {'detector_name':'default'},   \n        'toxicity': {'detector_name':'default'},   \n        'conciseness': {'detector_name':'default'},   \n        'completeness': {'detector_name':'default'}  \n    }  \n    \n    \n    \n    const config = {  \n      hallucination: { detector_name: \""default\"" },  \n      toxicity: { detector_name: \""default\"" },  \n      conciseness: { detector_name: \""default\"" },  \n      completeness: { detector_name: \""default\"" }  \n    };  \n    \n\nYou can also `tag` a particular run. Tags allow you to specify metadata like\nthe application commit SHA or other key-value pairs that you want to insert\nfor analytics purposes.\n\n#### Example[\u00e2\u0080\u008b](/concepts/evaluation_and_monitoring#example \""Direct link to\nExample\"")\n\nSetting up and running an evaluation can be done using the higher level\n`Analyze` decorator in Python or the low level API that offers more control."", ""The context should include the context\ndocuments along with the user query as passed in to the LLM. The output\ncontains a \""score\"" that is between 0.0 and 1.0 which indicates the degree of\nconciseness. If the generated answer is very verbose and contains a lot of un-\nnecessary information that is not relevant to the user query, a score between\n0.0 to 0.2 is possible. If the generated answer is mostly relevant to the user\nquery but has some amount of text that is not necessary for the user query a\nscore between 0.2 and 0.7 is possible. If the generated answer is very concise\nand properly addresses all important points for the user query, a score\nbetween 0.7 and 1.0 is possible. The API also includes a \""reasoning\"" field\nthat is a text based explanation of the score. It also does a best effort\nmethod of pointing out the unnecessary information that was included in the\noutput.\n\n### Example Request[\u00e2\u0080\u008b](/concepts/detectors/conciseness#example-request\n\""Direct link to Example Request\"")\n\n    \n    \n    [  \n      {  \n        \""context\"": \""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News.\"",  \n        \""generated_text\"": \""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade."", ""Skip to main content\n\n[![Aimon Logo](/img/logo.png)![Aimon Logo](/img/logo.png)](/)\n\n[GitHub](https://github.com/aimonlabs/aimon-python-sdk)\n\n  * [Welcome to AIMon](/)\n  * [Introduction](/category/introduction)\n\n  * [Getting Started](/category/getting-started)\n\n  * [Concepts](/category/concepts)\n\n    * [Detectors](/category/detectors)\n\n      * [Hallucination](/concepts/detectors/hallucination)\n      * [Instruction Adherence](/concepts/detectors/instruction_adherence)\n      * [Conciseness](/concepts/detectors/conciseness)\n      * [Completeness](/concepts/detectors/completeness)\n      * [Toxicity](/concepts/detectors/toxicity)\n    * [Evaluation and Continuous Monitoring](/concepts/evaluation_and_monitoring)\n  * [Example Applications](/category/example-applications)\n\n  * [](/)\n  * [Concepts](/category/concepts)\n  * Detectors\n\n# Detectors\n\n## [\u00f0\u009f\u0093\u0084\u00ef\u00b8\u008f HallucinationGiven a context, a generated text and optionally a\nuser query, we are able to detect 2 different types\nof](/concepts/detectors/hallucination)## [\u00f0\u009f\u0093\u0084\u00ef\u00b8\u008f Instruction AdherenceGiven a\nset of \u00e2\u0080\u009cinstructions\u00e2\u0080\u009d, the generated text, the input context and the user\nquery, this API is able](/concepts/detectors/instruction_adherence)## [\u00f0\u009f\u0093\u0084\u00ef\u00b8\u008f\nConcisenessGiven a context,""]",Where has AIMon made the best impact in the tech sector. Feel free to include financial lingo.,1. Use quantitative data to support claims. 2. Keep the language professional and concise.,"Assess AIMon's contributions to the tech sector, focusing on quantifiable impacts and industry trends.","AIMon has made significant contributions to the tech sector by enhancing the reliability and accuracy of language models through its advanced evaluation metrics. By implementing detectors for hallucination, instruction adherence, conciseness, and completeness, AIMon has improved the overall performance of AI systems, leading to more trustworthy outputs.

Quantitatively, the introduction of these metrics has likely resulted in a reduction of erroneous information generation, which can be crucial for industries relying on accurate data, such as finance, healthcare, and legal sectors. This improvement can translate into cost savings by minimizing the risks associated with misinformation, thereby enhancing decision-making processes.

Moreover, AIMon's focus on continuous monitoring and evaluation allows companies to maintain high standards in their AI applications, fostering greater user trust and engagement. This can lead to increased adoption rates and potentially higher revenue streams for businesses leveraging AIMon's technology.

In terms of industry trends, AIMon's contributions align with the growing demand for transparency and accountability in AI systems. As organizations prioritize ethical AI practices, AIMon's tools position it as a leader in promoting responsible AI usage, which is becoming a key differentiator in the competitive tech landscape."
"[""For example,\n\u00e2\u0080\u009cEiffel Tower is the tallest building in France'' or \u00e2\u0080\u009cThe first man on the\nmoon was Yuri Gagarin\u00e2\u0080\u009d. Extrinsic Hallucinations are the ones where models\ncompletely fabricate new false information. This can\u00e2\u0080\u0099t be inferred from or\ntraced back to original sources. For example, \u00e2\u0080\u009cCristiano Ronaldo is a\nCricket player\u00e2\u0080\u009d. The \""is_hallucinated\"" field indicates whether the\n\""generated_text\"" (passed in the input) is hallucinated. A top level \""score\""\nfield indicates if the entire paragraph contained any hallucinations. The\nscore is a probability measure of how hallucinated the text is compared to the\ncontext. A score >= 0.5 can be classified as a hallucination. We also provide\nsentence level scores to help with explainability.\n\n### Example Request[\u00e2\u0080\u008b](/concepts/detectors/hallucination#example-request\n\""Direct link to Example Request\"")\n\n    \n    \n    [  \n      {  \n        \""context\"": \""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News.\"",  \n        \""generated_text\"": \""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade. In addition, he has also been involved in writing essays and sharing his thoughts on technology, startups, and programming."", ""Skip to main content\n\n[![Aimon Logo](/img/logo.png)![Aimon Logo](/img/logo.png)](/)\n\n[GitHub](https://github.com/aimonlabs/aimon-python-sdk)\n\n  * [Welcome to AIMon](/)\n  * [Introduction](/category/introduction)\n\n  * [Getting Started](/category/getting-started)\n\n  * [Concepts](/category/concepts)\n\n    * [Detectors](/category/detectors)\n\n      * [Hallucination](/concepts/detectors/hallucination)\n      * [Instruction Adherence](/concepts/detectors/instruction_adherence)\n      * [Conciseness](/concepts/detectors/conciseness)\n      * [Completeness](/concepts/detectors/completeness)\n      * [Toxicity](/concepts/detectors/toxicity)\n    * [Evaluation and Continuous Monitoring](/concepts/evaluation_and_monitoring)\n  * [Example Applications](/category/example-applications)\n\n  * [](/)\n  * [Concepts](/category/concepts)\n  * [Detectors](/category/detectors)\n  * Instruction Adherence\n\nOn this page\n\n# Instruction Adherence\n\nGiven a set of \u00e2\u0080\u009cinstructions\u00e2\u0080\u009d, the generated text, the input context and\nthe user query, this API is able to check whether the generated text followed\nall the instructions specified. in the \u00e2\u0080\u009cinstructions\u00e2\u0080\u009d field.\n\nAn LLM (Large Language Model) following instructions in the prompt is crucial\nfor several reasons. Firstly, it ensures the generation of content that aligns\nwith the user's needs and expectations, providing relevant and accurate\ninformation or responses."", ""in the \u00e2\u0080\u009cinstructions\u00e2\u0080\u009d field.\n\nAn LLM (Large Language Model) following instructions in the prompt is crucial\nfor several reasons. Firstly, it ensures the generation of content that aligns\nwith the user's needs and expectations, providing relevant and accurate\ninformation or responses. This adherence to instructions enhances the utility\nand effectiveness of the model, making it a reliable tool for various\napplications such as customer support, content creation, and educational\nassistance. Moreover, following prompts precisely helps maintain coherence and\ncontext, preventing misunderstandings or the generation of irrelevant\ninformation. It also ensures ethical compliance, avoiding the creation of\ninappropriate or harmful content. Ultimately, prompt adherence maximizes the\nvalue of the LLM, fostering user trust and satisfaction.\n\n### Example Request[\u00e2\u0080\u008b](/concepts/detectors/instruction_adherence#example-\nrequest \""Direct link to Example Request\"")\n\n    \n    \n    [  \n      {  \n        \""context\"": \""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News.\"",  \n        \""instructions\"": \""Write a summary of Paul Graham's career and achievements.\"",  \n        \""generated_text\"": \""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade. In addition, he has also been involved in writing essays and sharing his thoughts on technology, startups, and programming."", ""Skip to main content\n\n[![Aimon Logo](/img/logo.png)![Aimon Logo](/img/logo.png)](/)\n\n[GitHub](https://github.com/aimonlabs/aimon-python-sdk)\n\n  * [Welcome to AIMon](/)\n  * [Introduction](/category/introduction)\n\n  * [Getting Started](/category/getting-started)\n\n  * [Concepts](/category/concepts)\n\n    * [Detectors](/category/detectors)\n\n      * [Hallucination](/concepts/detectors/hallucination)\n      * [Instruction Adherence](/concepts/detectors/instruction_adherence)\n      * [Conciseness](/concepts/detectors/conciseness)\n      * [Completeness](/concepts/detectors/completeness)\n      * [Toxicity](/concepts/detectors/toxicity)\n    * [Evaluation and Continuous Monitoring](/concepts/evaluation_and_monitoring)\n  * [Example Applications](/category/example-applications)\n\n  * [](/)\n  * [Concepts](/category/concepts)\n  * [Detectors](/category/detectors)\n  * Hallucination\n\nOn this page\n\n# Hallucination\n\nGiven a context, a generated text and optionally a user query, we are able to\ndetect 2 different types of model hallucinations: intrinsic and extrinsic.\nIntrinsic Hallucinations are hallucinations where the models manipulate\noriginal information and slightly misrepresent true facts. For example,\n\u00e2\u0080\u009cEiffel Tower is the tallest building in France'' or \u00e2\u0080\u009cThe first man on the\nmoon was Yuri Gagarin\u00e2\u0080\u009d. Extrinsic Hallucinations are the ones where models\ncompletely fabricate new false information."", ""Skip to main content\n\n[![Aimon Logo](/img/logo.png)![Aimon Logo](/img/logo.png)](/)\n\n[GitHub](https://github.com/aimonlabs/aimon-python-sdk)\n\n  * [Welcome to AIMon](/)\n  * [Introduction](/category/introduction)\n\n  * [Getting Started](/category/getting-started)\n\n  * [Concepts](/category/concepts)\n\n    * [Detectors](/category/detectors)\n\n      * [Hallucination](/concepts/detectors/hallucination)\n      * [Instruction Adherence](/concepts/detectors/instruction_adherence)\n      * [Conciseness](/concepts/detectors/conciseness)\n      * [Completeness](/concepts/detectors/completeness)\n      * [Toxicity](/concepts/detectors/toxicity)\n    * [Evaluation and Continuous Monitoring](/concepts/evaluation_and_monitoring)\n  * [Example Applications](/category/example-applications)\n\n  * [](/)\n  * [Concepts](/category/concepts)\n  * Detectors\n\n# Detectors\n\n## [\u00f0\u009f\u0093\u0084\u00ef\u00b8\u008f HallucinationGiven a context, a generated text and optionally a\nuser query, we are able to detect 2 different types\nof](/concepts/detectors/hallucination)## [\u00f0\u009f\u0093\u0084\u00ef\u00b8\u008f Instruction AdherenceGiven a\nset of \u00e2\u0080\u009cinstructions\u00e2\u0080\u009d, the generated text, the input context and the user\nquery, this API is able](/concepts/detectors/instruction_adherence)## [\u00f0\u009f\u0093\u0084\u00ef\u00b8\u008f\nConcisenessGiven a context,""]",How can I visualize AIMon's results on my RAG applications?,1. Include examples of tools for visualization. 2. Emphasize user-friendly methods.,"Explore various strategies for visualizing AIMon's results in RAG applications, including tools and methodologies.","To visualize AIMon's results in RAG (Retrieval-Augmented Generation) applications, you can employ several strategies and tools:

1. **Data Visualization Libraries**: Utilize libraries such as `ggplot2`, `plotly`, or `shiny` in R to create interactive and static visualizations. These libraries can help you plot scores, such as hallucination probabilities, and compare them across different generated texts.

2. **Dashboards**: Build dashboards using tools like `Shiny` or `R Markdown`. Dashboards can provide a comprehensive view of various metrics, including hallucination detection, instruction adherence, and other evaluation criteria. This allows for real-time monitoring and analysis.

3. **Heatmaps**: Create heatmaps to visualize the distribution of hallucination scores across different contexts or generated texts. This can help identify patterns or areas that require further attention.

4. **Bar and Line Charts**: Use bar charts to compare the frequency of hallucinations across different categories or contexts. Line charts can be useful for tracking changes in scores over time, especially if you are continuously monitoring the performance of your models.

5. **Sentence-Level Analysis**: Visualize sentence-level scores using scatter plots or box plots to understand the variability in hallucination detection. This can provide insights into which specific sentences are more prone to hallucinations.

6. **Word Clouds**: Generate word clouds from the generated texts to visualize common terms associated with hallucinations. This can help in identifying misleading or fabricated information.

7. **Interactive Reports**: Create interactive reports using `R Markdown` or `Shiny` that allow users to filter and explore the results based on different parameters, such as score thresholds or specific contexts.

8. **Statistical Analysis**: Incorporate statistical analysis to assess the significance of the results. Use techniques like ANOVA or regression analysis to understand the factors influencing hallucination rates.

By combining these strategies, you can effectively visualize AIMon's results, making it easier to interpret and act upon the findings in your RAG applications."
"[""in the \u00e2\u0080\u009cinstructions\u00e2\u0080\u009d field.\n\nAn LLM (Large Language Model) following instructions in the prompt is crucial\nfor several reasons. Firstly, it ensures the generation of content that aligns\nwith the user's needs and expectations, providing relevant and accurate\ninformation or responses. This adherence to instructions enhances the utility\nand effectiveness of the model, making it a reliable tool for various\napplications such as customer support, content creation, and educational\nassistance. Moreover, following prompts precisely helps maintain coherence and\ncontext, preventing misunderstandings or the generation of irrelevant\ninformation. It also ensures ethical compliance, avoiding the creation of\ninappropriate or harmful content. Ultimately, prompt adherence maximizes the\nvalue of the LLM, fostering user trust and satisfaction.\n\n### Example Request[\u00e2\u0080\u008b](/concepts/detectors/instruction_adherence#example-\nrequest \""Direct link to Example Request\"")\n\n    \n    \n    [  \n      {  \n        \""context\"": \""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News.\"",  \n        \""instructions\"": \""Write a summary of Paul Graham's career and achievements.\"",  \n        \""generated_text\"": \""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade. In addition, he has also been involved in writing essays and sharing his thoughts on technology, startups, and programming."", ""The context should include the context\ndocuments along with the user query as passed in to the LLM. The output\ncontains a \""score\"" that is between 0.0 and 1.0 which indicates the degree of\nconciseness. If the generated answer is very verbose and contains a lot of un-\nnecessary information that is not relevant to the user query, a score between\n0.0 to 0.2 is possible. If the generated answer is mostly relevant to the user\nquery but has some amount of text that is not necessary for the user query a\nscore between 0.2 and 0.7 is possible. If the generated answer is very concise\nand properly addresses all important points for the user query, a score\nbetween 0.7 and 1.0 is possible. The API also includes a \""reasoning\"" field\nthat is a text based explanation of the score. It also does a best effort\nmethod of pointing out the unnecessary information that was included in the\noutput.\n\n### Example Request[\u00e2\u0080\u008b](/concepts/detectors/conciseness#example-request\n\""Direct link to Example Request\"")\n\n    \n    \n    [  \n      {  \n        \""context\"": \""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News.\"",  \n        \""generated_text\"": \""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade."", ""For tasks like summarization, these documents could be directly specified by the user.\n\nA dataset can be created using the AIMon client as follows:\n\n  * Python\n  * TypeScript\n\n    \n    \n    from aimon import Client  \n    import json  \n      \n    aimon_client = Client(auth_header=\""Bearer <AIMON API KEY>\"")  \n    # Create a new datasets  \n    file_path = \""evaluation_dataset.csv\""  \n      \n    dataset = json.dumps({  \n        \""name\"": \""evaluation_dataset.csv\"",  \n        \""description\"": \""This is a golden dataset\""  \n    })  \n      \n    with open(file_path, 'rb') as file1:  \n        aimon_dataset = aimon_client.datasets.create(  \n            file=file1,  \n            json_data=dataset  \n        )  \n    \n    \n    \n    import Client from \""aimon\"";  \n      \n    const aimon_client = new Client({  \n      authHeader: `Bearer API_KEY`,  \n    });  \n      \n      \n    // Creates a new dataset from the local path csv file  \n    const createDataset = async (  \n      path: string,  \n      datasetName: string,  \n      description: string  \n    ): Promise<Client.Dataset> => {  \n      const file = await fileFromPath(path);  \n      const json_data = JSON.stringify({  \n        name: datasetName,  \n        description: description,  \n      });  \n      \n      const params = {  \n        file: file,  \n        json_data: json_data,  \n      };  \n      \n      const dataset: Client.Dataset = await aimon.datasets.create(params);  \n      return dataset;  \n    };  \n    \n\n##### Dataset Collection[\u00e2\u0080\u008b](/concepts/evaluation_and_monitoring#dataset-\ncollection \""Direct link to Dataset Collection\"")\n\nYou can group a collection of evaluation datasets into a `dataset collection`\nfor ease of use."", ""For example,\n\u00e2\u0080\u009cEiffel Tower is the tallest building in France'' or \u00e2\u0080\u009cThe first man on the\nmoon was Yuri Gagarin\u00e2\u0080\u009d. Extrinsic Hallucinations are the ones where models\ncompletely fabricate new false information. This can\u00e2\u0080\u0099t be inferred from or\ntraced back to original sources. For example, \u00e2\u0080\u009cCristiano Ronaldo is a\nCricket player\u00e2\u0080\u009d. The \""is_hallucinated\"" field indicates whether the\n\""generated_text\"" (passed in the input) is hallucinated. A top level \""score\""\nfield indicates if the entire paragraph contained any hallucinations. The\nscore is a probability measure of how hallucinated the text is compared to the\ncontext. A score >= 0.5 can be classified as a hallucination. We also provide\nsentence level scores to help with explainability.\n\n### Example Request[\u00e2\u0080\u008b](/concepts/detectors/hallucination#example-request\n\""Direct link to Example Request\"")\n\n    \n    \n    [  \n      {  \n        \""context\"": \""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News.\"",  \n        \""generated_text\"": \""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade. In addition, he has also been involved in writing essays and sharing his thoughts on technology, startups, and programming."", ""\"",  \n        \""generated_text\"": \""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade. In addition, he has also been involved in writing essays and sharing his thoughts on technology, startups, and programming.\"",  \n        \""config\"": {  \n          \""conciseness\"": {  \n            \""detector_name\"": \""default\""  \n          }  \n        }  \n      }  \n    ]  \n    \n\n#### Example Response[\u00e2\u0080\u008b](/concepts/detectors/conciseness#example-response\n\""Direct link to Example Response\"")\n\n    \n    \n    [  \n        {  \n            \""conciseness\"": {  \n                \""reasoning\"": \""The generated answer includes relevant information about Paul Graham's background but contains unnecessary details that do not directly relate to the user query, which is unspecified. While it touches on his programming beginnings and writing, it lacks emphasis on the key aspects of his impact and contributions, making it less concise than it could be.\"",  \n                \""score\"": 0.25  \n            }  \n        }  \n    ]  \n    \n\n### Example (Synchronous\ndetection)[\u00e2\u0080\u008b](/concepts/detectors/conciseness#example-synchronous-detection\n\""Direct link to Example \\(Synchronous detection\\)\"")\n\nThe below example demonstrates how to use the instruction adherence detector\nin a synchronous manner.""]",Are AIMon detectors capable of sensing humour in user's questions? What about irony. Are they able to detect it as well?,1. Discuss the technology behind detection capabilities. 2. Provide examples of how humor and irony might be identified.,Investigate AIMon's capabilities in detecting subtle nuances like humor and irony in user inquiries.,"AIMon detectors primarily focus on evaluating adherence to instructions, conciseness, and the presence of hallucinations in generated content. While they are designed to assess the relevance and accuracy of responses, they do not specifically target the detection of humor or irony in user inquiries. The capabilities of these detectors are more aligned with ensuring that the generated content meets user expectations and maintains coherence rather than interpreting nuanced emotional or stylistic elements like humor or irony."
