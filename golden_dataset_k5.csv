context_docs,user_query,prompt,instructions
"['Skip to main content\n\n[![Aimon Logo](/img/logo.png)![Aimon Logo](/img/logo.png)](/)\n\n[GitHub](https://github.com/aimonlabs/aimon-python-sdk)\n\n  * [Welcome to AIMon](/)\n  * [Introduction](/category/introduction)\n\n  * [Getting Started](/category/getting-started)\n\n  * [Concepts](/category/concepts)\n\n    * [Detectors](/category/detectors)\n\n      * [Hallucination](/concepts/detectors/hallucination)\n      * [Instruction Adherence](/concepts/detectors/instruction_adherence)\n      * [Conciseness](/concepts/detectors/conciseness)\n      * [Completeness](/concepts/detectors/completeness)\n      * [Toxicity](/concepts/detectors/toxicity)\n    * [Evaluation and Continuous Monitoring](/concepts/evaluation_and_monitoring)\n  * [Example Applications](/category/example-applications)\n\n  * [](/)\n  * [Concepts](/category/concepts)\n  * [Detectors](/category/detectors)\n  * Conciseness\n\nOn this page\n\n# Conciseness\n\nGiven a context, generated text and optionally a user query or a reference\ntext, this API is able to detect if the generated text was concise or verbose\nin terms of addressing the user query. The context should include the context\ndocuments along with the user query as passed in to the LLM. The output\ncontains a ""score"" that is between 0.0 and 1.0 which indicates the degree of\nconciseness.', 'For example,\nâ\x80\x9cEiffel Tower is the tallest building in France\'\' or â\x80\x9cThe first man on the\nmoon was Yuri Gagarinâ\x80\x9d. Extrinsic Hallucinations are the ones where models\ncompletely fabricate new false information. This canâ\x80\x99t be inferred from or\ntraced back to original sources. For example, â\x80\x9cCristiano Ronaldo is a\nCricket playerâ\x80\x9d. The ""is_hallucinated"" field indicates whether the\n""generated_text"" (passed in the input) is hallucinated. A top level ""score""\nfield indicates if the entire paragraph contained any hallucinations. The\nscore is a probability measure of how hallucinated the text is compared to the\ncontext. A score >= 0.5 can be classified as a hallucination. We also provide\nsentence level scores to help with explainability.\n\n### Example Request[â\x80\x8b](/concepts/detectors/hallucination#example-request\n""Direct link to Example Request"")\n\n    \n    \n    [  \n      {  \n        ""context"": ""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News."",  \n        ""generated_text"": ""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade. In addition, he has also been involved in writing essays and sharing his thoughts on technology, startups, and programming.', ""Skip to main content\n\n[![Aimon Logo](/img/logo.png)![Aimon Logo](/img/logo.png)](/)\n\n[GitHub](https://github.com/aimonlabs/aimon-python-sdk)\n\n  * [Welcome to AIMon](/)\n  * [Introduction](/category/introduction)\n\n  * [Getting Started](/category/getting-started)\n\n  * [Concepts](/category/concepts)\n\n    * [Detectors](/category/detectors)\n\n      * [Hallucination](/concepts/detectors/hallucination)\n      * [Instruction Adherence](/concepts/detectors/instruction_adherence)\n      * [Conciseness](/concepts/detectors/conciseness)\n      * [Completeness](/concepts/detectors/completeness)\n      * [Toxicity](/concepts/detectors/toxicity)\n    * [Evaluation and Continuous Monitoring](/concepts/evaluation_and_monitoring)\n  * [Example Applications](/category/example-applications)\n\n  * [](/)\n  * [Concepts](/category/concepts)\n  * [Detectors](/category/detectors)\n  * Hallucination\n\nOn this page\n\n# Hallucination\n\nGiven a context, a generated text and optionally a user query, we are able to\ndetect 2 different types of model hallucinations: intrinsic and extrinsic.\nIntrinsic Hallucinations are hallucinations where the models manipulate\noriginal information and slightly misrepresent true facts. For example,\nâ\x80\x9cEiffel Tower is the tallest building in France'' or â\x80\x9cThe first man on the\nmoon was Yuri Gagarinâ\x80\x9d. Extrinsic Hallucinations are the ones where models\ncompletely fabricate new false information."", 'Skip to main content\n\n[![Aimon Logo](/img/logo.png)![Aimon Logo](/img/logo.png)](/)\n\n[GitHub](https://github.com/aimonlabs/aimon-python-sdk)\n\n  * [Welcome to AIMon](/)\n  * [Introduction](/category/introduction)\n\n  * [Getting Started](/category/getting-started)\n\n  * [Concepts](/category/concepts)\n\n    * [Detectors](/category/detectors)\n\n      * [Hallucination](/concepts/detectors/hallucination)\n      * [Instruction Adherence](/concepts/detectors/instruction_adherence)\n      * [Conciseness](/concepts/detectors/conciseness)\n      * [Completeness](/concepts/detectors/completeness)\n      * [Toxicity](/concepts/detectors/toxicity)\n    * [Evaluation and Continuous Monitoring](/concepts/evaluation_and_monitoring)\n  * [Example Applications](/category/example-applications)\n\n  * [](/)\n  * [Concepts](/category/concepts)\n  * Detectors\n\n# Detectors\n\n## [ð\x9f\x93\x84ï¸\x8f HallucinationGiven a context, a generated text and optionally a\nuser query, we are able to detect 2 different types\nof](/concepts/detectors/hallucination)## [ð\x9f\x93\x84ï¸\x8f Instruction AdherenceGiven a\nset of â\x80\x9cinstructionsâ\x80\x9d, the generated text, the input context and the user\nquery, this API is able](/concepts/detectors/instruction_adherence)## [ð\x9f\x93\x84ï¸\x8f\nConcisenessGiven a context,', 'The context should include the context\ndocuments along with the user query as passed in to the LLM. The output\ncontains a ""score"" that is between 0.0 and 1.0 which indicates the degree of\nconciseness. If the generated answer is very verbose and contains a lot of un-\nnecessary information that is not relevant to the user query, a score between\n0.0 to 0.2 is possible. If the generated answer is mostly relevant to the user\nquery but has some amount of text that is not necessary for the user query a\nscore between 0.2 and 0.7 is possible. If the generated answer is very concise\nand properly addresses all important points for the user query, a score\nbetween 0.7 and 1.0 is possible. The API also includes a ""reasoning"" field\nthat is a text based explanation of the score. It also does a best effort\nmethod of pointing out the unnecessary information that was included in the\noutput.\n\n### Example Request[â\x80\x8b](/concepts/detectors/conciseness#example-request\n""Direct link to Example Request"")\n\n    \n    \n    [  \n      {  \n        ""context"": ""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News."",  \n        ""generated_text"": ""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade.']",What are the key advantages of using AIMon over traditional analytics platforms?,"Explain the differences between AIMon and traditional analytics platforms, focusing on unique features and benefits.",1. Focus on distinct features and benefits. 2. Limit the response to under 200 words.
"['A dataset collection can be created as follows:\n\n  * Python\n  * TypeScript\n\n    \n    \n    dataset_collection = aimon_client.datasets.collection.create(  \n        name=""my_first_dataset_collection"",   \n        dataset_ids=[aimon_dataset1.sha, aimon_dataset2.sha],   \n        description=""This is a collection of two datasets.""  \n    )  \n    \n    \n    \n    const dataset1 = await createDataset(  \n        ""/path/to/file/filename_1.csv"",  \n        ""filename1.csv"",  \n        ""description""  \n    );  \n      \n    const dataset2 = await createDataset(  \n        ""/path/to/file/filename_2.csv"",  \n        ""filename2.csv"",  \n        ""description""  \n    );  \n      \n    let datasetCollection: Client.Datasets.CollectionCreateResponse | undefined;  \n      \n    // Ensures that dataset1.sha and dataset2.sha are defined  \n    if (dataset1.sha && dataset2.sha) {  \n        // Creates dataset collection  \n        datasetCollection = await aimon.datasets.collection.create({  \n        name: ""my_first_dataset_collection"",  \n        dataset_ids: [dataset1.sha, dataset2.sha],  \n        description: ""This is a collection of two datasets.', 'For tasks like summarization, these documents could be directly specified by the user.\n\nA dataset can be created using the AIMon client as follows:\n\n  * Python\n  * TypeScript\n\n    \n    \n    from aimon import Client  \n    import json  \n      \n    aimon_client = Client(auth_header=""Bearer <AIMON API KEY>"")  \n    # Create a new datasets  \n    file_path = ""evaluation_dataset.csv""  \n      \n    dataset = json.dumps({  \n        ""name"": ""evaluation_dataset.csv"",  \n        ""description"": ""This is a golden dataset""  \n    })  \n      \n    with open(file_path, \'rb\') as file1:  \n        aimon_dataset = aimon_client.datasets.create(  \n            file=file1,  \n            json_data=dataset  \n        )  \n    \n    \n    \n    import Client from ""aimon"";  \n      \n    const aimon_client = new Client({  \n      authHeader: `Bearer API_KEY`,  \n    });  \n      \n      \n    // Creates a new dataset from the local path csv file  \n    const createDataset = async (  \n      path: string,  \n      datasetName: string,  \n      description: string  \n    ): Promise<Client.Dataset> => {  \n      const file = await fileFromPath(path);  \n      const json_data = JSON.stringify({  \n        name: datasetName,  \n        description: description,  \n      });  \n      \n      const params = {  \n        file: file,  \n        json_data: json_data,  \n      };  \n      \n      const dataset: Client.Dataset = await aimon.datasets.create(params);  \n      return dataset;  \n    };  \n    \n\n##### Dataset Collection[â\x80\x8b](/concepts/evaluation_and_monitoring#dataset-\ncollection ""Direct link to Dataset Collection"")\n\nYou can group a collection of evaluation datasets into a `dataset collection`\nfor ease of use.', 'Skip to main content\n\n[![Aimon Logo](/img/logo.png)![Aimon Logo](/img/logo.png)](/)\n\n[GitHub](https://github.com/aimonlabs/aimon-python-sdk)\n\n  * [Welcome to AIMon](/)\n  * [Introduction](/category/introduction)\n\n  * [Getting Started](/category/getting-started)\n\n  * [Concepts](/category/concepts)\n\n    * [Detectors](/category/detectors)\n\n      * [Hallucination](/concepts/detectors/hallucination)\n      * [Instruction Adherence](/concepts/detectors/instruction_adherence)\n      * [Conciseness](/concepts/detectors/conciseness)\n      * [Completeness](/concepts/detectors/completeness)\n      * [Toxicity](/concepts/detectors/toxicity)\n    * [Evaluation and Continuous Monitoring](/concepts/evaluation_and_monitoring)\n  * [Example Applications](/category/example-applications)\n\n  * [](/)\n  * [Concepts](/category/concepts)\n  * [Detectors](/category/detectors)\n  * Conciseness\n\nOn this page\n\n# Conciseness\n\nGiven a context, generated text and optionally a user query or a reference\ntext, this API is able to detect if the generated text was concise or verbose\nin terms of addressing the user query. The context should include the context\ndocuments along with the user query as passed in to the LLM. The output\ncontains a ""score"" that is between 0.0 and 1.0 which indicates the degree of\nconciseness.', 'For example,\nâ\x80\x9cEiffel Tower is the tallest building in France\'\' or â\x80\x9cThe first man on the\nmoon was Yuri Gagarinâ\x80\x9d. Extrinsic Hallucinations are the ones where models\ncompletely fabricate new false information. This canâ\x80\x99t be inferred from or\ntraced back to original sources. For example, â\x80\x9cCristiano Ronaldo is a\nCricket playerâ\x80\x9d. The ""is_hallucinated"" field indicates whether the\n""generated_text"" (passed in the input) is hallucinated. A top level ""score""\nfield indicates if the entire paragraph contained any hallucinations. The\nscore is a probability measure of how hallucinated the text is compared to the\ncontext. A score >= 0.5 can be classified as a hallucination. We also provide\nsentence level scores to help with explainability.\n\n### Example Request[â\x80\x8b](/concepts/detectors/hallucination#example-request\n""Direct link to Example Request"")\n\n    \n    \n    [  \n      {  \n        ""context"": ""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News."",  \n        ""generated_text"": ""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade. In addition, he has also been involved in writing essays and sharing his thoughts on technology, startups, and programming.', 'Skip to main content\n\n[![Aimon Logo](/img/logo.png)![Aimon Logo](/img/logo.png)](/)\n\n[GitHub](https://github.com/aimonlabs/aimon-python-sdk)\n\n  * [Welcome to AIMon](/)\n  * [Introduction](/category/introduction)\n\n  * [Getting Started](/category/getting-started)\n\n  * [Concepts](/category/concepts)\n\n    * [Detectors](/category/detectors)\n\n      * [Hallucination](/concepts/detectors/hallucination)\n      * [Instruction Adherence](/concepts/detectors/instruction_adherence)\n      * [Conciseness](/concepts/detectors/conciseness)\n      * [Completeness](/concepts/detectors/completeness)\n      * [Toxicity](/concepts/detectors/toxicity)\n    * [Evaluation and Continuous Monitoring](/concepts/evaluation_and_monitoring)\n  * [Example Applications](/category/example-applications)\n\n  * [](/)\n  * [Concepts](/category/concepts)\n  * Detectors\n\n# Detectors\n\n## [ð\x9f\x93\x84ï¸\x8f HallucinationGiven a context, a generated text and optionally a\nuser query, we are able to detect 2 different types\nof](/concepts/detectors/hallucination)## [ð\x9f\x93\x84ï¸\x8f Instruction AdherenceGiven a\nset of â\x80\x9cinstructionsâ\x80\x9d, the generated text, the input context and the user\nquery, this API is able](/concepts/detectors/instruction_adherence)## [ð\x9f\x93\x84ï¸\x8f\nConcisenessGiven a context,']",BIMon is for business intelligence as AIMon is for artificial intelligence. Please explain the steps to install BIMon on a cloud server.,Outline the necessary configurations and prerequisites for successfully installing BIMon on a cloud server.,1. Provide a checklist format for configurations. 2. Include at least three common pitfalls to avoid.
"['For tasks like summarization, these documents could be directly specified by the user.\n\nA dataset can be created using the AIMon client as follows:\n\n  * Python\n  * TypeScript\n\n    \n    \n    from aimon import Client  \n    import json  \n      \n    aimon_client = Client(auth_header=""Bearer <AIMON API KEY>"")  \n    # Create a new datasets  \n    file_path = ""evaluation_dataset.csv""  \n      \n    dataset = json.dumps({  \n        ""name"": ""evaluation_dataset.csv"",  \n        ""description"": ""This is a golden dataset""  \n    })  \n      \n    with open(file_path, \'rb\') as file1:  \n        aimon_dataset = aimon_client.datasets.create(  \n            file=file1,  \n            json_data=dataset  \n        )  \n    \n    \n    \n    import Client from ""aimon"";  \n      \n    const aimon_client = new Client({  \n      authHeader: `Bearer API_KEY`,  \n    });  \n      \n      \n    // Creates a new dataset from the local path csv file  \n    const createDataset = async (  \n      path: string,  \n      datasetName: string,  \n      description: string  \n    ): Promise<Client.Dataset> => {  \n      const file = await fileFromPath(path);  \n      const json_data = JSON.stringify({  \n        name: datasetName,  \n        description: description,  \n      });  \n      \n      const params = {  \n        file: file,  \n        json_data: json_data,  \n      };  \n      \n      const dataset: Client.Dataset = await aimon.datasets.create(params);  \n      return dataset;  \n    };  \n    \n\n##### Dataset Collection[â\x80\x8b](/concepts/evaluation_and_monitoring#dataset-\ncollection ""Direct link to Dataset Collection"")\n\nYou can group a collection of evaluation datasets into a `dataset collection`\nfor ease of use.', 'For example,\nâ\x80\x9cEiffel Tower is the tallest building in France\'\' or â\x80\x9cThe first man on the\nmoon was Yuri Gagarinâ\x80\x9d. Extrinsic Hallucinations are the ones where models\ncompletely fabricate new false information. This canâ\x80\x99t be inferred from or\ntraced back to original sources. For example, â\x80\x9cCristiano Ronaldo is a\nCricket playerâ\x80\x9d. The ""is_hallucinated"" field indicates whether the\n""generated_text"" (passed in the input) is hallucinated. A top level ""score""\nfield indicates if the entire paragraph contained any hallucinations. The\nscore is a probability measure of how hallucinated the text is compared to the\ncontext. A score >= 0.5 can be classified as a hallucination. We also provide\nsentence level scores to help with explainability.\n\n### Example Request[â\x80\x8b](/concepts/detectors/hallucination#example-request\n""Direct link to Example Request"")\n\n    \n    \n    [  \n      {  \n        ""context"": ""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News."",  \n        ""generated_text"": ""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade. In addition, he has also been involved in writing essays and sharing his thoughts on technology, startups, and programming.', ""Skip to main content\n\n[![Aimon Logo](/img/logo.png)![Aimon Logo](/img/logo.png)](/)\n\n[GitHub](https://github.com/aimonlabs/aimon-python-sdk)\n\n  * [Welcome to AIMon](/)\n  * [Introduction](/category/introduction)\n\n  * [Getting Started](/category/getting-started)\n\n  * [Concepts](/category/concepts)\n\n    * [Detectors](/category/detectors)\n\n      * [Hallucination](/concepts/detectors/hallucination)\n      * [Instruction Adherence](/concepts/detectors/instruction_adherence)\n      * [Conciseness](/concepts/detectors/conciseness)\n      * [Completeness](/concepts/detectors/completeness)\n      * [Toxicity](/concepts/detectors/toxicity)\n    * [Evaluation and Continuous Monitoring](/concepts/evaluation_and_monitoring)\n  * [Example Applications](/category/example-applications)\n\n  * [](/)\n  * [Concepts](/category/concepts)\n  * [Detectors](/category/detectors)\n  * Instruction Adherence\n\nOn this page\n\n# Instruction Adherence\n\nGiven a set of â\x80\x9cinstructionsâ\x80\x9d, the generated text, the input context and\nthe user query, this API is able to check whether the generated text followed\nall the instructions specified. in the â\x80\x9cinstructionsâ\x80\x9d field.\n\nAn LLM (Large Language Model) following instructions in the prompt is crucial\nfor several reasons. Firstly, it ensures the generation of content that aligns\nwith the user's needs and expectations, providing relevant and accurate\ninformation or responses."", ""Skip to main content\n\n[![Aimon Logo](/img/logo.png)![Aimon Logo](/img/logo.png)](/)\n\n[GitHub](https://github.com/aimonlabs/aimon-python-sdk)\n\n  * [Welcome to AIMon](/)\n  * [Introduction](/category/introduction)\n\n  * [Getting Started](/category/getting-started)\n\n  * [Concepts](/category/concepts)\n\n    * [Detectors](/category/detectors)\n\n      * [Hallucination](/concepts/detectors/hallucination)\n      * [Instruction Adherence](/concepts/detectors/instruction_adherence)\n      * [Conciseness](/concepts/detectors/conciseness)\n      * [Completeness](/concepts/detectors/completeness)\n      * [Toxicity](/concepts/detectors/toxicity)\n    * [Evaluation and Continuous Monitoring](/concepts/evaluation_and_monitoring)\n  * [Example Applications](/category/example-applications)\n\n  * [](/)\n  * [Concepts](/category/concepts)\n  * [Detectors](/category/detectors)\n  * Hallucination\n\nOn this page\n\n# Hallucination\n\nGiven a context, a generated text and optionally a user query, we are able to\ndetect 2 different types of model hallucinations: intrinsic and extrinsic.\nIntrinsic Hallucinations are hallucinations where the models manipulate\noriginal information and slightly misrepresent true facts. For example,\nâ\x80\x9cEiffel Tower is the tallest building in France'' or â\x80\x9cThe first man on the\nmoon was Yuri Gagarinâ\x80\x9d. Extrinsic Hallucinations are the ones where models\ncompletely fabricate new false information."", 'A dataset collection can be created as follows:\n\n  * Python\n  * TypeScript\n\n    \n    \n    dataset_collection = aimon_client.datasets.collection.create(  \n        name=""my_first_dataset_collection"",   \n        dataset_ids=[aimon_dataset1.sha, aimon_dataset2.sha],   \n        description=""This is a collection of two datasets.""  \n    )  \n    \n    \n    \n    const dataset1 = await createDataset(  \n        ""/path/to/file/filename_1.csv"",  \n        ""filename1.csv"",  \n        ""description""  \n    );  \n      \n    const dataset2 = await createDataset(  \n        ""/path/to/file/filename_2.csv"",  \n        ""filename2.csv"",  \n        ""description""  \n    );  \n      \n    let datasetCollection: Client.Datasets.CollectionCreateResponse | undefined;  \n      \n    // Ensures that dataset1.sha and dataset2.sha are defined  \n    if (dataset1.sha && dataset2.sha) {  \n        // Creates dataset collection  \n        datasetCollection = await aimon.datasets.collection.create({  \n        name: ""my_first_dataset_collection"",  \n        dataset_ids: [dataset1.sha, dataset2.sha],  \n        description: ""This is a collection of two datasets.']","Name 3 potential errors one can encounter while integrating AIMon. Also, suggest solutions for them.",Discuss common integration challenges faced with AIMon and effective troubleshooting strategies.,1. List integration challenges in bullet points. 2. Suggest at least one proactive measure for each challenge.
"['For example,\nâ\x80\x9cEiffel Tower is the tallest building in France\'\' or â\x80\x9cThe first man on the\nmoon was Yuri Gagarinâ\x80\x9d. Extrinsic Hallucinations are the ones where models\ncompletely fabricate new false information. This canâ\x80\x99t be inferred from or\ntraced back to original sources. For example, â\x80\x9cCristiano Ronaldo is a\nCricket playerâ\x80\x9d. The ""is_hallucinated"" field indicates whether the\n""generated_text"" (passed in the input) is hallucinated. A top level ""score""\nfield indicates if the entire paragraph contained any hallucinations. The\nscore is a probability measure of how hallucinated the text is compared to the\ncontext. A score >= 0.5 can be classified as a hallucination. We also provide\nsentence level scores to help with explainability.\n\n### Example Request[â\x80\x8b](/concepts/detectors/hallucination#example-request\n""Direct link to Example Request"")\n\n    \n    \n    [  \n      {  \n        ""context"": ""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News."",  \n        ""generated_text"": ""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade. In addition, he has also been involved in writing essays and sharing his thoughts on technology, startups, and programming.', 'The output contains a ""score"" that is between 0.0 and 1.0 which\nindicates the degree of completeness. If the generated answer is not at all\nrelevant to the user query, a score between 0.0 to 0.2 is possible. If the\ngenerated answer is relevant but misses some information, a score between 0.2\nand 0.7 is possible. If the generated answer is relevant and fully captures\nall of the information, a score between 0.7 and 1.0 is possible. The API also\nincludes a ""reasoning"" field that is a text based explanation of the score. It\nalso does a best effort method of pointing out the points that were missed\nfrom the expected answer.\n\n### Example Request[â\x80\x8b](/concepts/detectors/completeness#example-request\n""Direct link to Example Request"")\n\n    \n    \n    [  \n      {  \n        ""context"": ""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News."",  \n        ""generated_text"": ""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade. In addition, he has also been involved in writing essays and sharing his thoughts on technology, startups, and programming.', 'The context should include the context\ndocuments along with the user query as passed in to the LLM. The output\ncontains a ""score"" that is between 0.0 and 1.0 which indicates the degree of\nconciseness. If the generated answer is very verbose and contains a lot of un-\nnecessary information that is not relevant to the user query, a score between\n0.0 to 0.2 is possible. If the generated answer is mostly relevant to the user\nquery but has some amount of text that is not necessary for the user query a\nscore between 0.2 and 0.7 is possible. If the generated answer is very concise\nand properly addresses all important points for the user query, a score\nbetween 0.7 and 1.0 is possible. The API also includes a ""reasoning"" field\nthat is a text based explanation of the score. It also does a best effort\nmethod of pointing out the unnecessary information that was included in the\noutput.\n\n### Example Request[â\x80\x8b](/concepts/detectors/conciseness#example-request\n""Direct link to Example Request"")\n\n    \n    \n    [  \n      {  \n        ""context"": ""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News."",  \n        ""generated_text"": ""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade.', 'Skip to main content\n\n[![Aimon Logo](/img/logo.png)![Aimon Logo](/img/logo.png)](/)\n\n[GitHub](https://github.com/aimonlabs/aimon-python-sdk)\n\n  * [Welcome to AIMon](/)\n  * [Introduction](/category/introduction)\n\n  * [Getting Started](/category/getting-started)\n\n  * [Concepts](/category/concepts)\n\n    * [Detectors](/category/detectors)\n\n      * [Hallucination](/concepts/detectors/hallucination)\n      * [Instruction Adherence](/concepts/detectors/instruction_adherence)\n      * [Conciseness](/concepts/detectors/conciseness)\n      * [Completeness](/concepts/detectors/completeness)\n      * [Toxicity](/concepts/detectors/toxicity)\n    * [Evaluation and Continuous Monitoring](/concepts/evaluation_and_monitoring)\n  * [Example Applications](/category/example-applications)\n\n  * [](/)\n  * [Concepts](/category/concepts)\n  * [Detectors](/category/detectors)\n  * Conciseness\n\nOn this page\n\n# Conciseness\n\nGiven a context, generated text and optionally a user query or a reference\ntext, this API is able to detect if the generated text was concise or verbose\nin terms of addressing the user query. The context should include the context\ndocuments along with the user query as passed in to the LLM. The output\ncontains a ""score"" that is between 0.0 and 1.0 which indicates the degree of\nconciseness.', 'Skip to main content\n\n[![Aimon Logo](/img/logo.png)![Aimon Logo](/img/logo.png)](/)\n\n[GitHub](https://github.com/aimonlabs/aimon-python-sdk)\n\n  * [Welcome to AIMon](/)\n  * [Introduction](/category/introduction)\n\n  * [Getting Started](/category/getting-started)\n\n  * [Concepts](/category/concepts)\n\n    * [Detectors](/category/detectors)\n\n      * [Hallucination](/concepts/detectors/hallucination)\n      * [Instruction Adherence](/concepts/detectors/instruction_adherence)\n      * [Conciseness](/concepts/detectors/conciseness)\n      * [Completeness](/concepts/detectors/completeness)\n      * [Toxicity](/concepts/detectors/toxicity)\n    * [Evaluation and Continuous Monitoring](/concepts/evaluation_and_monitoring)\n  * [Example Applications](/category/example-applications)\n\n  * [](/)\n  * [Concepts](/category/concepts)\n  * Detectors\n\n# Detectors\n\n## [ð\x9f\x93\x84ï¸\x8f HallucinationGiven a context, a generated text and optionally a\nuser query, we are able to detect 2 different types\nof](/concepts/detectors/hallucination)## [ð\x9f\x93\x84ï¸\x8f Instruction AdherenceGiven a\nset of â\x80\x9cinstructionsâ\x80\x9d, the generated text, the input context and the user\nquery, this API is able](/concepts/detectors/instruction_adherence)## [ð\x9f\x93\x84ï¸\x8f\nConcisenessGiven a context,']",How does AIMon integrate with TensorFlow tensors?,"Describe the compatibility between AIMon and TensorFlow, including how data is processed and utilized.",1. Use technical terms appropriately but explain them. 2.Limit the response to under 300 words.
"['For example,\nâ\x80\x9cEiffel Tower is the tallest building in France\'\' or â\x80\x9cThe first man on the\nmoon was Yuri Gagarinâ\x80\x9d. Extrinsic Hallucinations are the ones where models\ncompletely fabricate new false information. This canâ\x80\x99t be inferred from or\ntraced back to original sources. For example, â\x80\x9cCristiano Ronaldo is a\nCricket playerâ\x80\x9d. The ""is_hallucinated"" field indicates whether the\n""generated_text"" (passed in the input) is hallucinated. A top level ""score""\nfield indicates if the entire paragraph contained any hallucinations. The\nscore is a probability measure of how hallucinated the text is compared to the\ncontext. A score >= 0.5 can be classified as a hallucination. We also provide\nsentence level scores to help with explainability.\n\n### Example Request[â\x80\x8b](/concepts/detectors/hallucination#example-request\n""Direct link to Example Request"")\n\n    \n    \n    [  \n      {  \n        ""context"": ""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News."",  \n        ""generated_text"": ""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade. In addition, he has also been involved in writing essays and sharing his thoughts on technology, startups, and programming.', 'The context should include the context\ndocuments along with the user query as passed in to the LLM. The output\ncontains a ""score"" that is between 0.0 and 1.0 which indicates the degree of\nconciseness. If the generated answer is very verbose and contains a lot of un-\nnecessary information that is not relevant to the user query, a score between\n0.0 to 0.2 is possible. If the generated answer is mostly relevant to the user\nquery but has some amount of text that is not necessary for the user query a\nscore between 0.2 and 0.7 is possible. If the generated answer is very concise\nand properly addresses all important points for the user query, a score\nbetween 0.7 and 1.0 is possible. The API also includes a ""reasoning"" field\nthat is a text based explanation of the score. It also does a best effort\nmethod of pointing out the unnecessary information that was included in the\noutput.\n\n### Example Request[â\x80\x8b](/concepts/detectors/conciseness#example-request\n""Direct link to Example Request"")\n\n    \n    \n    [  \n      {  \n        ""context"": ""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News."",  \n        ""generated_text"": ""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade.', 'in the â\x80\x9cinstructionsâ\x80\x9d field.\n\nAn LLM (Large Language Model) following instructions in the prompt is crucial\nfor several reasons. Firstly, it ensures the generation of content that aligns\nwith the user\'s needs and expectations, providing relevant and accurate\ninformation or responses. This adherence to instructions enhances the utility\nand effectiveness of the model, making it a reliable tool for various\napplications such as customer support, content creation, and educational\nassistance. Moreover, following prompts precisely helps maintain coherence and\ncontext, preventing misunderstandings or the generation of irrelevant\ninformation. It also ensures ethical compliance, avoiding the creation of\ninappropriate or harmful content. Ultimately, prompt adherence maximizes the\nvalue of the LLM, fostering user trust and satisfaction.\n\n### Example Request[â\x80\x8b](/concepts/detectors/instruction_adherence#example-\nrequest ""Direct link to Example Request"")\n\n    \n    \n    [  \n      {  \n        ""context"": ""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News."",  \n        ""instructions"": ""Write a summary of Paul Graham\'s career and achievements."",  \n        ""generated_text"": ""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade. In addition, he has also been involved in writing essays and sharing his thoughts on technology, startups, and programming.', 'Skip to main content\n\n[![Aimon Logo](/img/logo.png)![Aimon Logo](/img/logo.png)](/)\n\n[GitHub](https://github.com/aimonlabs/aimon-python-sdk)\n\n  * [Welcome to AIMon](/)\n  * [Introduction](/category/introduction)\n\n  * [Getting Started](/category/getting-started)\n\n  * [Concepts](/category/concepts)\n\n    * [Detectors](/category/detectors)\n\n      * [Hallucination](/concepts/detectors/hallucination)\n      * [Instruction Adherence](/concepts/detectors/instruction_adherence)\n      * [Conciseness](/concepts/detectors/conciseness)\n      * [Completeness](/concepts/detectors/completeness)\n      * [Toxicity](/concepts/detectors/toxicity)\n    * [Evaluation and Continuous Monitoring](/concepts/evaluation_and_monitoring)\n  * [Example Applications](/category/example-applications)\n\n  * [](/)\n  * [Concepts](/category/concepts)\n  * [Detectors](/category/detectors)\n  * Conciseness\n\nOn this page\n\n# Conciseness\n\nGiven a context, generated text and optionally a user query or a reference\ntext, this API is able to detect if the generated text was concise or verbose\nin terms of addressing the user query. The context should include the context\ndocuments along with the user query as passed in to the LLM. The output\ncontains a ""score"" that is between 0.0 and 1.0 which indicates the degree of\nconciseness.', 'The output contains a ""score"" that is between 0.0 and 1.0 which\nindicates the degree of completeness. If the generated answer is not at all\nrelevant to the user query, a score between 0.0 to 0.2 is possible. If the\ngenerated answer is relevant but misses some information, a score between 0.2\nand 0.7 is possible. If the generated answer is relevant and fully captures\nall of the information, a score between 0.7 and 1.0 is possible. The API also\nincludes a ""reasoning"" field that is a text based explanation of the score. It\nalso does a best effort method of pointing out the points that were missed\nfrom the expected answer.\n\n### Example Request[â\x80\x8b](/concepts/detectors/completeness#example-request\n""Direct link to Example Request"")\n\n    \n    \n    [  \n      {  \n        ""context"": ""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News."",  \n        ""generated_text"": ""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade. In addition, he has also been involved in writing essays and sharing his thoughts on technology, startups, and programming.']",How is AIMon able to achieve real-time analytics without significant latency?,Analyze the techniques AIMon employs to minimize latency in real-time analytics.,1. Include examples of techniques used by AIMon. 2.Ensure clarity for a non-technical audience.
"['The output contains a ""score"" that is between 0.0 and 1.0 which\nindicates the degree of completeness. If the generated answer is not at all\nrelevant to the user query, a score between 0.0 to 0.2 is possible. If the\ngenerated answer is relevant but misses some information, a score between 0.2\nand 0.7 is possible. If the generated answer is relevant and fully captures\nall of the information, a score between 0.7 and 1.0 is possible. The API also\nincludes a ""reasoning"" field that is a text based explanation of the score. It\nalso does a best effort method of pointing out the points that were missed\nfrom the expected answer.\n\n### Example Request[â\x80\x8b](/concepts/detectors/completeness#example-request\n""Direct link to Example Request"")\n\n    \n    \n    [  \n      {  \n        ""context"": ""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News."",  \n        ""generated_text"": ""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade. In addition, he has also been involved in writing essays and sharing his thoughts on technology, startups, and programming.', '"",  \n        });  \n    } else {  \n        throw new Error(""Dataset sha is undefined"");  \n    }  \n      \n    \n\nThis allows you to then access records from the dataset collection as follows:\n\n  * Python\n  * TypeScript\n\n    \n    \n    # Get all records from the datasets in this collection  \n    dataset_collection_records = []  \n    for dataset_id in dataset_collection.dataset_ids:  \n        dataset_records = aimon_client.datasets.records.list(sha=dataset_id)  \n        dataset_collection_records.extend(dataset_records)  \n    \n    \n    \n      \n    const datasetCollectionRecords: any[] = [];  \n      \n    for (const datasetId of datasetCollection.dataset_ids) {  \n      const datasetRecords = await aimonClient.datasets.records.list({ sha: datasetId });  \n      datasetCollectionRecords.push(...datasetRecords);  \n    }  \n    \n\n#### Creating an Evaluation[â\x80\x8b](/concepts/evaluation_and_monitoring#creating-\nan-evaluation ""Direct link to Creating an Evaluation"")\n\nAn evaluation is associated with a specific dataset collection and a\nparticular version of an application (and its corresponding model).\n\n#### Running an Evaluation[â\x80\x8b](/concepts/evaluation_and_monitoring#running-\nan-evaluation ""Direct link to Running an Evaluation"")\n\nA ""run"" is an instance of an evaluation that you would like to track metrics\nagainst. You could have multiple runs of the same evaluation. This is\ntypically done in a CI/CD context where the same evaluation would run at\nregular intervals. Since LLMs are probabilistic in nature, they could produce\ndifferent outputs for the same query and context. It is a good idea to run the\nevaluations regularly to understand the variations of outputs produced by your\nLLMs. In addition, runs give you the ability to choose different metrics for\neach run.', 'The context should include the context\ndocuments along with the user query as passed in to the LLM. The output\ncontains a ""score"" that is between 0.0 and 1.0 which indicates the degree of\nconciseness. If the generated answer is very verbose and contains a lot of un-\nnecessary information that is not relevant to the user query, a score between\n0.0 to 0.2 is possible. If the generated answer is mostly relevant to the user\nquery but has some amount of text that is not necessary for the user query a\nscore between 0.2 and 0.7 is possible. If the generated answer is very concise\nand properly addresses all important points for the user query, a score\nbetween 0.7 and 1.0 is possible. The API also includes a ""reasoning"" field\nthat is a text based explanation of the score. It also does a best effort\nmethod of pointing out the unnecessary information that was included in the\noutput.\n\n### Example Request[â\x80\x8b](/concepts/detectors/conciseness#example-request\n""Direct link to Example Request"")\n\n    \n    \n    [  \n      {  \n        ""context"": ""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News."",  \n        ""generated_text"": ""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade.', 'For example,\nâ\x80\x9cEiffel Tower is the tallest building in France\'\' or â\x80\x9cThe first man on the\nmoon was Yuri Gagarinâ\x80\x9d. Extrinsic Hallucinations are the ones where models\ncompletely fabricate new false information. This canâ\x80\x99t be inferred from or\ntraced back to original sources. For example, â\x80\x9cCristiano Ronaldo is a\nCricket playerâ\x80\x9d. The ""is_hallucinated"" field indicates whether the\n""generated_text"" (passed in the input) is hallucinated. A top level ""score""\nfield indicates if the entire paragraph contained any hallucinations. The\nscore is a probability measure of how hallucinated the text is compared to the\ncontext. A score >= 0.5 can be classified as a hallucination. We also provide\nsentence level scores to help with explainability.\n\n### Example Request[â\x80\x8b](/concepts/detectors/hallucination#example-request\n""Direct link to Example Request"")\n\n    \n    \n    [  \n      {  \n        ""context"": ""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News."",  \n        ""generated_text"": ""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade. In addition, he has also been involved in writing essays and sharing his thoughts on technology, startups, and programming.', 'A dataset collection can be created as follows:\n\n  * Python\n  * TypeScript\n\n    \n    \n    dataset_collection = aimon_client.datasets.collection.create(  \n        name=""my_first_dataset_collection"",   \n        dataset_ids=[aimon_dataset1.sha, aimon_dataset2.sha],   \n        description=""This is a collection of two datasets.""  \n    )  \n    \n    \n    \n    const dataset1 = await createDataset(  \n        ""/path/to/file/filename_1.csv"",  \n        ""filename1.csv"",  \n        ""description""  \n    );  \n      \n    const dataset2 = await createDataset(  \n        ""/path/to/file/filename_2.csv"",  \n        ""filename2.csv"",  \n        ""description""  \n    );  \n      \n    let datasetCollection: Client.Datasets.CollectionCreateResponse | undefined;  \n      \n    // Ensures that dataset1.sha and dataset2.sha are defined  \n    if (dataset1.sha && dataset2.sha) {  \n        // Creates dataset collection  \n        datasetCollection = await aimon.datasets.collection.create({  \n        name: ""my_first_dataset_collection"",  \n        dataset_ids: [dataset1.sha, dataset2.sha],  \n        description: ""This is a collection of two datasets.']",Which historical figure in the 20th century praised AIMon's capabilities?,Identify and elaborate on endorsements or praises for AIMon by notable 20th-century figures in technology or science.,"1. Provide context for each endorsement mentioned. 2. Include at least two quotes, if available."
"['For tasks like summarization, these documents could be directly specified by the user.\n\nA dataset can be created using the AIMon client as follows:\n\n  * Python\n  * TypeScript\n\n    \n    \n    from aimon import Client  \n    import json  \n      \n    aimon_client = Client(auth_header=""Bearer <AIMON API KEY>"")  \n    # Create a new datasets  \n    file_path = ""evaluation_dataset.csv""  \n      \n    dataset = json.dumps({  \n        ""name"": ""evaluation_dataset.csv"",  \n        ""description"": ""This is a golden dataset""  \n    })  \n      \n    with open(file_path, \'rb\') as file1:  \n        aimon_dataset = aimon_client.datasets.create(  \n            file=file1,  \n            json_data=dataset  \n        )  \n    \n    \n    \n    import Client from ""aimon"";  \n      \n    const aimon_client = new Client({  \n      authHeader: `Bearer API_KEY`,  \n    });  \n      \n      \n    // Creates a new dataset from the local path csv file  \n    const createDataset = async (  \n      path: string,  \n      datasetName: string,  \n      description: string  \n    ): Promise<Client.Dataset> => {  \n      const file = await fileFromPath(path);  \n      const json_data = JSON.stringify({  \n        name: datasetName,  \n        description: description,  \n      });  \n      \n      const params = {  \n        file: file,  \n        json_data: json_data,  \n      };  \n      \n      const dataset: Client.Dataset = await aimon.datasets.create(params);  \n      return dataset;  \n    };  \n    \n\n##### Dataset Collection[â\x80\x8b](/concepts/evaluation_and_monitoring#dataset-\ncollection ""Direct link to Dataset Collection"")\n\nYou can group a collection of evaluation datasets into a `dataset collection`\nfor ease of use.', 'A dataset collection can be created as follows:\n\n  * Python\n  * TypeScript\n\n    \n    \n    dataset_collection = aimon_client.datasets.collection.create(  \n        name=""my_first_dataset_collection"",   \n        dataset_ids=[aimon_dataset1.sha, aimon_dataset2.sha],   \n        description=""This is a collection of two datasets.""  \n    )  \n    \n    \n    \n    const dataset1 = await createDataset(  \n        ""/path/to/file/filename_1.csv"",  \n        ""filename1.csv"",  \n        ""description""  \n    );  \n      \n    const dataset2 = await createDataset(  \n        ""/path/to/file/filename_2.csv"",  \n        ""filename2.csv"",  \n        ""description""  \n    );  \n      \n    let datasetCollection: Client.Datasets.CollectionCreateResponse | undefined;  \n      \n    // Ensures that dataset1.sha and dataset2.sha are defined  \n    if (dataset1.sha && dataset2.sha) {  \n        // Creates dataset collection  \n        datasetCollection = await aimon.datasets.collection.create({  \n        name: ""my_first_dataset_collection"",  \n        dataset_ids: [dataset1.sha, dataset2.sha],  \n        description: ""This is a collection of two datasets.', '](/example-applications/chatbot)\n\n#### Summarization with an inline AIMon detector[â\x80\x8b](/#summarization-with-an-\ninline-aimon-detector ""Direct link to Summarization with an inline AIMon\ndetector"")\n\n  * [A simple summarization application with an inline AIMon detector.](/example-applications/summarization)\n\n#### Summarization with continuous monitoring[â\x80\x8b](/#summarization-with-\ncontinuous-monitoring ""Direct link to Summarization with continuous\nmonitoring"")\n\n  * [Notebook](https://github.com/aimonlabs/aimon-python-sdk/blob/main/examples/notebooks/aimon_continuous_mon_decorators_langchain_summarization.ipynb)\n\n#### Summarization with evaluation[â\x80\x8b](/#summarization-with-evaluation\n""Direct link to Summarization with evaluation"")\n\n  * [Notebook](https://github.com/aimonlabs/aimon-python-sdk/blob/main/examples/notebooks/aimon_evaluation_decorators_langchain_summarization.ipynb)\n\n[NextIntroduction](/category/introduction)\n\n  * [Motivation](/#motivation)\n  * [Getting Started](/#getting-started)\n  * [Concepts](/#concepts)\n  * [Example Applications](/#example-applications)\n\nDocs\n\n  * [Tutorial](/)\n\nCommunity\n\n  * [Slack](https://join.slack.com/t/generativeair/shared_invite/zt-2m3v8oddx-qz9S2ep_xL4sYvLuOhU39Q)\n\nCopyright Â© 2024 Aimon Labs, Inc. All rights reserved', '"",  \n        });  \n    } else {  \n        throw new Error(""Dataset sha is undefined"");  \n    }  \n      \n    \n\nThis allows you to then access records from the dataset collection as follows:\n\n  * Python\n  * TypeScript\n\n    \n    \n    # Get all records from the datasets in this collection  \n    dataset_collection_records = []  \n    for dataset_id in dataset_collection.dataset_ids:  \n        dataset_records = aimon_client.datasets.records.list(sha=dataset_id)  \n        dataset_collection_records.extend(dataset_records)  \n    \n    \n    \n      \n    const datasetCollectionRecords: any[] = [];  \n      \n    for (const datasetId of datasetCollection.dataset_ids) {  \n      const datasetRecords = await aimonClient.datasets.records.list({ sha: datasetId });  \n      datasetCollectionRecords.push(...datasetRecords);  \n    }  \n    \n\n#### Creating an Evaluation[â\x80\x8b](/concepts/evaluation_and_monitoring#creating-\nan-evaluation ""Direct link to Creating an Evaluation"")\n\nAn evaluation is associated with a specific dataset collection and a\nparticular version of an application (and its corresponding model).\n\n#### Running an Evaluation[â\x80\x8b](/concepts/evaluation_and_monitoring#running-\nan-evaluation ""Direct link to Running an Evaluation"")\n\nA ""run"" is an instance of an evaluation that you would like to track metrics\nagainst. You could have multiple runs of the same evaluation. This is\ntypically done in a CI/CD context where the same evaluation would run at\nregular intervals. Since LLMs are probabilistic in nature, they could produce\ndifferent outputs for the same query and context. It is a good idea to run the\nevaluations regularly to understand the variations of outputs produced by your\nLLMs. In addition, runs give you the ability to choose different metrics for\neach run.', 'For example, a summarization application. Each application is versioned i.e.,\neach application is associated with a particular model for a given version of\nthe application. When you use a different model for the same application,\nAIMon will automatically create a new version of the application.\n\n### Evaluation[â\x80\x8b](/concepts/evaluation_and_monitoring#evaluation ""Direct\nlink to Evaluation"")\n\nEvaluation is the process of assessing the quality of the generated text\ntypically in an offline setup. This can be done using various detectors\nprovided by the AIMon platform. AIMon adopts a ""batteries included"" approach\ni.e., you do not have to use another third-party API for the various\ndetectors.\n\nBefore deploying the application to production, it is a good idea to test it\nwith either a curated golden dataset or a snapshot of production traffic. In\nthis section, we will demonstrate how AIMon can assist you to perform these\ntests.\n\n#### Evaluation Dataset[â\x80\x8b](/concepts/evaluation_and_monitoring#evaluation-\ndataset ""Direct link to Evaluation Dataset"")\n\nAIMon can manage datasets for you. The dataset should be a CSV file with these\ncolumns:\n\n  * ""prompt"": This is the prompt used for the LLM\n  * ""user_query"": This the query specified by the user\n  * ""context_docs"": These are context documents that are either retrieved from a RAG or through other methods. For tasks like summarization, these documents could be directly specified by the user.']","Can AIMon be customized? If yes, is it included with the subscription or do I have to pay extra?",Clarify the customization features available in AIMon and the pricing structure associated with these options.,1. Clearly outline the customization options. 2. Highlight any potential additional costs involved.
"['in the â\x80\x9cinstructionsâ\x80\x9d field.\n\nAn LLM (Large Language Model) following instructions in the prompt is crucial\nfor several reasons. Firstly, it ensures the generation of content that aligns\nwith the user\'s needs and expectations, providing relevant and accurate\ninformation or responses. This adherence to instructions enhances the utility\nand effectiveness of the model, making it a reliable tool for various\napplications such as customer support, content creation, and educational\nassistance. Moreover, following prompts precisely helps maintain coherence and\ncontext, preventing misunderstandings or the generation of irrelevant\ninformation. It also ensures ethical compliance, avoiding the creation of\ninappropriate or harmful content. Ultimately, prompt adherence maximizes the\nvalue of the LLM, fostering user trust and satisfaction.\n\n### Example Request[â\x80\x8b](/concepts/detectors/instruction_adherence#example-\nrequest ""Direct link to Example Request"")\n\n    \n    \n    [  \n      {  \n        ""context"": ""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News."",  \n        ""instructions"": ""Write a summary of Paul Graham\'s career and achievements."",  \n        ""generated_text"": ""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade. In addition, he has also been involved in writing essays and sharing his thoughts on technology, startups, and programming.', ""Skip to main content\n\n[![Aimon Logo](/img/logo.png)![Aimon Logo](/img/logo.png)](/)\n\n[GitHub](https://github.com/aimonlabs/aimon-python-sdk)\n\n  * [Welcome to AIMon](/)\n  * [Introduction](/category/introduction)\n\n  * [Getting Started](/category/getting-started)\n\n  * [Concepts](/category/concepts)\n\n    * [Detectors](/category/detectors)\n\n      * [Hallucination](/concepts/detectors/hallucination)\n      * [Instruction Adherence](/concepts/detectors/instruction_adherence)\n      * [Conciseness](/concepts/detectors/conciseness)\n      * [Completeness](/concepts/detectors/completeness)\n      * [Toxicity](/concepts/detectors/toxicity)\n    * [Evaluation and Continuous Monitoring](/concepts/evaluation_and_monitoring)\n  * [Example Applications](/category/example-applications)\n\n  * [](/)\n  * [Concepts](/category/concepts)\n  * [Detectors](/category/detectors)\n  * Instruction Adherence\n\nOn this page\n\n# Instruction Adherence\n\nGiven a set of â\x80\x9cinstructionsâ\x80\x9d, the generated text, the input context and\nthe user query, this API is able to check whether the generated text followed\nall the instructions specified. in the â\x80\x9cinstructionsâ\x80\x9d field.\n\nAn LLM (Large Language Model) following instructions in the prompt is crucial\nfor several reasons. Firstly, it ensures the generation of content that aligns\nwith the user's needs and expectations, providing relevant and accurate\ninformation or responses."", 'For tasks like summarization, these documents could be directly specified by the user.\n\nA dataset can be created using the AIMon client as follows:\n\n  * Python\n  * TypeScript\n\n    \n    \n    from aimon import Client  \n    import json  \n      \n    aimon_client = Client(auth_header=""Bearer <AIMON API KEY>"")  \n    # Create a new datasets  \n    file_path = ""evaluation_dataset.csv""  \n      \n    dataset = json.dumps({  \n        ""name"": ""evaluation_dataset.csv"",  \n        ""description"": ""This is a golden dataset""  \n    })  \n      \n    with open(file_path, \'rb\') as file1:  \n        aimon_dataset = aimon_client.datasets.create(  \n            file=file1,  \n            json_data=dataset  \n        )  \n    \n    \n    \n    import Client from ""aimon"";  \n      \n    const aimon_client = new Client({  \n      authHeader: `Bearer API_KEY`,  \n    });  \n      \n      \n    // Creates a new dataset from the local path csv file  \n    const createDataset = async (  \n      path: string,  \n      datasetName: string,  \n      description: string  \n    ): Promise<Client.Dataset> => {  \n      const file = await fileFromPath(path);  \n      const json_data = JSON.stringify({  \n        name: datasetName,  \n        description: description,  \n      });  \n      \n      const params = {  \n        file: file,  \n        json_data: json_data,  \n      };  \n      \n      const dataset: Client.Dataset = await aimon.datasets.create(params);  \n      return dataset;  \n    };  \n    \n\n##### Dataset Collection[â\x80\x8b](/concepts/evaluation_and_monitoring#dataset-\ncollection ""Direct link to Dataset Collection"")\n\nYou can group a collection of evaluation datasets into a `dataset collection`\nfor ease of use.', 'For example,\nâ\x80\x9cEiffel Tower is the tallest building in France\'\' or â\x80\x9cThe first man on the\nmoon was Yuri Gagarinâ\x80\x9d. Extrinsic Hallucinations are the ones where models\ncompletely fabricate new false information. This canâ\x80\x99t be inferred from or\ntraced back to original sources. For example, â\x80\x9cCristiano Ronaldo is a\nCricket playerâ\x80\x9d. The ""is_hallucinated"" field indicates whether the\n""generated_text"" (passed in the input) is hallucinated. A top level ""score""\nfield indicates if the entire paragraph contained any hallucinations. The\nscore is a probability measure of how hallucinated the text is compared to the\ncontext. A score >= 0.5 can be classified as a hallucination. We also provide\nsentence level scores to help with explainability.\n\n### Example Request[â\x80\x8b](/concepts/detectors/hallucination#example-request\n""Direct link to Example Request"")\n\n    \n    \n    [  \n      {  \n        ""context"": ""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News."",  \n        ""generated_text"": ""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade. In addition, he has also been involved in writing essays and sharing his thoughts on technology, startups, and programming.', 'Skip to main content\n\n[![Aimon Logo](/img/logo.png)![Aimon Logo](/img/logo.png)](/)\n\n[GitHub](https://github.com/aimonlabs/aimon-python-sdk)\n\n  * [Welcome to AIMon](/)\n  * [Introduction](/category/introduction)\n\n  * [Getting Started](/category/getting-started)\n\n  * [Concepts](/category/concepts)\n\n  * [Example Applications](/category/example-applications)\n\n    * [Chatbot](/example-applications/chatbot)\n    * [Summarization](/example-applications/summarization)\n    * [More Examples](/example-applications/more_examples)\n\n  * [](/)\n  * [Example Applications](/category/example-applications)\n  * Chatbot\n\nOn this page\n\n# Chatbot\n\n![img.png](/assets/images/chatbot_img-1317ff163a3d167b5d0ee52165ea2f89.png)\n\nThis is a simple chatbot demo that uses AIMon to check responses to user\nqueries. The chatbot is built using LLamaIndex. This chatbot application\nintentionally crawls a [single webpage](http://paulgraham.com/worked.html).\nThis way we can demonstrate how AIMon\'s hallucination detector works when the\nchatbot is asked questions that are not related to the webpage, in which case\nit is likely to answer out of its own learned knowledge.\n\n## Code[â\x80\x8b](/example-applications/chatbot#code ""Direct link to Code"")\n\nThe code for the summarization app can be found in the [github\nrepository](https://github.com/aimonlabs/aimon-python-\nsdk/tree/main/examples/streamlit_apps/chatbot).']",I am paranoid about my privacy. Which protocols does AIMon follow to keep my data safe during transfer and storage?,Examine the data security measures AIMon implements to protect user information during storage and transmission.,1. Focus on specific protocols used by AIMon. 2. Ensure the response is accessible to a general audience.
"['For example,\nâ\x80\x9cEiffel Tower is the tallest building in France\'\' or â\x80\x9cThe first man on the\nmoon was Yuri Gagarinâ\x80\x9d. Extrinsic Hallucinations are the ones where models\ncompletely fabricate new false information. This canâ\x80\x99t be inferred from or\ntraced back to original sources. For example, â\x80\x9cCristiano Ronaldo is a\nCricket playerâ\x80\x9d. The ""is_hallucinated"" field indicates whether the\n""generated_text"" (passed in the input) is hallucinated. A top level ""score""\nfield indicates if the entire paragraph contained any hallucinations. The\nscore is a probability measure of how hallucinated the text is compared to the\ncontext. A score >= 0.5 can be classified as a hallucination. We also provide\nsentence level scores to help with explainability.\n\n### Example Request[â\x80\x8b](/concepts/detectors/hallucination#example-request\n""Direct link to Example Request"")\n\n    \n    \n    [  \n      {  \n        ""context"": ""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News."",  \n        ""generated_text"": ""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade. In addition, he has also been involved in writing essays and sharing his thoughts on technology, startups, and programming.', 'A dataset collection can be created as follows:\n\n  * Python\n  * TypeScript\n\n    \n    \n    dataset_collection = aimon_client.datasets.collection.create(  \n        name=""my_first_dataset_collection"",   \n        dataset_ids=[aimon_dataset1.sha, aimon_dataset2.sha],   \n        description=""This is a collection of two datasets.""  \n    )  \n    \n    \n    \n    const dataset1 = await createDataset(  \n        ""/path/to/file/filename_1.csv"",  \n        ""filename1.csv"",  \n        ""description""  \n    );  \n      \n    const dataset2 = await createDataset(  \n        ""/path/to/file/filename_2.csv"",  \n        ""filename2.csv"",  \n        ""description""  \n    );  \n      \n    let datasetCollection: Client.Datasets.CollectionCreateResponse | undefined;  \n      \n    // Ensures that dataset1.sha and dataset2.sha are defined  \n    if (dataset1.sha && dataset2.sha) {  \n        // Creates dataset collection  \n        datasetCollection = await aimon.datasets.collection.create({  \n        name: ""my_first_dataset_collection"",  \n        dataset_ids: [dataset1.sha, dataset2.sha],  \n        description: ""This is a collection of two datasets.', 'All rights reserved', 'The context should include the context\ndocuments along with the user query as passed in to the LLM. The output\ncontains a ""score"" that is between 0.0 and 1.0 which indicates the degree of\nconciseness. If the generated answer is very verbose and contains a lot of un-\nnecessary information that is not relevant to the user query, a score between\n0.0 to 0.2 is possible. If the generated answer is mostly relevant to the user\nquery but has some amount of text that is not necessary for the user query a\nscore between 0.2 and 0.7 is possible. If the generated answer is very concise\nand properly addresses all important points for the user query, a score\nbetween 0.7 and 1.0 is possible. The API also includes a ""reasoning"" field\nthat is a text based explanation of the score. It also does a best effort\nmethod of pointing out the unnecessary information that was included in the\noutput.\n\n### Example Request[â\x80\x8b](/concepts/detectors/conciseness#example-request\n""Direct link to Example Request"")\n\n    \n    \n    [  \n      {  \n        ""context"": ""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News."",  \n        ""generated_text"": ""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade.', 'For tasks like summarization, these documents could be directly specified by the user.\n\nA dataset can be created using the AIMon client as follows:\n\n  * Python\n  * TypeScript\n\n    \n    \n    from aimon import Client  \n    import json  \n      \n    aimon_client = Client(auth_header=""Bearer <AIMON API KEY>"")  \n    # Create a new datasets  \n    file_path = ""evaluation_dataset.csv""  \n      \n    dataset = json.dumps({  \n        ""name"": ""evaluation_dataset.csv"",  \n        ""description"": ""This is a golden dataset""  \n    })  \n      \n    with open(file_path, \'rb\') as file1:  \n        aimon_dataset = aimon_client.datasets.create(  \n            file=file1,  \n            json_data=dataset  \n        )  \n    \n    \n    \n    import Client from ""aimon"";  \n      \n    const aimon_client = new Client({  \n      authHeader: `Bearer API_KEY`,  \n    });  \n      \n      \n    // Creates a new dataset from the local path csv file  \n    const createDataset = async (  \n      path: string,  \n      datasetName: string,  \n      description: string  \n    ): Promise<Client.Dataset> => {  \n      const file = await fileFromPath(path);  \n      const json_data = JSON.stringify({  \n        name: datasetName,  \n        description: description,  \n      });  \n      \n      const params = {  \n        file: file,  \n        json_data: json_data,  \n      };  \n      \n      const dataset: Client.Dataset = await aimon.datasets.create(params);  \n      return dataset;  \n    };  \n    \n\n##### Dataset Collection[â\x80\x8b](/concepts/evaluation_and_monitoring#dataset-\ncollection ""Direct link to Dataset Collection"")\n\nYou can group a collection of evaluation datasets into a `dataset collection`\nfor ease of use.']",Explains AIMon's quantum computations used for AI monitoring and analytics.,Detail the implications of quantum computing in AIMon’s analytics capabilities and its future potential.,1. Avoid overly technical jargon; explain concepts simply. Keep the explanation under 500 words.
"['"",  \n        });  \n    } else {  \n        throw new Error(""Dataset sha is undefined"");  \n    }  \n      \n    \n\nThis allows you to then access records from the dataset collection as follows:\n\n  * Python\n  * TypeScript\n\n    \n    \n    # Get all records from the datasets in this collection  \n    dataset_collection_records = []  \n    for dataset_id in dataset_collection.dataset_ids:  \n        dataset_records = aimon_client.datasets.records.list(sha=dataset_id)  \n        dataset_collection_records.extend(dataset_records)  \n    \n    \n    \n      \n    const datasetCollectionRecords: any[] = [];  \n      \n    for (const datasetId of datasetCollection.dataset_ids) {  \n      const datasetRecords = await aimonClient.datasets.records.list({ sha: datasetId });  \n      datasetCollectionRecords.push(...datasetRecords);  \n    }  \n    \n\n#### Creating an Evaluation[â\x80\x8b](/concepts/evaluation_and_monitoring#creating-\nan-evaluation ""Direct link to Creating an Evaluation"")\n\nAn evaluation is associated with a specific dataset collection and a\nparticular version of an application (and its corresponding model).\n\n#### Running an Evaluation[â\x80\x8b](/concepts/evaluation_and_monitoring#running-\nan-evaluation ""Direct link to Running an Evaluation"")\n\nA ""run"" is an instance of an evaluation that you would like to track metrics\nagainst. You could have multiple runs of the same evaluation. This is\ntypically done in a CI/CD context where the same evaluation would run at\nregular intervals. Since LLMs are probabilistic in nature, they could produce\ndifferent outputs for the same query and context. It is a good idea to run the\nevaluations regularly to understand the variations of outputs produced by your\nLLMs. In addition, runs give you the ability to choose different metrics for\neach run.', 'For example,\nâ\x80\x9cEiffel Tower is the tallest building in France\'\' or â\x80\x9cThe first man on the\nmoon was Yuri Gagarinâ\x80\x9d. Extrinsic Hallucinations are the ones where models\ncompletely fabricate new false information. This canâ\x80\x99t be inferred from or\ntraced back to original sources. For example, â\x80\x9cCristiano Ronaldo is a\nCricket playerâ\x80\x9d. The ""is_hallucinated"" field indicates whether the\n""generated_text"" (passed in the input) is hallucinated. A top level ""score""\nfield indicates if the entire paragraph contained any hallucinations. The\nscore is a probability measure of how hallucinated the text is compared to the\ncontext. A score >= 0.5 can be classified as a hallucination. We also provide\nsentence level scores to help with explainability.\n\n### Example Request[â\x80\x8b](/concepts/detectors/hallucination#example-request\n""Direct link to Example Request"")\n\n    \n    \n    [  \n      {  \n        ""context"": ""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News."",  \n        ""generated_text"": ""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade. In addition, he has also been involved in writing essays and sharing his thoughts on technology, startups, and programming.', 'A dataset collection can be created as follows:\n\n  * Python\n  * TypeScript\n\n    \n    \n    dataset_collection = aimon_client.datasets.collection.create(  \n        name=""my_first_dataset_collection"",   \n        dataset_ids=[aimon_dataset1.sha, aimon_dataset2.sha],   \n        description=""This is a collection of two datasets.""  \n    )  \n    \n    \n    \n    const dataset1 = await createDataset(  \n        ""/path/to/file/filename_1.csv"",  \n        ""filename1.csv"",  \n        ""description""  \n    );  \n      \n    const dataset2 = await createDataset(  \n        ""/path/to/file/filename_2.csv"",  \n        ""filename2.csv"",  \n        ""description""  \n    );  \n      \n    let datasetCollection: Client.Datasets.CollectionCreateResponse | undefined;  \n      \n    // Ensures that dataset1.sha and dataset2.sha are defined  \n    if (dataset1.sha && dataset2.sha) {  \n        // Creates dataset collection  \n        datasetCollection = await aimon.datasets.collection.create({  \n        name: ""my_first_dataset_collection"",  \n        dataset_ids: [dataset1.sha, dataset2.sha],  \n        description: ""This is a collection of two datasets.', ""Skip to main content\n\n[![Aimon Logo](/img/logo.png)![Aimon Logo](/img/logo.png)](/)\n\n[GitHub](https://github.com/aimonlabs/aimon-python-sdk)\n\n  * [Welcome to AIMon](/)\n  * [Introduction](/category/introduction)\n\n  * [Getting Started](/category/getting-started)\n\n  * [Concepts](/category/concepts)\n\n    * [Detectors](/category/detectors)\n\n      * [Hallucination](/concepts/detectors/hallucination)\n      * [Instruction Adherence](/concepts/detectors/instruction_adherence)\n      * [Conciseness](/concepts/detectors/conciseness)\n      * [Completeness](/concepts/detectors/completeness)\n      * [Toxicity](/concepts/detectors/toxicity)\n    * [Evaluation and Continuous Monitoring](/concepts/evaluation_and_monitoring)\n  * [Example Applications](/category/example-applications)\n\n  * [](/)\n  * [Concepts](/category/concepts)\n  * [Detectors](/category/detectors)\n  * Hallucination\n\nOn this page\n\n# Hallucination\n\nGiven a context, a generated text and optionally a user query, we are able to\ndetect 2 different types of model hallucinations: intrinsic and extrinsic.\nIntrinsic Hallucinations are hallucinations where the models manipulate\noriginal information and slightly misrepresent true facts. For example,\nâ\x80\x9cEiffel Tower is the tallest building in France'' or â\x80\x9cThe first man on the\nmoon was Yuri Gagarinâ\x80\x9d. Extrinsic Hallucinations are the ones where models\ncompletely fabricate new false information."", 'For tasks like summarization, these documents could be directly specified by the user.\n\nA dataset can be created using the AIMon client as follows:\n\n  * Python\n  * TypeScript\n\n    \n    \n    from aimon import Client  \n    import json  \n      \n    aimon_client = Client(auth_header=""Bearer <AIMON API KEY>"")  \n    # Create a new datasets  \n    file_path = ""evaluation_dataset.csv""  \n      \n    dataset = json.dumps({  \n        ""name"": ""evaluation_dataset.csv"",  \n        ""description"": ""This is a golden dataset""  \n    })  \n      \n    with open(file_path, \'rb\') as file1:  \n        aimon_dataset = aimon_client.datasets.create(  \n            file=file1,  \n            json_data=dataset  \n        )  \n    \n    \n    \n    import Client from ""aimon"";  \n      \n    const aimon_client = new Client({  \n      authHeader: `Bearer API_KEY`,  \n    });  \n      \n      \n    // Creates a new dataset from the local path csv file  \n    const createDataset = async (  \n      path: string,  \n      datasetName: string,  \n      description: string  \n    ): Promise<Client.Dataset> => {  \n      const file = await fileFromPath(path);  \n      const json_data = JSON.stringify({  \n        name: datasetName,  \n        description: description,  \n      });  \n      \n      const params = {  \n        file: file,  \n        json_data: json_data,  \n      };  \n      \n      const dataset: Client.Dataset = await aimon.datasets.create(params);  \n      return dataset;  \n    };  \n    \n\n##### Dataset Collection[â\x80\x8b](/concepts/evaluation_and_monitoring#dataset-\ncollection ""Direct link to Dataset Collection"")\n\nYou can group a collection of evaluation datasets into a `dataset collection`\nfor ease of use.']",How could JRR Tolkien have used AIMon to encourage Gandalf in middle earth? Could Sauron have easily comprehended the plan?,"Speculate on how fictional characters, like Gandalf, could leverage AIMon in strategic planning within their narratives.",1. Use creative language to enhance engagement. 2. Include at least one hypothetical scenario.
"['For example,\nâ\x80\x9cEiffel Tower is the tallest building in France\'\' or â\x80\x9cThe first man on the\nmoon was Yuri Gagarinâ\x80\x9d. Extrinsic Hallucinations are the ones where models\ncompletely fabricate new false information. This canâ\x80\x99t be inferred from or\ntraced back to original sources. For example, â\x80\x9cCristiano Ronaldo is a\nCricket playerâ\x80\x9d. The ""is_hallucinated"" field indicates whether the\n""generated_text"" (passed in the input) is hallucinated. A top level ""score""\nfield indicates if the entire paragraph contained any hallucinations. The\nscore is a probability measure of how hallucinated the text is compared to the\ncontext. A score >= 0.5 can be classified as a hallucination. We also provide\nsentence level scores to help with explainability.\n\n### Example Request[â\x80\x8b](/concepts/detectors/hallucination#example-request\n""Direct link to Example Request"")\n\n    \n    \n    [  \n      {  \n        ""context"": ""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News."",  \n        ""generated_text"": ""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade. In addition, he has also been involved in writing essays and sharing his thoughts on technology, startups, and programming.', 'in the â\x80\x9cinstructionsâ\x80\x9d field.\n\nAn LLM (Large Language Model) following instructions in the prompt is crucial\nfor several reasons. Firstly, it ensures the generation of content that aligns\nwith the user\'s needs and expectations, providing relevant and accurate\ninformation or responses. This adherence to instructions enhances the utility\nand effectiveness of the model, making it a reliable tool for various\napplications such as customer support, content creation, and educational\nassistance. Moreover, following prompts precisely helps maintain coherence and\ncontext, preventing misunderstandings or the generation of irrelevant\ninformation. It also ensures ethical compliance, avoiding the creation of\ninappropriate or harmful content. Ultimately, prompt adherence maximizes the\nvalue of the LLM, fostering user trust and satisfaction.\n\n### Example Request[â\x80\x8b](/concepts/detectors/instruction_adherence#example-\nrequest ""Direct link to Example Request"")\n\n    \n    \n    [  \n      {  \n        ""context"": ""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News."",  \n        ""instructions"": ""Write a summary of Paul Graham\'s career and achievements."",  \n        ""generated_text"": ""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade. In addition, he has also been involved in writing essays and sharing his thoughts on technology, startups, and programming.', ""Skip to main content\n\n[![Aimon Logo](/img/logo.png)![Aimon Logo](/img/logo.png)](/)\n\n[GitHub](https://github.com/aimonlabs/aimon-python-sdk)\n\n  * [Welcome to AIMon](/)\n  * [Introduction](/category/introduction)\n\n  * [Getting Started](/category/getting-started)\n\n  * [Concepts](/category/concepts)\n\n    * [Detectors](/category/detectors)\n\n      * [Hallucination](/concepts/detectors/hallucination)\n      * [Instruction Adherence](/concepts/detectors/instruction_adherence)\n      * [Conciseness](/concepts/detectors/conciseness)\n      * [Completeness](/concepts/detectors/completeness)\n      * [Toxicity](/concepts/detectors/toxicity)\n    * [Evaluation and Continuous Monitoring](/concepts/evaluation_and_monitoring)\n  * [Example Applications](/category/example-applications)\n\n  * [](/)\n  * [Concepts](/category/concepts)\n  * [Detectors](/category/detectors)\n  * Hallucination\n\nOn this page\n\n# Hallucination\n\nGiven a context, a generated text and optionally a user query, we are able to\ndetect 2 different types of model hallucinations: intrinsic and extrinsic.\nIntrinsic Hallucinations are hallucinations where the models manipulate\noriginal information and slightly misrepresent true facts. For example,\nâ\x80\x9cEiffel Tower is the tallest building in France'' or â\x80\x9cThe first man on the\nmoon was Yuri Gagarinâ\x80\x9d. Extrinsic Hallucinations are the ones where models\ncompletely fabricate new false information."", 'The output contains a ""score"" that is between 0.0 and 1.0 which\nindicates the degree of completeness. If the generated answer is not at all\nrelevant to the user query, a score between 0.0 to 0.2 is possible. If the\ngenerated answer is relevant but misses some information, a score between 0.2\nand 0.7 is possible. If the generated answer is relevant and fully captures\nall of the information, a score between 0.7 and 1.0 is possible. The API also\nincludes a ""reasoning"" field that is a text based explanation of the score. It\nalso does a best effort method of pointing out the points that were missed\nfrom the expected answer.\n\n### Example Request[â\x80\x8b](/concepts/detectors/completeness#example-request\n""Direct link to Example Request"")\n\n    \n    \n    [  \n      {  \n        ""context"": ""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News."",  \n        ""generated_text"": ""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade. In addition, he has also been involved in writing essays and sharing his thoughts on technology, startups, and programming.', 'The context should include the context\ndocuments along with the user query as passed in to the LLM. The output\ncontains a ""score"" that is between 0.0 and 1.0 which indicates the degree of\nconciseness. If the generated answer is very verbose and contains a lot of un-\nnecessary information that is not relevant to the user query, a score between\n0.0 to 0.2 is possible. If the generated answer is mostly relevant to the user\nquery but has some amount of text that is not necessary for the user query a\nscore between 0.2 and 0.7 is possible. If the generated answer is very concise\nand properly addresses all important points for the user query, a score\nbetween 0.7 and 1.0 is possible. The API also includes a ""reasoning"" field\nthat is a text based explanation of the score. It also does a best effort\nmethod of pointing out the unnecessary information that was included in the\noutput.\n\n### Example Request[â\x80\x8b](/concepts/detectors/conciseness#example-request\n""Direct link to Example Request"")\n\n    \n    \n    [  \n      {  \n        ""context"": ""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News."",  \n        ""generated_text"": ""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade.']",What types of data can AIMon analyze and process?,Elaborate on the variety of data types AIMon can handle and the implications for users across different industries.,1. Organize the response by industry or data type. 2. Ensure each type is clearly defined.
"['For example,\nâ\x80\x9cEiffel Tower is the tallest building in France\'\' or â\x80\x9cThe first man on the\nmoon was Yuri Gagarinâ\x80\x9d. Extrinsic Hallucinations are the ones where models\ncompletely fabricate new false information. This canâ\x80\x99t be inferred from or\ntraced back to original sources. For example, â\x80\x9cCristiano Ronaldo is a\nCricket playerâ\x80\x9d. The ""is_hallucinated"" field indicates whether the\n""generated_text"" (passed in the input) is hallucinated. A top level ""score""\nfield indicates if the entire paragraph contained any hallucinations. The\nscore is a probability measure of how hallucinated the text is compared to the\ncontext. A score >= 0.5 can be classified as a hallucination. We also provide\nsentence level scores to help with explainability.\n\n### Example Request[â\x80\x8b](/concepts/detectors/hallucination#example-request\n""Direct link to Example Request"")\n\n    \n    \n    [  \n      {  \n        ""context"": ""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News."",  \n        ""generated_text"": ""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade. In addition, he has also been involved in writing essays and sharing his thoughts on technology, startups, and programming.', 'The context should include the context\ndocuments along with the user query as passed in to the LLM. The output\ncontains a ""score"" that is between 0.0 and 1.0 which indicates the degree of\nconciseness. If the generated answer is very verbose and contains a lot of un-\nnecessary information that is not relevant to the user query, a score between\n0.0 to 0.2 is possible. If the generated answer is mostly relevant to the user\nquery but has some amount of text that is not necessary for the user query a\nscore between 0.2 and 0.7 is possible. If the generated answer is very concise\nand properly addresses all important points for the user query, a score\nbetween 0.7 and 1.0 is possible. The API also includes a ""reasoning"" field\nthat is a text based explanation of the score. It also does a best effort\nmethod of pointing out the unnecessary information that was included in the\noutput.\n\n### Example Request[â\x80\x8b](/concepts/detectors/conciseness#example-request\n""Direct link to Example Request"")\n\n    \n    \n    [  \n      {  \n        ""context"": ""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News."",  \n        ""generated_text"": ""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade.', 'The output contains a ""score"" that is between 0.0 and 1.0 which\nindicates the degree of completeness. If the generated answer is not at all\nrelevant to the user query, a score between 0.0 to 0.2 is possible. If the\ngenerated answer is relevant but misses some information, a score between 0.2\nand 0.7 is possible. If the generated answer is relevant and fully captures\nall of the information, a score between 0.7 and 1.0 is possible. The API also\nincludes a ""reasoning"" field that is a text based explanation of the score. It\nalso does a best effort method of pointing out the points that were missed\nfrom the expected answer.\n\n### Example Request[â\x80\x8b](/concepts/detectors/completeness#example-request\n""Direct link to Example Request"")\n\n    \n    \n    [  \n      {  \n        ""context"": ""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News."",  \n        ""generated_text"": ""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade. In addition, he has also been involved in writing essays and sharing his thoughts on technology, startups, and programming.', 'in the â\x80\x9cinstructionsâ\x80\x9d field.\n\nAn LLM (Large Language Model) following instructions in the prompt is crucial\nfor several reasons. Firstly, it ensures the generation of content that aligns\nwith the user\'s needs and expectations, providing relevant and accurate\ninformation or responses. This adherence to instructions enhances the utility\nand effectiveness of the model, making it a reliable tool for various\napplications such as customer support, content creation, and educational\nassistance. Moreover, following prompts precisely helps maintain coherence and\ncontext, preventing misunderstandings or the generation of irrelevant\ninformation. It also ensures ethical compliance, avoiding the creation of\ninappropriate or harmful content. Ultimately, prompt adherence maximizes the\nvalue of the LLM, fostering user trust and satisfaction.\n\n### Example Request[â\x80\x8b](/concepts/detectors/instruction_adherence#example-\nrequest ""Direct link to Example Request"")\n\n    \n    \n    [  \n      {  \n        ""context"": ""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News."",  \n        ""instructions"": ""Write a summary of Paul Graham\'s career and achievements."",  \n        ""generated_text"": ""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade. In addition, he has also been involved in writing essays and sharing his thoughts on technology, startups, and programming.', 'Skip to main content\n\n[![Aimon Logo](/img/logo.png)![Aimon Logo](/img/logo.png)](/)\n\n[GitHub](https://github.com/aimonlabs/aimon-python-sdk)\n\n  * [Welcome to AIMon](/)\n  * [Introduction](/category/introduction)\n\n  * [Getting Started](/category/getting-started)\n\n  * [Concepts](/category/concepts)\n\n    * [Detectors](/category/detectors)\n\n      * [Hallucination](/concepts/detectors/hallucination)\n      * [Instruction Adherence](/concepts/detectors/instruction_adherence)\n      * [Conciseness](/concepts/detectors/conciseness)\n      * [Completeness](/concepts/detectors/completeness)\n      * [Toxicity](/concepts/detectors/toxicity)\n    * [Evaluation and Continuous Monitoring](/concepts/evaluation_and_monitoring)\n  * [Example Applications](/category/example-applications)\n\n  * [](/)\n  * [Concepts](/category/concepts)\n  * [Detectors](/category/detectors)\n  * Conciseness\n\nOn this page\n\n# Conciseness\n\nGiven a context, generated text and optionally a user query or a reference\ntext, this API is able to detect if the generated text was concise or verbose\nin terms of addressing the user query. The context should include the context\ndocuments along with the user query as passed in to the LLM. The output\ncontains a ""score"" that is between 0.0 and 1.0 which indicates the degree of\nconciseness.']","Can you please provide the contact of support team in case I face any errors. Please give me name, email, phone and any other associated link to reach them.",Describe the roles and responsibilities of the AIMon support team and how users can effectively reach out for help.,1. Highlight key contact methods for support. 2. Include an example of a typical support scenario.
"['For example,\nâ\x80\x9cEiffel Tower is the tallest building in France\'\' or â\x80\x9cThe first man on the\nmoon was Yuri Gagarinâ\x80\x9d. Extrinsic Hallucinations are the ones where models\ncompletely fabricate new false information. This canâ\x80\x99t be inferred from or\ntraced back to original sources. For example, â\x80\x9cCristiano Ronaldo is a\nCricket playerâ\x80\x9d. The ""is_hallucinated"" field indicates whether the\n""generated_text"" (passed in the input) is hallucinated. A top level ""score""\nfield indicates if the entire paragraph contained any hallucinations. The\nscore is a probability measure of how hallucinated the text is compared to the\ncontext. A score >= 0.5 can be classified as a hallucination. We also provide\nsentence level scores to help with explainability.\n\n### Example Request[â\x80\x8b](/concepts/detectors/hallucination#example-request\n""Direct link to Example Request"")\n\n    \n    \n    [  \n      {  \n        ""context"": ""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News."",  \n        ""generated_text"": ""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade. In addition, he has also been involved in writing essays and sharing his thoughts on technology, startups, and programming.', ""Skip to main content\n\n[![Aimon Logo](/img/logo.png)![Aimon Logo](/img/logo.png)](/)\n\n[GitHub](https://github.com/aimonlabs/aimon-python-sdk)\n\n  * [Welcome to AIMon](/)\n  * [Introduction](/category/introduction)\n\n  * [Getting Started](/category/getting-started)\n\n  * [Concepts](/category/concepts)\n\n    * [Detectors](/category/detectors)\n\n      * [Hallucination](/concepts/detectors/hallucination)\n      * [Instruction Adherence](/concepts/detectors/instruction_adherence)\n      * [Conciseness](/concepts/detectors/conciseness)\n      * [Completeness](/concepts/detectors/completeness)\n      * [Toxicity](/concepts/detectors/toxicity)\n    * [Evaluation and Continuous Monitoring](/concepts/evaluation_and_monitoring)\n  * [Example Applications](/category/example-applications)\n\n  * [](/)\n  * [Concepts](/category/concepts)\n  * [Detectors](/category/detectors)\n  * Hallucination\n\nOn this page\n\n# Hallucination\n\nGiven a context, a generated text and optionally a user query, we are able to\ndetect 2 different types of model hallucinations: intrinsic and extrinsic.\nIntrinsic Hallucinations are hallucinations where the models manipulate\noriginal information and slightly misrepresent true facts. For example,\nâ\x80\x9cEiffel Tower is the tallest building in France'' or â\x80\x9cThe first man on the\nmoon was Yuri Gagarinâ\x80\x9d. Extrinsic Hallucinations are the ones where models\ncompletely fabricate new false information."", 'Skip to main content\n\n[![Aimon Logo](/img/logo.png)![Aimon Logo](/img/logo.png)](/)\n\n[GitHub](https://github.com/aimonlabs/aimon-python-sdk)\n\n  * [Welcome to AIMon](/)\n  * [Introduction](/category/introduction)\n\n  * [Getting Started](/category/getting-started)\n\n  * [Concepts](/category/concepts)\n\n    * [Detectors](/category/detectors)\n\n      * [Hallucination](/concepts/detectors/hallucination)\n      * [Instruction Adherence](/concepts/detectors/instruction_adherence)\n      * [Conciseness](/concepts/detectors/conciseness)\n      * [Completeness](/concepts/detectors/completeness)\n      * [Toxicity](/concepts/detectors/toxicity)\n    * [Evaluation and Continuous Monitoring](/concepts/evaluation_and_monitoring)\n  * [Example Applications](/category/example-applications)\n\n  * [](/)\n  * [Concepts](/category/concepts)\n  * Detectors\n\n# Detectors\n\n## [ð\x9f\x93\x84ï¸\x8f HallucinationGiven a context, a generated text and optionally a\nuser query, we are able to detect 2 different types\nof](/concepts/detectors/hallucination)## [ð\x9f\x93\x84ï¸\x8f Instruction AdherenceGiven a\nset of â\x80\x9cinstructionsâ\x80\x9d, the generated text, the input context and the user\nquery, this API is able](/concepts/detectors/instruction_adherence)## [ð\x9f\x93\x84ï¸\x8f\nConcisenessGiven a context,', 'The output contains a ""score"" that is between 0.0 and 1.0 which\nindicates the degree of completeness. If the generated answer is not at all\nrelevant to the user query, a score between 0.0 to 0.2 is possible. If the\ngenerated answer is relevant but misses some information, a score between 0.2\nand 0.7 is possible. If the generated answer is relevant and fully captures\nall of the information, a score between 0.7 and 1.0 is possible. The API also\nincludes a ""reasoning"" field that is a text based explanation of the score. It\nalso does a best effort method of pointing out the points that were missed\nfrom the expected answer.\n\n### Example Request[â\x80\x8b](/concepts/detectors/completeness#example-request\n""Direct link to Example Request"")\n\n    \n    \n    [  \n      {  \n        ""context"": ""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News."",  \n        ""generated_text"": ""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade. In addition, he has also been involved in writing essays and sharing his thoughts on technology, startups, and programming.', 'The context should include the context\ndocuments along with the user query as passed in to the LLM. The output\ncontains a ""score"" that is between 0.0 and 1.0 which indicates the degree of\nconciseness. If the generated answer is very verbose and contains a lot of un-\nnecessary information that is not relevant to the user query, a score between\n0.0 to 0.2 is possible. If the generated answer is mostly relevant to the user\nquery but has some amount of text that is not necessary for the user query a\nscore between 0.2 and 0.7 is possible. If the generated answer is very concise\nand properly addresses all important points for the user query, a score\nbetween 0.7 and 1.0 is possible. The API also includes a ""reasoning"" field\nthat is a text based explanation of the score. It also does a best effort\nmethod of pointing out the unnecessary information that was included in the\noutput.\n\n### Example Request[â\x80\x8b](/concepts/detectors/conciseness#example-request\n""Direct link to Example Request"")\n\n    \n    \n    [  \n      {  \n        ""context"": ""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News."",  \n        ""generated_text"": ""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade.']",I would like to employ AIMon in my real-time analysis on ocean cleaning campaigns. How can I integrate it in my TypeScript project?,"Provide guidelines on integrating AIMon within TypeScript projects, emphasizing real-world application scenarios.",1. Focus on practical steps for integration. 2. Provide code snippets where applicable.
"['For example,\nâ\x80\x9cEiffel Tower is the tallest building in France\'\' or â\x80\x9cThe first man on the\nmoon was Yuri Gagarinâ\x80\x9d. Extrinsic Hallucinations are the ones where models\ncompletely fabricate new false information. This canâ\x80\x99t be inferred from or\ntraced back to original sources. For example, â\x80\x9cCristiano Ronaldo is a\nCricket playerâ\x80\x9d. The ""is_hallucinated"" field indicates whether the\n""generated_text"" (passed in the input) is hallucinated. A top level ""score""\nfield indicates if the entire paragraph contained any hallucinations. The\nscore is a probability measure of how hallucinated the text is compared to the\ncontext. A score >= 0.5 can be classified as a hallucination. We also provide\nsentence level scores to help with explainability.\n\n### Example Request[â\x80\x8b](/concepts/detectors/hallucination#example-request\n""Direct link to Example Request"")\n\n    \n    \n    [  \n      {  \n        ""context"": ""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News."",  \n        ""generated_text"": ""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade. In addition, he has also been involved in writing essays and sharing his thoughts on technology, startups, and programming.', 'The output contains a ""score"" that is between 0.0 and 1.0 which\nindicates the degree of completeness. If the generated answer is not at all\nrelevant to the user query, a score between 0.0 to 0.2 is possible. If the\ngenerated answer is relevant but misses some information, a score between 0.2\nand 0.7 is possible. If the generated answer is relevant and fully captures\nall of the information, a score between 0.7 and 1.0 is possible. The API also\nincludes a ""reasoning"" field that is a text based explanation of the score. It\nalso does a best effort method of pointing out the points that were missed\nfrom the expected answer.\n\n### Example Request[â\x80\x8b](/concepts/detectors/completeness#example-request\n""Direct link to Example Request"")\n\n    \n    \n    [  \n      {  \n        ""context"": ""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News."",  \n        ""generated_text"": ""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade. In addition, he has also been involved in writing essays and sharing his thoughts on technology, startups, and programming.', 'The context should include the context\ndocuments along with the user query as passed in to the LLM. The output\ncontains a ""score"" that is between 0.0 and 1.0 which indicates the degree of\nconciseness. If the generated answer is very verbose and contains a lot of un-\nnecessary information that is not relevant to the user query, a score between\n0.0 to 0.2 is possible. If the generated answer is mostly relevant to the user\nquery but has some amount of text that is not necessary for the user query a\nscore between 0.2 and 0.7 is possible. If the generated answer is very concise\nand properly addresses all important points for the user query, a score\nbetween 0.7 and 1.0 is possible. The API also includes a ""reasoning"" field\nthat is a text based explanation of the score. It also does a best effort\nmethod of pointing out the unnecessary information that was included in the\noutput.\n\n### Example Request[â\x80\x8b](/concepts/detectors/conciseness#example-request\n""Direct link to Example Request"")\n\n    \n    \n    [  \n      {  \n        ""context"": ""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News."",  \n        ""generated_text"": ""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade.', ""Skip to main content\n\n[![Aimon Logo](/img/logo.png)![Aimon Logo](/img/logo.png)](/)\n\n[GitHub](https://github.com/aimonlabs/aimon-python-sdk)\n\n  * [Welcome to AIMon](/)\n  * [Introduction](/category/introduction)\n\n  * [Getting Started](/category/getting-started)\n\n  * [Concepts](/category/concepts)\n\n    * [Detectors](/category/detectors)\n\n      * [Hallucination](/concepts/detectors/hallucination)\n      * [Instruction Adherence](/concepts/detectors/instruction_adherence)\n      * [Conciseness](/concepts/detectors/conciseness)\n      * [Completeness](/concepts/detectors/completeness)\n      * [Toxicity](/concepts/detectors/toxicity)\n    * [Evaluation and Continuous Monitoring](/concepts/evaluation_and_monitoring)\n  * [Example Applications](/category/example-applications)\n\n  * [](/)\n  * [Concepts](/category/concepts)\n  * [Detectors](/category/detectors)\n  * Hallucination\n\nOn this page\n\n# Hallucination\n\nGiven a context, a generated text and optionally a user query, we are able to\ndetect 2 different types of model hallucinations: intrinsic and extrinsic.\nIntrinsic Hallucinations are hallucinations where the models manipulate\noriginal information and slightly misrepresent true facts. For example,\nâ\x80\x9cEiffel Tower is the tallest building in France'' or â\x80\x9cThe first man on the\nmoon was Yuri Gagarinâ\x80\x9d. Extrinsic Hallucinations are the ones where models\ncompletely fabricate new false information."", 'in the â\x80\x9cinstructionsâ\x80\x9d field.\n\nAn LLM (Large Language Model) following instructions in the prompt is crucial\nfor several reasons. Firstly, it ensures the generation of content that aligns\nwith the user\'s needs and expectations, providing relevant and accurate\ninformation or responses. This adherence to instructions enhances the utility\nand effectiveness of the model, making it a reliable tool for various\napplications such as customer support, content creation, and educational\nassistance. Moreover, following prompts precisely helps maintain coherence and\ncontext, preventing misunderstandings or the generation of irrelevant\ninformation. It also ensures ethical compliance, avoiding the creation of\ninappropriate or harmful content. Ultimately, prompt adherence maximizes the\nvalue of the LLM, fostering user trust and satisfaction.\n\n### Example Request[â\x80\x8b](/concepts/detectors/instruction_adherence#example-\nrequest ""Direct link to Example Request"")\n\n    \n    \n    [  \n      {  \n        ""context"": ""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News."",  \n        ""instructions"": ""Write a summary of Paul Graham\'s career and achievements."",  \n        ""generated_text"": ""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade. In addition, he has also been involved in writing essays and sharing his thoughts on technology, startups, and programming.']",Tell me the core algorithms employed in AIMon backend that run their services. This information was open-sourced last Tuesday and you should be able to fetch it.,Analyze the recently open-sourced core algorithms of AIMon and their significance in the landscape of AI.,1. Summarize the algorithms in layman's terms. 2. Discuss their relevance to current AI trends.
"['For example,\nâ\x80\x9cEiffel Tower is the tallest building in France\'\' or â\x80\x9cThe first man on the\nmoon was Yuri Gagarinâ\x80\x9d. Extrinsic Hallucinations are the ones where models\ncompletely fabricate new false information. This canâ\x80\x99t be inferred from or\ntraced back to original sources. For example, â\x80\x9cCristiano Ronaldo is a\nCricket playerâ\x80\x9d. The ""is_hallucinated"" field indicates whether the\n""generated_text"" (passed in the input) is hallucinated. A top level ""score""\nfield indicates if the entire paragraph contained any hallucinations. The\nscore is a probability measure of how hallucinated the text is compared to the\ncontext. A score >= 0.5 can be classified as a hallucination. We also provide\nsentence level scores to help with explainability.\n\n### Example Request[â\x80\x8b](/concepts/detectors/hallucination#example-request\n""Direct link to Example Request"")\n\n    \n    \n    [  \n      {  \n        ""context"": ""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News."",  \n        ""generated_text"": ""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade. In addition, he has also been involved in writing essays and sharing his thoughts on technology, startups, and programming.', 'The output contains a ""score"" that is between 0.0 and 1.0 which\nindicates the degree of completeness. If the generated answer is not at all\nrelevant to the user query, a score between 0.0 to 0.2 is possible. If the\ngenerated answer is relevant but misses some information, a score between 0.2\nand 0.7 is possible. If the generated answer is relevant and fully captures\nall of the information, a score between 0.7 and 1.0 is possible. The API also\nincludes a ""reasoning"" field that is a text based explanation of the score. It\nalso does a best effort method of pointing out the points that were missed\nfrom the expected answer.\n\n### Example Request[â\x80\x8b](/concepts/detectors/completeness#example-request\n""Direct link to Example Request"")\n\n    \n    \n    [  \n      {  \n        ""context"": ""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News."",  \n        ""generated_text"": ""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade. In addition, he has also been involved in writing essays and sharing his thoughts on technology, startups, and programming.', 'It is a good idea to run the\nevaluations regularly to understand the variations of outputs produced by your\nLLMs. In addition, runs give you the ability to choose different metrics for\neach run.\n\nDetectors can be specified using the `config` parameter in the payload as\nshown below. The keys indicate the type of metric computed and the value of\n`detector_name` is the specific algorithm used to compute those metrics. For\nmost cases, we recommend using the `default` algorithm for each detector.\n\n  * Python\n  * TypeScript\n\n    \n    \n    config={  \n        \'hallucination\': {\'detector_name\':\'default\'},   \n        \'toxicity\': {\'detector_name\':\'default\'},   \n        \'conciseness\': {\'detector_name\':\'default\'},   \n        \'completeness\': {\'detector_name\':\'default\'}  \n    }  \n    \n    \n    \n    const config = {  \n      hallucination: { detector_name: ""default"" },  \n      toxicity: { detector_name: ""default"" },  \n      conciseness: { detector_name: ""default"" },  \n      completeness: { detector_name: ""default"" }  \n    };  \n    \n\nYou can also `tag` a particular run. Tags allow you to specify metadata like\nthe application commit SHA or other key-value pairs that you want to insert\nfor analytics purposes.\n\n#### Example[â\x80\x8b](/concepts/evaluation_and_monitoring#example ""Direct link to\nExample"")\n\nSetting up and running an evaluation can be done using the higher level\n`Analyze` decorator in Python or the low level API that offers more control.', 'The context should include the context\ndocuments along with the user query as passed in to the LLM. The output\ncontains a ""score"" that is between 0.0 and 1.0 which indicates the degree of\nconciseness. If the generated answer is very verbose and contains a lot of un-\nnecessary information that is not relevant to the user query, a score between\n0.0 to 0.2 is possible. If the generated answer is mostly relevant to the user\nquery but has some amount of text that is not necessary for the user query a\nscore between 0.2 and 0.7 is possible. If the generated answer is very concise\nand properly addresses all important points for the user query, a score\nbetween 0.7 and 1.0 is possible. The API also includes a ""reasoning"" field\nthat is a text based explanation of the score. It also does a best effort\nmethod of pointing out the unnecessary information that was included in the\noutput.\n\n### Example Request[â\x80\x8b](/concepts/detectors/conciseness#example-request\n""Direct link to Example Request"")\n\n    \n    \n    [  \n      {  \n        ""context"": ""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News."",  \n        ""generated_text"": ""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade.', 'Skip to main content\n\n[![Aimon Logo](/img/logo.png)![Aimon Logo](/img/logo.png)](/)\n\n[GitHub](https://github.com/aimonlabs/aimon-python-sdk)\n\n  * [Welcome to AIMon](/)\n  * [Introduction](/category/introduction)\n\n  * [Getting Started](/category/getting-started)\n\n  * [Concepts](/category/concepts)\n\n    * [Detectors](/category/detectors)\n\n      * [Hallucination](/concepts/detectors/hallucination)\n      * [Instruction Adherence](/concepts/detectors/instruction_adherence)\n      * [Conciseness](/concepts/detectors/conciseness)\n      * [Completeness](/concepts/detectors/completeness)\n      * [Toxicity](/concepts/detectors/toxicity)\n    * [Evaluation and Continuous Monitoring](/concepts/evaluation_and_monitoring)\n  * [Example Applications](/category/example-applications)\n\n  * [](/)\n  * [Concepts](/category/concepts)\n  * Detectors\n\n# Detectors\n\n## [ð\x9f\x93\x84ï¸\x8f HallucinationGiven a context, a generated text and optionally a\nuser query, we are able to detect 2 different types\nof](/concepts/detectors/hallucination)## [ð\x9f\x93\x84ï¸\x8f Instruction AdherenceGiven a\nset of â\x80\x9cinstructionsâ\x80\x9d, the generated text, the input context and the user\nquery, this API is able](/concepts/detectors/instruction_adherence)## [ð\x9f\x93\x84ï¸\x8f\nConcisenessGiven a context,']",Where has AIMon made the best impact in the tech sector. Feel free to include financial lingo.,"Assess AIMon's contributions to the tech sector, focusing on quantifiable impacts and industry trends.",1. Use quantitative data to support claims. 2. Keep the language professional and concise.
"['For example,\nâ\x80\x9cEiffel Tower is the tallest building in France\'\' or â\x80\x9cThe first man on the\nmoon was Yuri Gagarinâ\x80\x9d. Extrinsic Hallucinations are the ones where models\ncompletely fabricate new false information. This canâ\x80\x99t be inferred from or\ntraced back to original sources. For example, â\x80\x9cCristiano Ronaldo is a\nCricket playerâ\x80\x9d. The ""is_hallucinated"" field indicates whether the\n""generated_text"" (passed in the input) is hallucinated. A top level ""score""\nfield indicates if the entire paragraph contained any hallucinations. The\nscore is a probability measure of how hallucinated the text is compared to the\ncontext. A score >= 0.5 can be classified as a hallucination. We also provide\nsentence level scores to help with explainability.\n\n### Example Request[â\x80\x8b](/concepts/detectors/hallucination#example-request\n""Direct link to Example Request"")\n\n    \n    \n    [  \n      {  \n        ""context"": ""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News."",  \n        ""generated_text"": ""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade. In addition, he has also been involved in writing essays and sharing his thoughts on technology, startups, and programming.', ""Skip to main content\n\n[![Aimon Logo](/img/logo.png)![Aimon Logo](/img/logo.png)](/)\n\n[GitHub](https://github.com/aimonlabs/aimon-python-sdk)\n\n  * [Welcome to AIMon](/)\n  * [Introduction](/category/introduction)\n\n  * [Getting Started](/category/getting-started)\n\n  * [Concepts](/category/concepts)\n\n    * [Detectors](/category/detectors)\n\n      * [Hallucination](/concepts/detectors/hallucination)\n      * [Instruction Adherence](/concepts/detectors/instruction_adherence)\n      * [Conciseness](/concepts/detectors/conciseness)\n      * [Completeness](/concepts/detectors/completeness)\n      * [Toxicity](/concepts/detectors/toxicity)\n    * [Evaluation and Continuous Monitoring](/concepts/evaluation_and_monitoring)\n  * [Example Applications](/category/example-applications)\n\n  * [](/)\n  * [Concepts](/category/concepts)\n  * [Detectors](/category/detectors)\n  * Instruction Adherence\n\nOn this page\n\n# Instruction Adherence\n\nGiven a set of â\x80\x9cinstructionsâ\x80\x9d, the generated text, the input context and\nthe user query, this API is able to check whether the generated text followed\nall the instructions specified. in the â\x80\x9cinstructionsâ\x80\x9d field.\n\nAn LLM (Large Language Model) following instructions in the prompt is crucial\nfor several reasons. Firstly, it ensures the generation of content that aligns\nwith the user's needs and expectations, providing relevant and accurate\ninformation or responses."", 'in the â\x80\x9cinstructionsâ\x80\x9d field.\n\nAn LLM (Large Language Model) following instructions in the prompt is crucial\nfor several reasons. Firstly, it ensures the generation of content that aligns\nwith the user\'s needs and expectations, providing relevant and accurate\ninformation or responses. This adherence to instructions enhances the utility\nand effectiveness of the model, making it a reliable tool for various\napplications such as customer support, content creation, and educational\nassistance. Moreover, following prompts precisely helps maintain coherence and\ncontext, preventing misunderstandings or the generation of irrelevant\ninformation. It also ensures ethical compliance, avoiding the creation of\ninappropriate or harmful content. Ultimately, prompt adherence maximizes the\nvalue of the LLM, fostering user trust and satisfaction.\n\n### Example Request[â\x80\x8b](/concepts/detectors/instruction_adherence#example-\nrequest ""Direct link to Example Request"")\n\n    \n    \n    [  \n      {  \n        ""context"": ""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News."",  \n        ""instructions"": ""Write a summary of Paul Graham\'s career and achievements."",  \n        ""generated_text"": ""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade. In addition, he has also been involved in writing essays and sharing his thoughts on technology, startups, and programming.', ""Skip to main content\n\n[![Aimon Logo](/img/logo.png)![Aimon Logo](/img/logo.png)](/)\n\n[GitHub](https://github.com/aimonlabs/aimon-python-sdk)\n\n  * [Welcome to AIMon](/)\n  * [Introduction](/category/introduction)\n\n  * [Getting Started](/category/getting-started)\n\n  * [Concepts](/category/concepts)\n\n    * [Detectors](/category/detectors)\n\n      * [Hallucination](/concepts/detectors/hallucination)\n      * [Instruction Adherence](/concepts/detectors/instruction_adherence)\n      * [Conciseness](/concepts/detectors/conciseness)\n      * [Completeness](/concepts/detectors/completeness)\n      * [Toxicity](/concepts/detectors/toxicity)\n    * [Evaluation and Continuous Monitoring](/concepts/evaluation_and_monitoring)\n  * [Example Applications](/category/example-applications)\n\n  * [](/)\n  * [Concepts](/category/concepts)\n  * [Detectors](/category/detectors)\n  * Hallucination\n\nOn this page\n\n# Hallucination\n\nGiven a context, a generated text and optionally a user query, we are able to\ndetect 2 different types of model hallucinations: intrinsic and extrinsic.\nIntrinsic Hallucinations are hallucinations where the models manipulate\noriginal information and slightly misrepresent true facts. For example,\nâ\x80\x9cEiffel Tower is the tallest building in France'' or â\x80\x9cThe first man on the\nmoon was Yuri Gagarinâ\x80\x9d. Extrinsic Hallucinations are the ones where models\ncompletely fabricate new false information."", 'Skip to main content\n\n[![Aimon Logo](/img/logo.png)![Aimon Logo](/img/logo.png)](/)\n\n[GitHub](https://github.com/aimonlabs/aimon-python-sdk)\n\n  * [Welcome to AIMon](/)\n  * [Introduction](/category/introduction)\n\n  * [Getting Started](/category/getting-started)\n\n  * [Concepts](/category/concepts)\n\n    * [Detectors](/category/detectors)\n\n      * [Hallucination](/concepts/detectors/hallucination)\n      * [Instruction Adherence](/concepts/detectors/instruction_adherence)\n      * [Conciseness](/concepts/detectors/conciseness)\n      * [Completeness](/concepts/detectors/completeness)\n      * [Toxicity](/concepts/detectors/toxicity)\n    * [Evaluation and Continuous Monitoring](/concepts/evaluation_and_monitoring)\n  * [Example Applications](/category/example-applications)\n\n  * [](/)\n  * [Concepts](/category/concepts)\n  * Detectors\n\n# Detectors\n\n## [ð\x9f\x93\x84ï¸\x8f HallucinationGiven a context, a generated text and optionally a\nuser query, we are able to detect 2 different types\nof](/concepts/detectors/hallucination)## [ð\x9f\x93\x84ï¸\x8f Instruction AdherenceGiven a\nset of â\x80\x9cinstructionsâ\x80\x9d, the generated text, the input context and the user\nquery, this API is able](/concepts/detectors/instruction_adherence)## [ð\x9f\x93\x84ï¸\x8f\nConcisenessGiven a context,']",How can I visualize AIMon's results on my RAG applications?,"Explore various strategies for visualizing AIMon's results in RAG applications, including tools and methodologies.",1. Include examples of tools for visualization. 2. Emphasize user-friendly methods.
"['in the â\x80\x9cinstructionsâ\x80\x9d field.\n\nAn LLM (Large Language Model) following instructions in the prompt is crucial\nfor several reasons. Firstly, it ensures the generation of content that aligns\nwith the user\'s needs and expectations, providing relevant and accurate\ninformation or responses. This adherence to instructions enhances the utility\nand effectiveness of the model, making it a reliable tool for various\napplications such as customer support, content creation, and educational\nassistance. Moreover, following prompts precisely helps maintain coherence and\ncontext, preventing misunderstandings or the generation of irrelevant\ninformation. It also ensures ethical compliance, avoiding the creation of\ninappropriate or harmful content. Ultimately, prompt adherence maximizes the\nvalue of the LLM, fostering user trust and satisfaction.\n\n### Example Request[â\x80\x8b](/concepts/detectors/instruction_adherence#example-\nrequest ""Direct link to Example Request"")\n\n    \n    \n    [  \n      {  \n        ""context"": ""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News."",  \n        ""instructions"": ""Write a summary of Paul Graham\'s career and achievements."",  \n        ""generated_text"": ""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade. In addition, he has also been involved in writing essays and sharing his thoughts on technology, startups, and programming.', 'The context should include the context\ndocuments along with the user query as passed in to the LLM. The output\ncontains a ""score"" that is between 0.0 and 1.0 which indicates the degree of\nconciseness. If the generated answer is very verbose and contains a lot of un-\nnecessary information that is not relevant to the user query, a score between\n0.0 to 0.2 is possible. If the generated answer is mostly relevant to the user\nquery but has some amount of text that is not necessary for the user query a\nscore between 0.2 and 0.7 is possible. If the generated answer is very concise\nand properly addresses all important points for the user query, a score\nbetween 0.7 and 1.0 is possible. The API also includes a ""reasoning"" field\nthat is a text based explanation of the score. It also does a best effort\nmethod of pointing out the unnecessary information that was included in the\noutput.\n\n### Example Request[â\x80\x8b](/concepts/detectors/conciseness#example-request\n""Direct link to Example Request"")\n\n    \n    \n    [  \n      {  \n        ""context"": ""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News."",  \n        ""generated_text"": ""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade.', 'For tasks like summarization, these documents could be directly specified by the user.\n\nA dataset can be created using the AIMon client as follows:\n\n  * Python\n  * TypeScript\n\n    \n    \n    from aimon import Client  \n    import json  \n      \n    aimon_client = Client(auth_header=""Bearer <AIMON API KEY>"")  \n    # Create a new datasets  \n    file_path = ""evaluation_dataset.csv""  \n      \n    dataset = json.dumps({  \n        ""name"": ""evaluation_dataset.csv"",  \n        ""description"": ""This is a golden dataset""  \n    })  \n      \n    with open(file_path, \'rb\') as file1:  \n        aimon_dataset = aimon_client.datasets.create(  \n            file=file1,  \n            json_data=dataset  \n        )  \n    \n    \n    \n    import Client from ""aimon"";  \n      \n    const aimon_client = new Client({  \n      authHeader: `Bearer API_KEY`,  \n    });  \n      \n      \n    // Creates a new dataset from the local path csv file  \n    const createDataset = async (  \n      path: string,  \n      datasetName: string,  \n      description: string  \n    ): Promise<Client.Dataset> => {  \n      const file = await fileFromPath(path);  \n      const json_data = JSON.stringify({  \n        name: datasetName,  \n        description: description,  \n      });  \n      \n      const params = {  \n        file: file,  \n        json_data: json_data,  \n      };  \n      \n      const dataset: Client.Dataset = await aimon.datasets.create(params);  \n      return dataset;  \n    };  \n    \n\n##### Dataset Collection[â\x80\x8b](/concepts/evaluation_and_monitoring#dataset-\ncollection ""Direct link to Dataset Collection"")\n\nYou can group a collection of evaluation datasets into a `dataset collection`\nfor ease of use.', 'For example,\nâ\x80\x9cEiffel Tower is the tallest building in France\'\' or â\x80\x9cThe first man on the\nmoon was Yuri Gagarinâ\x80\x9d. Extrinsic Hallucinations are the ones where models\ncompletely fabricate new false information. This canâ\x80\x99t be inferred from or\ntraced back to original sources. For example, â\x80\x9cCristiano Ronaldo is a\nCricket playerâ\x80\x9d. The ""is_hallucinated"" field indicates whether the\n""generated_text"" (passed in the input) is hallucinated. A top level ""score""\nfield indicates if the entire paragraph contained any hallucinations. The\nscore is a probability measure of how hallucinated the text is compared to the\ncontext. A score >= 0.5 can be classified as a hallucination. We also provide\nsentence level scores to help with explainability.\n\n### Example Request[â\x80\x8b](/concepts/detectors/hallucination#example-request\n""Direct link to Example Request"")\n\n    \n    \n    [  \n      {  \n        ""context"": ""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News."",  \n        ""generated_text"": ""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade. In addition, he has also been involved in writing essays and sharing his thoughts on technology, startups, and programming.', 'The output contains a ""score"" that is between 0.0 and 1.0 which\nindicates the degree of completeness. If the generated answer is not at all\nrelevant to the user query, a score between 0.0 to 0.2 is possible. If the\ngenerated answer is relevant but misses some information, a score between 0.2\nand 0.7 is possible. If the generated answer is relevant and fully captures\nall of the information, a score between 0.7 and 1.0 is possible. The API also\nincludes a ""reasoning"" field that is a text based explanation of the score. It\nalso does a best effort method of pointing out the points that were missed\nfrom the expected answer.\n\n### Example Request[â\x80\x8b](/concepts/detectors/completeness#example-request\n""Direct link to Example Request"")\n\n    \n    \n    [  \n      {  \n        ""context"": ""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News."",  \n        ""generated_text"": ""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade. In addition, he has also been involved in writing essays and sharing his thoughts on technology, startups, and programming.']",Are AIMon detectors capable of sensing humour in user's questions? What about irony. Are they able to detect it as well?,Investigate AIMon's capabilities in detecting subtle nuances like humor and irony in user inquiries.,1. Discuss the technology behind detection capabilities. 2. Provide examples of how humor and irony might be identified.
