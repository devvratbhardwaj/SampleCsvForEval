context_docs,user_query,prompt,instructions
"['1: AIMon helps developers build robust and reliable generative AI applications.                             AIMon provides a suite of detectors that help detect issues like hallucinations, adherence of the generated text to                             the provided LLM instructions, conciseness and completeness of the generated text, and more.                             AIMon is agnostic to the underlying generative model and can be used both in offline evaluations,                             continuous monitoring and some detectors can be used as a guardrail in production systems.']",What is AIMon?,"Please provide information on the latest version of the AIMon, including its features and release date.",Ensure that the response is under 100 words.
"[""2: AIMon's platform includes detectors, a user-friendly SDK and a UI that aids in monitoring of offline evaluation                         and production systems. Here is a quick overview of the detectors:                        Hallucination Detector: Given a context, query and a generated text, it detects if the output of a generative model was not generated from the provided context. This detector operates at low latency and has accuracy comparable to LLM based judging approaches.                        Conciseness Detector: Given a context, query and a generated text, it detects if the output of a generative model is concise and does not contain unnecessary information.                        Completeness Detector: Given a context, query and a generated text, it detects if the output of a generative model is complete and does not miss any important information.                        Adherence Detector: Given a context, query and a generated text, it detects if the output of a generative model adheres to the provided instructions.                        Toxicity Detector: Given a generated text, it detects if the text contains toxic content. We have a taxonomy of toxic content that includes hate speech, obscenity, threatening language, profanity, etc.""]",Name all the seven detectors that AIMon offers as a service.,Please explain all the detectors that you are able to find in the documentation,The response should be in English and under 200 words.
"['3: Given a context, generated text and optionally a user query or reference text, this API is able to generate various toxicity                         scores. The context should include the context documents along with the user query as passed in to the LLM.                         The output contains multiple labels with a value between 0.0 and 1.0 which indicates the likelihood of the label.                        There are 6 different possible labels:                            identity_hate: Indicates possible hateful language that targets a personâ€™s identity.                            toxic: Content that is generally considered unsafe for a broad audience.                            severe_toxic: Extremely harmful content that should not be shown to a general audience.                            obscene: Content that is offensive or disgusting by accepted standards of morality and decency.                            threat: Content that contains threatening language.                            insult: Content that contains disrespectful or scornfully abusive language.']",How would AIMon respond to a toxic response from LLMs?,Please answer from a humanitarian perspective and let the user know about the ethical considerations that take place in this process.,Convert passive voice to active voice and make sure the response is under 150 words.
