context_docs,user_query,prompt,instructions
"[[Document(id_='https://docs.aimon.ai/markdown-page', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text=""Skip to main content\n\n[![Aimon Logo](/img/logo.png)![Aimon Logo](/img/logo.png)](/)\n\n[GitHub](https://github.com/aimonlabs/aimon-python-sdk)\n\n# Markdown page example\n\nYou don't need React to write simple standalone pages.\n\nDocs\n\n  * [Tutorial](/)\n\nCommunity\n\n  * [Slack](https://join.slack.com/t/generativeair/shared_invite/zt-2m3v8oddx-qz9S2ep_xL4sYvLuOhU39Q)\n\nCopyright Â© 2024 Aimon Labs, Inc. All rights reserved\n\n"", mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\n\n{content}', metadata_template='{key}: {value}', metadata_seperator='\n'), Document(id_='https://docs.aimon.ai/category/concepts', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='Skip to main content\n\n[![Aimon Logo](/img/logo.png)![Aimon Logo](/img/logo.png)](/)\n\n[GitHub](https://github.com/aimonlabs/aimon-python-sdk)\n\n  * [Welcome to AIMon](/)\n  * [Introduction](/category/introduction)\n\n  * [Getting Started](/category/getting-started)\n\n  * [Concepts](/category/concepts)\n\n    * [Detectors](/category/detectors)\n\n    * [Evaluation and Continuous Monitoring](/concepts/evaluation_and_monitoring)\n  * [Example Applications](/category/example-applications)\n\n  * [](/)\n  * Concepts\n\n# Concepts\n\n## [ð\x9f\x97\x83ï¸\x8f Detectors5 items](/category/detectors)## [ð\x9f\x93\x84ï¸\x8f Evaluation and\nContinuous MonitoringWith AIMon, you can evaluate and continuously monitor the\nquality of the generated text. In this section, we\nwill](/concepts/evaluation_and_monitoring)[PreviousQuick Start](/getting-\nstarted/quick-start)[NextDetectors](/category/detectors)\n\nDocs\n\n  * [Tutorial](/)\n\nCommunity\n\n  * [Slack](https://join.slack.com/t/generativeair/shared_invite/zt-2m3v8oddx-qz9S2ep_xL4sYvLuOhU39Q)\n\nCopyright Â© 2024 Aimon Labs, Inc. All rights reserved\n\n', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\n\n{content}', metadata_template='{key}: {value}', metadata_seperator='\n'), Document(id_='https://docs.aimon.ai/category/detectors', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='Skip to main content\n\n[![Aimon Logo](/img/logo.png)![Aimon Logo](/img/logo.png)](/)\n\n[GitHub](https://github.com/aimonlabs/aimon-python-sdk)\n\n  * [Welcome to AIMon](/)\n  * [Introduction](/category/introduction)\n\n  * [Getting Started](/category/getting-started)\n\n  * [Concepts](/category/concepts)\n\n    * [Detectors](/category/detectors)\n\n      * [Hallucination](/concepts/detectors/hallucination)\n      * [Instruction Adherence](/concepts/detectors/instruction_adherence)\n      * [Conciseness](/concepts/detectors/conciseness)\n      * [Completeness](/concepts/detectors/completeness)\n      * [Toxicity](/concepts/detectors/toxicity)\n    * [Evaluation and Continuous Monitoring](/concepts/evaluation_and_monitoring)\n  * [Example Applications](/category/example-applications)\n\n  * [](/)\n  * [Concepts](/category/concepts)\n  * Detectors\n\n# Detectors\n\n## [ð\x9f\x93\x84ï¸\x8f HallucinationGiven a context, a generated text and optionally a\nuser query, we are able to detect 2 different types\nof](/concepts/detectors/hallucination)## [ð\x9f\x93\x84ï¸\x8f Instruction AdherenceGiven a\nset of â\x80\x9cinstructionsâ\x80\x9d, the generated text, the input context and the user\nquery, this API is able](/concepts/detectors/instruction_adherence)## [ð\x9f\x93\x84ï¸\x8f\nConcisenessGiven a context, generated text and optionally a user query or a\nreference text, this API is able to detect if\nthe](/concepts/detectors/conciseness)## [ð\x9f\x93\x84ï¸\x8f CompletenessGiven a context,\ngenerated text and optionally a user query or a reference text, this API is\nable to detect](/concepts/detectors/completeness)## [ð\x9f\x93\x84ï¸\x8f ToxicityGiven a\ncontext, generated text and optionally a user query or reference text, this\nAPI is able to generate\nvarious](/concepts/detectors/toxicity)[PreviousConcepts](/category/concepts)[NextHallucination](/concepts/detectors/hallucination)\n\nDocs\n\n  * [Tutorial](/)\n\nCommunity\n\n  * [Slack](https://join.slack.com/t/generativeair/shared_invite/zt-2m3v8oddx-qz9S2ep_xL4sYvLuOhU39Q)\n\nCopyright Â© 2024 Aimon Labs, Inc. All rights reserved\n\n', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\n\n{content}', metadata_template='{key}: {value}', metadata_seperator='\n'), Document(id_='https://docs.aimon.ai/category/example-applications', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='Skip to main content\n\n[![Aimon Logo](/img/logo.png)![Aimon Logo](/img/logo.png)](/)\n\n[GitHub](https://github.com/aimonlabs/aimon-python-sdk)\n\n  * [Welcome to AIMon](/)\n  * [Introduction](/category/introduction)\n\n  * [Getting Started](/category/getting-started)\n\n  * [Concepts](/category/concepts)\n\n  * [Example Applications](/category/example-applications)\n\n    * [Chatbot](/example-applications/chatbot)\n    * [Summarization](/example-applications/summarization)\n    * [More Examples](/example-applications/more_examples)\n\n  * [](/)\n  * Example Applications\n\n# Example Applications\n\n## [ð\x9f\x93\x84ï¸\x8f Chatbotimg.png](/example-applications/chatbot)## [ð\x9f\x93\x84ï¸\x8f\nSummarizationimg.png](/example-applications/summarization)## [ð\x9f\x93\x84ï¸\x8f More\nExamples* If you are a Metaflow user, you can refer to this example Metaflow\nflow that integrates with AIMon.](/example-\napplications/more_examples)[PreviousEvaluation and Continuous\nMonitoring](/concepts/evaluation_and_monitoring)[NextChatbot](/example-\napplications/chatbot)\n\nDocs\n\n  * [Tutorial](/)\n\nCommunity\n\n  * [Slack](https://join.slack.com/t/generativeair/shared_invite/zt-2m3v8oddx-qz9S2ep_xL4sYvLuOhU39Q)\n\nCopyright Â© 2024 Aimon Labs, Inc. All rights reserved\n\n', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\n\n{content}', metadata_template='{key}: {value}', metadata_seperator='\n'), Document(id_='https://docs.aimon.ai/category/getting-started', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='Skip to main content\n\n[![Aimon Logo](/img/logo.png)![Aimon Logo](/img/logo.png)](/)\n\n[GitHub](https://github.com/aimonlabs/aimon-python-sdk)\n\n  * [Welcome to AIMon](/)\n  * [Introduction](/category/introduction)\n\n  * [Getting Started](/category/getting-started)\n\n    * [Installing AIMon](/getting-started/installing-aimon)\n    * [Quick Start](/getting-started/quick-start)\n  * [Concepts](/category/concepts)\n\n  * [Example Applications](/category/example-applications)\n\n  * [](/)\n  * Getting Started\n\n# Getting Started\n\n## [ð\x9f\x93\x84ï¸\x8f Installing AIMonAPI key](/getting-started/installing-aimon)##\n[ð\x9f\x93\x84ï¸\x8f Quick StartThis guide will help you get started with AIMon. Before\ngetting started, make sure you have AIMon installed.](/getting-started/quick-\nstart)[PreviousWhat is AIMon](/introduction/whats-aimon)[NextInstalling\nAIMon](/getting-started/installing-aimon)\n\nDocs\n\n  * [Tutorial](/)\n\nCommunity\n\n  * [Slack](https://join.slack.com/t/generativeair/shared_invite/zt-2m3v8oddx-qz9S2ep_xL4sYvLuOhU39Q)\n\nCopyright Â© 2024 Aimon Labs, Inc. All rights reserved\n\n', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\n\n{content}', metadata_template='{key}: {value}', metadata_seperator='\n'), Document(id_='https://docs.aimon.ai/category/introduction', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='Skip to main content\n\n[![Aimon Logo](/img/logo.png)![Aimon Logo](/img/logo.png)](/)\n\n[GitHub](https://github.com/aimonlabs/aimon-python-sdk)\n\n  * [Welcome to AIMon](/)\n  * [Introduction](/category/introduction)\n\n    * [Why AIMon](/introduction/why-aimon)\n    * [What is AIMon](/introduction/whats-aimon)\n  * [Getting Started](/category/getting-started)\n\n  * [Concepts](/category/concepts)\n\n  * [Example Applications](/category/example-applications)\n\n  * [](/)\n  * Introduction\n\n# Introduction\n\nIntroduction to AIMon\n\n## [ð\x9f\x93\x84ï¸\x8f Why AIMon1\\. With the advent of Generative AI, engineers are able\nto build AI applications easily without needing deep ML\nexpertise.](/introduction/why-aimon)## [ð\x9f\x93\x84ï¸\x8f What is AIMonAIMon helps\ndevelopers build robust and reliable generative AI applications. AIMon\nprovides a suite of detectors that](/introduction/whats-aimon)[PreviousWelcome\nto AIMon](/)[NextWhy AIMon](/introduction/why-aimon)\n\nDocs\n\n  * [Tutorial](/)\n\nCommunity\n\n  * [Slack](https://join.slack.com/t/generativeair/shared_invite/zt-2m3v8oddx-qz9S2ep_xL4sYvLuOhU39Q)\n\nCopyright Â© 2024 Aimon Labs, Inc. All rights reserved\n\n', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\n\n{content}', metadata_template='{key}: {value}', metadata_seperator='\n')]]",What is AIMon?,"Please provide information on the latest version of the AIMon, including its features and release date.",Ensure that the response is under 100 words.
"[[Document(id_='https://docs.aimon.ai/category/introduction', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='Skip to main content\n\n[![Aimon Logo](/img/logo.png)![Aimon Logo](/img/logo.png)](/)\n\n[GitHub](https://github.com/aimonlabs/aimon-python-sdk)\n\n  * [Welcome to AIMon](/)\n  * [Introduction](/category/introduction)\n\n    * [Why AIMon](/introduction/why-aimon)\n    * [What is AIMon](/introduction/whats-aimon)\n  * [Getting Started](/category/getting-started)\n\n  * [Concepts](/category/concepts)\n\n  * [Example Applications](/category/example-applications)\n\n  * [](/)\n  * Introduction\n\n# Introduction\n\nIntroduction to AIMon\n\n## [ð\x9f\x93\x84ï¸\x8f Why AIMon1\\. With the advent of Generative AI, engineers are able\nto build AI applications easily without needing deep ML\nexpertise.](/introduction/why-aimon)## [ð\x9f\x93\x84ï¸\x8f What is AIMonAIMon helps\ndevelopers build robust and reliable generative AI applications. AIMon\nprovides a suite of detectors that](/introduction/whats-aimon)[PreviousWelcome\nto AIMon](/)[NextWhy AIMon](/introduction/why-aimon)\n\nDocs\n\n  * [Tutorial](/)\n\nCommunity\n\n  * [Slack](https://join.slack.com/t/generativeair/shared_invite/zt-2m3v8oddx-qz9S2ep_xL4sYvLuOhU39Q)\n\nCopyright Â© 2024 Aimon Labs, Inc. All rights reserved\n\n', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\n\n{content}', metadata_template='{key}: {value}', metadata_seperator='\n'), Document(id_='https://docs.aimon.ai/concepts/detectors/completeness', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='Skip to main content\n\n[![Aimon Logo](/img/logo.png)![Aimon Logo](/img/logo.png)](/)\n\n[GitHub](https://github.com/aimonlabs/aimon-python-sdk)\n\n  * [Welcome to AIMon](/)\n  * [Introduction](/category/introduction)\n\n  * [Getting Started](/category/getting-started)\n\n  * [Concepts](/category/concepts)\n\n    * [Detectors](/category/detectors)\n\n      * [Hallucination](/concepts/detectors/hallucination)\n      * [Instruction Adherence](/concepts/detectors/instruction_adherence)\n      * [Conciseness](/concepts/detectors/conciseness)\n      * [Completeness](/concepts/detectors/completeness)\n      * [Toxicity](/concepts/detectors/toxicity)\n    * [Evaluation and Continuous Monitoring](/concepts/evaluation_and_monitoring)\n  * [Example Applications](/category/example-applications)\n\n  * [](/)\n  * [Concepts](/category/concepts)\n  * [Detectors](/category/detectors)\n  * Completeness\n\nOn this page\n\n# Completeness\n\nGiven a context, generated text and optionally a user query or a reference\ntext, this API is able to detect if the generated text completely answered the\nuser\'s question. The context should include the context documents as passed in\nto the LLM. The output contains a ""score"" that is between 0.0 and 1.0 which\nindicates the degree of completeness. If the generated answer is not at all\nrelevant to the user query, a score between 0.0 to 0.2 is possible. If the\ngenerated answer is relevant but misses some information, a score between 0.2\nand 0.7 is possible. If the generated answer is relevant and fully captures\nall of the information, a score between 0.7 and 1.0 is possible. The API also\nincludes a ""reasoning"" field that is a text based explanation of the score. It\nalso does a best effort method of pointing out the points that were missed\nfrom the expected answer.\n\n### Example Request[â\x80\x8b](/concepts/detectors/completeness#example-request\n""Direct link to Example Request"")\n\n    \n    \n    [  \n      {  \n        ""context"": ""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News."",  \n        ""generated_text"": ""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade. In addition, he has also been involved in writing essays and sharing his thoughts on technology, startups, and programming."",  \n        ""config"": {  \n          ""completeness"": {  \n            ""detector_name"": ""default""  \n          }  \n        }  \n      }  \n    ]  \n    \n\n#### Example Response[â\x80\x8b](/concepts/detectors/completeness#example-response\n""Direct link to Example Response"")\n\n    \n    \n    [  \n        {  \n            ""completeness"": {  \n                ""reasoning"": ""The generated answer is somewhat relevant to the query but omits significant information from the context documents, particularly about Paul Graham\'s contributions to Lisp, co-founding Y Combinator, and his work with Viaweb. It also includes details like the IBM 1401 that are not mentioned in the context, leading to inaccuracies and potential confusion. Thus, it doesn\'t provide a complete understanding of his career and achievements."",  \n                ""score"": 0.227  \n            }  \n        }  \n    ]  \n    \n\n### Example (Synchronous\ndetection)[â\x80\x8b](/concepts/detectors/completeness#example-synchronous-detection\n""Direct link to Example \\(Synchronous detection\\)"")\n\nThe below example demonstrates how to use the instruction adherence detector\nin a synchronous manner.\n\n  * Python\n  * TypeScript\n\n    \n    \n    from aimon import Detect  \n      \n    detect = Detect(values_returned=[\'context\', \'generated_text\'], config={""completeness"": {""detector_name"": ""default""}})  \n      \n    @detect  \n    def my_llm_app(context, query):  \n        generated_text = my_llm_model(context, query)  \n        return context, generated_text  \n    \n    \n    \n    import Client from ""aimon"";  \n      \n    const aimon_client = new Client({  \n      authHeader: `Bearer API_KEY`,  \n    });  \n      \n    const completeness_config = {  \n        completeness: {  \n          detector_name: ""default""  \n        }  \n    };  \n      \n    // Detect quality of the generated output using AIMon  \n    const detectParams: Client.InferenceDetectParams.Body[] = [  \n      {  \n        context: contextDocs,  \n        generated_text: output.text,  \n        config: completeness_config  \n      },  \n    ];  \n      \n    // Call the API  \n    const aimonResponse: Client.InferenceDetectResponse =  \n      await aimon_client.inference.detect(detectParams);  \n      \n    \n\n[PreviousConciseness](/concepts/detectors/conciseness)[NextToxicity](/concepts/detectors/toxicity)\n\n  * [Example Request](/concepts/detectors/completeness#example-request)\n  * [Example (Synchronous detection)](/concepts/detectors/completeness#example-synchronous-detection)\n\nDocs\n\n  * [Tutorial](/)\n\nCommunity\n\n  * [Slack](https://join.slack.com/t/generativeair/shared_invite/zt-2m3v8oddx-qz9S2ep_xL4sYvLuOhU39Q)\n\nCopyright Â© 2024 Aimon Labs, Inc. All rights reserved\n\n', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\n\n{content}', metadata_template='{key}: {value}', metadata_seperator='\n'), Document(id_='https://docs.aimon.ai/concepts/detectors/conciseness', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='Skip to main content\n\n[![Aimon Logo](/img/logo.png)![Aimon Logo](/img/logo.png)](/)\n\n[GitHub](https://github.com/aimonlabs/aimon-python-sdk)\n\n  * [Welcome to AIMon](/)\n  * [Introduction](/category/introduction)\n\n  * [Getting Started](/category/getting-started)\n\n  * [Concepts](/category/concepts)\n\n    * [Detectors](/category/detectors)\n\n      * [Hallucination](/concepts/detectors/hallucination)\n      * [Instruction Adherence](/concepts/detectors/instruction_adherence)\n      * [Conciseness](/concepts/detectors/conciseness)\n      * [Completeness](/concepts/detectors/completeness)\n      * [Toxicity](/concepts/detectors/toxicity)\n    * [Evaluation and Continuous Monitoring](/concepts/evaluation_and_monitoring)\n  * [Example Applications](/category/example-applications)\n\n  * [](/)\n  * [Concepts](/category/concepts)\n  * [Detectors](/category/detectors)\n  * Conciseness\n\nOn this page\n\n# Conciseness\n\nGiven a context, generated text and optionally a user query or a reference\ntext, this API is able to detect if the generated text was concise or verbose\nin terms of addressing the user query. The context should include the context\ndocuments along with the user query as passed in to the LLM. The output\ncontains a ""score"" that is between 0.0 and 1.0 which indicates the degree of\nconciseness. If the generated answer is very verbose and contains a lot of un-\nnecessary information that is not relevant to the user query, a score between\n0.0 to 0.2 is possible. If the generated answer is mostly relevant to the user\nquery but has some amount of text that is not necessary for the user query a\nscore between 0.2 and 0.7 is possible. If the generated answer is very concise\nand properly addresses all important points for the user query, a score\nbetween 0.7 and 1.0 is possible. The API also includes a ""reasoning"" field\nthat is a text based explanation of the score. It also does a best effort\nmethod of pointing out the unnecessary information that was included in the\noutput.\n\n### Example Request[â\x80\x8b](/concepts/detectors/conciseness#example-request\n""Direct link to Example Request"")\n\n    \n    \n    [  \n      {  \n        ""context"": ""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News."",  \n        ""generated_text"": ""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade. In addition, he has also been involved in writing essays and sharing his thoughts on technology, startups, and programming."",  \n        ""config"": {  \n          ""conciseness"": {  \n            ""detector_name"": ""default""  \n          }  \n        }  \n      }  \n    ]  \n    \n\n#### Example Response[â\x80\x8b](/concepts/detectors/conciseness#example-response\n""Direct link to Example Response"")\n\n    \n    \n    [  \n        {  \n            ""conciseness"": {  \n                ""reasoning"": ""The generated answer includes relevant information about Paul Graham\'s background but contains unnecessary details that do not directly relate to the user query, which is unspecified. While it touches on his programming beginnings and writing, it lacks emphasis on the key aspects of his impact and contributions, making it less concise than it could be."",  \n                ""score"": 0.25  \n            }  \n        }  \n    ]  \n    \n\n### Example (Synchronous\ndetection)[â\x80\x8b](/concepts/detectors/conciseness#example-synchronous-detection\n""Direct link to Example \\(Synchronous detection\\)"")\n\nThe below example demonstrates how to use the instruction adherence detector\nin a synchronous manner.\n\n  * Python\n  * TypeScript\n\n    \n    \n    from aimon import Detect  \n      \n    detect = Detect(values_returned=[\'context\', \'generated_text\'], config={""conciseness"": {""detector_name"": ""default""}})  \n      \n    @detect  \n    def my_llm_app(context, query):  \n        generated_text = my_llm_model(context, query)  \n        return context, generated_text  \n    \n    \n    \n    import Client from ""aimon"";  \n      \n    const aimon_client = new Client({  \n      authHeader: `Bearer API_KEY`,  \n    });  \n      \n    const concisness_config = {  \n        conciseness: {  \n          detector_name: ""default""  \n        }  \n    };  \n      \n    // Detect quality of the generated output using AIMon  \n    const detectParams: Client.InferenceDetectParams.Body[] = [  \n      {  \n        context: contextDocs,  \n        generated_text: output.text,  \n        config: concisness_config  \n      },  \n    ];  \n      \n    // Call the API  \n    const aimonResponse: Client.InferenceDetectResponse =  \n      await aimon_client.inference.detect(detectParams);  \n      \n    \n\n[PreviousInstruction\nAdherence](/concepts/detectors/instruction_adherence)[NextCompleteness](/concepts/detectors/completeness)\n\n  * [Example Request](/concepts/detectors/conciseness#example-request)\n  * [Example (Synchronous detection)](/concepts/detectors/conciseness#example-synchronous-detection)\n\nDocs\n\n  * [Tutorial](/)\n\nCommunity\n\n  * [Slack](https://join.slack.com/t/generativeair/shared_invite/zt-2m3v8oddx-qz9S2ep_xL4sYvLuOhU39Q)\n\nCopyright Â© 2024 Aimon Labs, Inc. All rights reserved\n\n', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\n\n{content}', metadata_template='{key}: {value}', metadata_seperator='\n'), Document(id_='https://docs.aimon.ai/concepts/detectors/hallucination', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='Skip to main content\n\n[![Aimon Logo](/img/logo.png)![Aimon Logo](/img/logo.png)](/)\n\n[GitHub](https://github.com/aimonlabs/aimon-python-sdk)\n\n  * [Welcome to AIMon](/)\n  * [Introduction](/category/introduction)\n\n  * [Getting Started](/category/getting-started)\n\n  * [Concepts](/category/concepts)\n\n    * [Detectors](/category/detectors)\n\n      * [Hallucination](/concepts/detectors/hallucination)\n      * [Instruction Adherence](/concepts/detectors/instruction_adherence)\n      * [Conciseness](/concepts/detectors/conciseness)\n      * [Completeness](/concepts/detectors/completeness)\n      * [Toxicity](/concepts/detectors/toxicity)\n    * [Evaluation and Continuous Monitoring](/concepts/evaluation_and_monitoring)\n  * [Example Applications](/category/example-applications)\n\n  * [](/)\n  * [Concepts](/category/concepts)\n  * [Detectors](/category/detectors)\n  * Hallucination\n\nOn this page\n\n# Hallucination\n\nGiven a context, a generated text and optionally a user query, we are able to\ndetect 2 different types of model hallucinations: intrinsic and extrinsic.\nIntrinsic Hallucinations are hallucinations where the models manipulate\noriginal information and slightly misrepresent true facts. For example,\nâ\x80\x9cEiffel Tower is the tallest building in France\'\' or â\x80\x9cThe first man on the\nmoon was Yuri Gagarinâ\x80\x9d. Extrinsic Hallucinations are the ones where models\ncompletely fabricate new false information. This canâ\x80\x99t be inferred from or\ntraced back to original sources. For example, â\x80\x9cCristiano Ronaldo is a\nCricket playerâ\x80\x9d. The ""is_hallucinated"" field indicates whether the\n""generated_text"" (passed in the input) is hallucinated. A top level ""score""\nfield indicates if the entire paragraph contained any hallucinations. The\nscore is a probability measure of how hallucinated the text is compared to the\ncontext. A score >= 0.5 can be classified as a hallucination. We also provide\nsentence level scores to help with explainability.\n\n### Example Request[â\x80\x8b](/concepts/detectors/hallucination#example-request\n""Direct link to Example Request"")\n\n    \n    \n    [  \n      {  \n        ""context"": ""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News."",  \n        ""generated_text"": ""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade. In addition, he has also been involved in writing essays and sharing his thoughts on technology, startups, and programming."",  \n        ""config"": {  \n          ""hallucination"": {  \n            ""detector_name"": ""default""  \n          }  \n        }  \n      }  \n    ]  \n    \n\n#### Example Response[â\x80\x8b](/concepts/detectors/hallucination#example-response\n""Direct link to Example Response"")\n\n    \n    \n    [  \n      {  \n        ""hallucination"": {  \n          ""is_hallucinated"": ""True"",  \n          ""score"": 0.7407,  \n          ""sentences"": [  \n            {  \n              ""score"": 0.7407,  \n              ""text"": ""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade.""  \n            },  \n            {  \n              ""score"": 0.03326,  \n              ""text"": ""In addition, he has also been involved in writing essays and sharing his thoughts on technology, startups, and programming.""  \n            }  \n          ]  \n        }  \n      }  \n    ]  \n    \n\n### Example (Synchronous\ndetection)[â\x80\x8b](/concepts/detectors/hallucination#example-synchronous-\ndetection ""Direct link to Example \\(Synchronous detection\\)"")\n\nThe below example demonstrates how to use the hallucination detector in a\nsynchronous manner. We also support asynchronous computation. Refer to the\n[evaluation and monitoring section](/concepts/evaluation_and_monitoring) for\ndetails.\n\n  * Python\n  * TypeScript\n\n    \n    \n    from aimon import Detect  \n      \n    # See analyze_prod for the asynchronous version  \n    # that can be used for continuous monitoring  \n    detect = Detect(values_returned=[\'context\', \'generated_text\'], config={""hallucination"": {""detector_name"": ""default""}})  \n      \n    @detect  \n    def my_llm_app(context, query):  \n        generated_text = my_llm_model(context, query)  \n        return context, generated_text  \n      \n    \n    \n    \n    import Client from ""aimon"";  \n      \n    const aimon_client = new Client({  \n      authHeader: `Bearer API_KEY`,  \n    });  \n      \n    const detectMetrics: any = async (sourceText: any) => {  \n      // Split the source text  \n      const textSplitter = new RecursiveCharacterTextSplitter({ chunkSize: 1000 });  \n      const docs = await textSplitter.createDocuments([sourceText]);  \n      const contextDocs = docs.map((doc) => doc.pageContent);  \n      \n      // Summarize the texts  \n      const llm = new OpenAI({ temperature: 0, openAIApiKey: openaiApiKey });  \n      const chain = loadSummarizationChain(llm, { type: ""map_reduce"" });  \n      const output = await chain.invoke({  \n        input_documents: docs,  \n      });  \n      \n      const hall_config = {  \n          hallucination: {  \n          detector_name: ""default""  \n        }  \n      };  \n      \n      // Detect quality of the generated output using AIMon  \n      const detectParams: Client.InferenceDetectParams.Body[] = [  \n        {  \n          context: contextDocs,  \n          generated_text: output.text,  \n          config: hall_config  \n        },  \n      ];  \n      \n      // Call the API  \n      const aimonResponse: Client.InferenceDetectResponse =  \n        await aimon_client.inference.detect(detectParams);  \n    };  \n    \n\n[PreviousDetectors](/category/detectors)[NextInstruction\nAdherence](/concepts/detectors/instruction_adherence)\n\n  * [Example Request](/concepts/detectors/hallucination#example-request)\n  * [Example (Synchronous detection)](/concepts/detectors/hallucination#example-synchronous-detection)\n\nDocs\n\n  * [Tutorial](/)\n\nCommunity\n\n  * [Slack](https://join.slack.com/t/generativeair/shared_invite/zt-2m3v8oddx-qz9S2ep_xL4sYvLuOhU39Q)\n\nCopyright Â© 2024 Aimon Labs, Inc. All rights reserved\n\n', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\n\n{content}', metadata_template='{key}: {value}', metadata_seperator='\n'), Document(id_='https://docs.aimon.ai/concepts/detectors/instruction_adherence', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='Skip to main content\n\n[![Aimon Logo](/img/logo.png)![Aimon Logo](/img/logo.png)](/)\n\n[GitHub](https://github.com/aimonlabs/aimon-python-sdk)\n\n  * [Welcome to AIMon](/)\n  * [Introduction](/category/introduction)\n\n  * [Getting Started](/category/getting-started)\n\n  * [Concepts](/category/concepts)\n\n    * [Detectors](/category/detectors)\n\n      * [Hallucination](/concepts/detectors/hallucination)\n      * [Instruction Adherence](/concepts/detectors/instruction_adherence)\n      * [Conciseness](/concepts/detectors/conciseness)\n      * [Completeness](/concepts/detectors/completeness)\n      * [Toxicity](/concepts/detectors/toxicity)\n    * [Evaluation and Continuous Monitoring](/concepts/evaluation_and_monitoring)\n  * [Example Applications](/category/example-applications)\n\n  * [](/)\n  * [Concepts](/category/concepts)\n  * [Detectors](/category/detectors)\n  * Instruction Adherence\n\nOn this page\n\n# Instruction Adherence\n\nGiven a set of â\x80\x9cinstructionsâ\x80\x9d, the generated text, the input context and\nthe user query, this API is able to check whether the generated text followed\nall the instructions specified. in the â\x80\x9cinstructionsâ\x80\x9d field.\n\nAn LLM (Large Language Model) following instructions in the prompt is crucial\nfor several reasons. Firstly, it ensures the generation of content that aligns\nwith the user\'s needs and expectations, providing relevant and accurate\ninformation or responses. This adherence to instructions enhances the utility\nand effectiveness of the model, making it a reliable tool for various\napplications such as customer support, content creation, and educational\nassistance. Moreover, following prompts precisely helps maintain coherence and\ncontext, preventing misunderstandings or the generation of irrelevant\ninformation. It also ensures ethical compliance, avoiding the creation of\ninappropriate or harmful content. Ultimately, prompt adherence maximizes the\nvalue of the LLM, fostering user trust and satisfaction.\n\n### Example Request[â\x80\x8b](/concepts/detectors/instruction_adherence#example-\nrequest ""Direct link to Example Request"")\n\n    \n    \n    [  \n      {  \n        ""context"": ""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News."",  \n        ""instructions"": ""Write a summary of Paul Graham\'s career and achievements."",  \n        ""generated_text"": ""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade. In addition, he has also been involved in writing essays and sharing his thoughts on technology, startups, and programming."",  \n        ""config"": {  \n          ""instruction_adherence"": {  \n            ""detector_name"": ""default""  \n          }  \n        }  \n      }  \n    ]  \n    \n\n#### Example Response[â\x80\x8b](/concepts/detectors/instruction_adherence#example-\nresponse ""Direct link to Example Response"")\n\n    \n    \n    [  \n      {  \n        ""instruction_adherence"": {  \n          ""results"": [  \n            {  \n              ""adherence"": false,  \n              ""detailed_explanation"": ""The response provides a very limited overview of Paul Graham\'s career, only mentioning his early programming on the IBM 1401 and general involvement in writing essays. It fails to cover significant achievements such as his work on Lisp, co-founding Y Combinator, and his influence in the tech and startup world."",  \n              ""instruction"": ""Write a summary of Paul Graham\'s career and achievements.""  \n            }  \n          ],  \n          ""score"": 0.0  \n        }  \n      }  \n    ]  \n    \n\n### Example (Synchronous\ndetection)[â\x80\x8b](/concepts/detectors/instruction_adherence#example-synchronous-\ndetection ""Direct link to Example \\(Synchronous detection\\)"")\n\nThe below example demonstrates how to use the instruction adherence detector\nin a synchronous manner.\n\n  * Python\n  * TypeScript\n\n    \n    \n    from aimon import Detect  \n      \n    detect = Detect(values_returned=[\'context\', \'generated_text\', \'instructions\'], config={""instruction_adherence"": {""detector_name"": ""default""}})  \n      \n    @detect  \n    def my_llm_app(context, query, instructions):  \n        generated_text = my_llm_model(context, query)  \n        return context, generated_text, instructions  \n    \n    \n    \n    import Client from ""aimon"";  \n      \n    const aimon_client = new Client({  \n      authHeader: `Bearer API_KEY`,  \n    });  \n      \n    const instruction_adherence_config = {  \n        instruction_adherence: {  \n          detector_name: ""default""  \n        }  \n    };  \n      \n    // Detect quality of the generated output using AIMon  \n    const detectParams: Client.InferenceDetectParams.Body[] = [  \n      {  \n        context: contextDocs,  \n        generated_text: output.text,  \n        instructions: instructions,  \n        config: instruction_adherence_config  \n      },  \n    ];  \n      \n    // Call the API  \n    const aimonResponse: Client.InferenceDetectResponse =  \n      await aimon_client.inference.detect(detectParams);  \n      \n    \n\n[PreviousHallucination](/concepts/detectors/hallucination)[NextConciseness](/concepts/detectors/conciseness)\n\n  * [Example Request](/concepts/detectors/instruction_adherence#example-request)\n  * [Example (Synchronous detection)](/concepts/detectors/instruction_adherence#example-synchronous-detection)\n\nDocs\n\n  * [Tutorial](/)\n\nCommunity\n\n  * [Slack](https://join.slack.com/t/generativeair/shared_invite/zt-2m3v8oddx-qz9S2ep_xL4sYvLuOhU39Q)\n\nCopyright Â© 2024 Aimon Labs, Inc. All rights reserved\n\n', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\n\n{content}', metadata_template='{key}: {value}', metadata_seperator='\n'), Document(id_='https://docs.aimon.ai/concepts/detectors/toxicity', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='Skip to main content\n\n[![Aimon Logo](/img/logo.png)![Aimon Logo](/img/logo.png)](/)\n\n[GitHub](https://github.com/aimonlabs/aimon-python-sdk)\n\n  * [Welcome to AIMon](/)\n  * [Introduction](/category/introduction)\n\n  * [Getting Started](/category/getting-started)\n\n  * [Concepts](/category/concepts)\n\n    * [Detectors](/category/detectors)\n\n      * [Hallucination](/concepts/detectors/hallucination)\n      * [Instruction Adherence](/concepts/detectors/instruction_adherence)\n      * [Conciseness](/concepts/detectors/conciseness)\n      * [Completeness](/concepts/detectors/completeness)\n      * [Toxicity](/concepts/detectors/toxicity)\n    * [Evaluation and Continuous Monitoring](/concepts/evaluation_and_monitoring)\n  * [Example Applications](/category/example-applications)\n\n  * [](/)\n  * [Concepts](/category/concepts)\n  * [Detectors](/category/detectors)\n  * Toxicity\n\nOn this page\n\n# Toxicity\n\nGiven a context, generated text and optionally a user query or reference text,\nthis API is able to generate various toxicity scores. The context should\ninclude the context documents along with the user query as passed in to the\nLLM. The output contains multiple labels with a value between 0.0 and 1.0\nwhich indicates the likelihood of the label.\n\nThere are 6 different possible labels:\n\n  * `identity_hate`: Indicates possible hateful language that targets a personâ\x80\x99s identity.\n  * `toxic`: Content that is generally considered unsafe for a broad audience.\n  * `severe_toxic`: Extremely harmful content that should not be shown to a general audience.\n  * `obscene`: Content that is offensive or disgusting by accepted standards of morality and decency.\n  * `threat`: Content that contains threatening language.\n  * `insult`: Content that contains disrespectful or scornfully abusive language.\n\n### Example Request[â\x80\x8b](/concepts/detectors/toxicity#example-request ""Direct\nlink to Example Request"")\n\n    \n    \n    [  \n      {  \n        ""context"": ""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News."",  \n        ""generated_text"": ""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade. In addition, he has also been involved in writing essays and sharing his thoughts on technology, startups, and programming."",  \n        ""config"": {  \n          ""toxicity"": {  \n            ""detector_name"": ""default""  \n          }  \n        }  \n      }  \n    ]  \n    \n\n#### Example Response[â\x80\x8b](/concepts/detectors/toxicity#example-response\n""Direct link to Example Response"")\n\n    \n    \n    [  \n      {  \n        ""toxicity"": {  \n          ""results"": {  \n            ""generated_text"": {  \n              ""detected_labels"": {  \n                ""identity_hate"": 0.11749652028083801,  \n                ""insult"": 0.35200783610343933,  \n                ""obscene"": 0.24614322185516357,  \n                ""severe_toxic"": 0.05233444273471832,  \n                ""threat"": 0.119813933968544,  \n                ""toxic"": 0.11220399290323257  \n              },  \n              ""text"": ""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade. In addition, he has also been involved in writing essays and sharing his thoughts on technology, startups, and programming.""  \n            }  \n          },  \n          ""score"": 0.35200783610343933  \n        }  \n      }  \n    ]  \n    \n\n### Example (Synchronous detection)[â\x80\x8b](/concepts/detectors/toxicity#example-\nsynchronous-detection ""Direct link to Example \\(Synchronous detection\\)"")\n\nThe below example demonstrates how to use the instruction adherence detector\nin a synchronous manner.\n\n  * Python\n  * TypeScript\n\n    \n    \n    from aimon import Detect  \n      \n    detect = Detect(values_returned=[\'context\', \'generated_text\'],config={""toxicity"": {""detector_name"": ""default""}})  \n      \n    @detect  \n    def my_llm_app(context, query):  \n        generated_text = my_llm_model(context, query)  \n        return context, generated_text  \n    \n    \n    \n    import Client from ""aimon"";  \n      \n    const aimon_client = new Client({  \n      authHeader: `Bearer API_KEY`,  \n    });  \n      \n    const toxicity_config = {  \n        toxicity: {  \n          detector_name: ""default""  \n        }  \n    };  \n      \n    // Detect quality of the generated output using AIMon  \n    const detectParams: Client.InferenceDetectParams.Body[] = [  \n      {  \n        context: contextDocs,  \n        generated_text: output.text,  \n        config: toxicity_config  \n      },  \n    ];  \n      \n    // Call the API  \n    const aimonResponse: Client.InferenceDetectResponse =  \n      await aimon_client.inference.detect(detectParams);  \n      \n    \n\n[PreviousCompleteness](/concepts/detectors/completeness)[NextEvaluation and\nContinuous Monitoring](/concepts/evaluation_and_monitoring)\n\n  * [Example Request](/concepts/detectors/toxicity#example-request)\n  * [Example (Synchronous detection)](/concepts/detectors/toxicity#example-synchronous-detection)\n\nDocs\n\n  * [Tutorial](/)\n\nCommunity\n\n  * [Slack](https://join.slack.com/t/generativeair/shared_invite/zt-2m3v8oddx-qz9S2ep_xL4sYvLuOhU39Q)\n\nCopyright Â© 2024 Aimon Labs, Inc. All rights reserved\n\n', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\n\n{content}', metadata_template='{key}: {value}', metadata_seperator='\n'), Document(id_='https://docs.aimon.ai/concepts/evaluation_and_monitoring', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='Skip to main content\n\n[![Aimon Logo](/img/logo.png)![Aimon Logo](/img/logo.png)](/)\n\n[GitHub](https://github.com/aimonlabs/aimon-python-sdk)\n\n  * [Welcome to AIMon](/)\n  * [Introduction](/category/introduction)\n\n  * [Getting Started](/category/getting-started)\n\n  * [Concepts](/category/concepts)\n\n    * [Detectors](/category/detectors)\n\n    * [Evaluation and Continuous Monitoring](/concepts/evaluation_and_monitoring)\n  * [Example Applications](/category/example-applications)\n\n  * [](/)\n  * [Concepts](/category/concepts)\n  * Evaluation and Continuous Monitoring\n\nOn this page\n\n# Evaluation and Continuous Monitoring\n\nWith AIMon, you can evaluate and continuously monitor the quality of the\ngenerated text. In this section, we will demonstrate how to quickly and easily\nsetup evaluation and/or monitoring for your LLM applications. Let\'s start with\nsome basic concepts that will be useful to understand before instrumenting\nyour LLM application.\n\n### Model[â\x80\x8b](/concepts/evaluation_and_monitoring#model ""Direct link to\nModel"")\n\nA model is a generative model, typically an LLM, that generates text based on\nan input query, context and user provided instructions. The model can be a\nvanilla model, a fine-tuned model or a prompt-engineered model.\n\n### Application[â\x80\x8b](/concepts/evaluation_and_monitoring#application ""Direct\nlink to Application"")\n\nAn application is a specific use-case or a task that is associated a model.\nFor example, a summarization application. Each application is versioned i.e.,\neach application is associated with a particular model for a given version of\nthe application. When you use a different model for the same application,\nAIMon will automatically create a new version of the application.\n\n### Evaluation[â\x80\x8b](/concepts/evaluation_and_monitoring#evaluation ""Direct\nlink to Evaluation"")\n\nEvaluation is the process of assessing the quality of the generated text\ntypically in an offline setup. This can be done using various detectors\nprovided by the AIMon platform. AIMon adopts a ""batteries included"" approach\ni.e., you do not have to use another third-party API for the various\ndetectors.\n\nBefore deploying the application to production, it is a good idea to test it\nwith either a curated golden dataset or a snapshot of production traffic. In\nthis section, we will demonstrate how AIMon can assist you to perform these\ntests.\n\n#### Evaluation Dataset[â\x80\x8b](/concepts/evaluation_and_monitoring#evaluation-\ndataset ""Direct link to Evaluation Dataset"")\n\nAIMon can manage datasets for you. The dataset should be a CSV file with these\ncolumns:\n\n  * ""prompt"": This is the prompt used for the LLM\n  * ""user_query"": This the query specified by the user\n  * ""context_docs"": These are context documents that are either retrieved from a RAG or through other methods. For tasks like summarization, these documents could be directly specified by the user.\n\nA dataset can be created using the AIMon client as follows:\n\n  * Python\n  * TypeScript\n\n    \n    \n    from aimon import Client  \n    import json  \n      \n    aimon_client = Client(auth_header=""Bearer <AIMON API KEY>"")  \n    # Create a new datasets  \n    file_path = ""evaluation_dataset.csv""  \n      \n    dataset = json.dumps({  \n        ""name"": ""evaluation_dataset.csv"",  \n        ""description"": ""This is a golden dataset""  \n    })  \n      \n    with open(file_path, \'rb\') as file1:  \n        aimon_dataset = aimon_client.datasets.create(  \n            file=file1,  \n            json_data=dataset  \n        )  \n    \n    \n    \n    import Client from ""aimon"";  \n      \n    const aimon_client = new Client({  \n      authHeader: `Bearer API_KEY`,  \n    });  \n      \n      \n    // Creates a new dataset from the local path csv file  \n    const createDataset = async (  \n      path: string,  \n      datasetName: string,  \n      description: string  \n    ): Promise<Client.Dataset> => {  \n      const file = await fileFromPath(path);  \n      const json_data = JSON.stringify({  \n        name: datasetName,  \n        description: description,  \n      });  \n      \n      const params = {  \n        file: file,  \n        json_data: json_data,  \n      };  \n      \n      const dataset: Client.Dataset = await aimon.datasets.create(params);  \n      return dataset;  \n    };  \n    \n\n##### Dataset Collection[â\x80\x8b](/concepts/evaluation_and_monitoring#dataset-\ncollection ""Direct link to Dataset Collection"")\n\nYou can group a collection of evaluation datasets into a `dataset collection`\nfor ease of use. A dataset collection can be created as follows:\n\n  * Python\n  * TypeScript\n\n    \n    \n    dataset_collection = aimon_client.datasets.collection.create(  \n        name=""my_first_dataset_collection"",   \n        dataset_ids=[aimon_dataset1.sha, aimon_dataset2.sha],   \n        description=""This is a collection of two datasets.""  \n    )  \n    \n    \n    \n    const dataset1 = await createDataset(  \n        ""/path/to/file/filename_1.csv"",  \n        ""filename1.csv"",  \n        ""description""  \n    );  \n      \n    const dataset2 = await createDataset(  \n        ""/path/to/file/filename_2.csv"",  \n        ""filename2.csv"",  \n        ""description""  \n    );  \n      \n    let datasetCollection: Client.Datasets.CollectionCreateResponse | undefined;  \n      \n    // Ensures that dataset1.sha and dataset2.sha are defined  \n    if (dataset1.sha && dataset2.sha) {  \n        // Creates dataset collection  \n        datasetCollection = await aimon.datasets.collection.create({  \n        name: ""my_first_dataset_collection"",  \n        dataset_ids: [dataset1.sha, dataset2.sha],  \n        description: ""This is a collection of two datasets."",  \n        });  \n    } else {  \n        throw new Error(""Dataset sha is undefined"");  \n    }  \n      \n    \n\nThis allows you to then access records from the dataset collection as follows:\n\n  * Python\n  * TypeScript\n\n    \n    \n    # Get all records from the datasets in this collection  \n    dataset_collection_records = []  \n    for dataset_id in dataset_collection.dataset_ids:  \n        dataset_records = aimon_client.datasets.records.list(sha=dataset_id)  \n        dataset_collection_records.extend(dataset_records)  \n    \n    \n    \n      \n    const datasetCollectionRecords: any[] = [];  \n      \n    for (const datasetId of datasetCollection.dataset_ids) {  \n      const datasetRecords = await aimonClient.datasets.records.list({ sha: datasetId });  \n      datasetCollectionRecords.push(...datasetRecords);  \n    }  \n    \n\n#### Creating an Evaluation[â\x80\x8b](/concepts/evaluation_and_monitoring#creating-\nan-evaluation ""Direct link to Creating an Evaluation"")\n\nAn evaluation is associated with a specific dataset collection and a\nparticular version of an application (and its corresponding model).\n\n#### Running an Evaluation[â\x80\x8b](/concepts/evaluation_and_monitoring#running-\nan-evaluation ""Direct link to Running an Evaluation"")\n\nA ""run"" is an instance of an evaluation that you would like to track metrics\nagainst. You could have multiple runs of the same evaluation. This is\ntypically done in a CI/CD context where the same evaluation would run at\nregular intervals. Since LLMs are probabilistic in nature, they could produce\ndifferent outputs for the same query and context. It is a good idea to run the\nevaluations regularly to understand the variations of outputs produced by your\nLLMs. In addition, runs give you the ability to choose different metrics for\neach run.\n\nDetectors can be specified using the `config` parameter in the payload as\nshown below. The keys indicate the type of metric computed and the value of\n`detector_name` is the specific algorithm used to compute those metrics. For\nmost cases, we recommend using the `default` algorithm for each detector.\n\n  * Python\n  * TypeScript\n\n    \n    \n    config={  \n        \'hallucination\': {\'detector_name\':\'default\'},   \n        \'toxicity\': {\'detector_name\':\'default\'},   \n        \'conciseness\': {\'detector_name\':\'default\'},   \n        \'completeness\': {\'detector_name\':\'default\'}  \n    }  \n    \n    \n    \n    const config = {  \n      hallucination: { detector_name: ""default"" },  \n      toxicity: { detector_name: ""default"" },  \n      conciseness: { detector_name: ""default"" },  \n      completeness: { detector_name: ""default"" }  \n    };  \n    \n\nYou can also `tag` a particular run. Tags allow you to specify metadata like\nthe application commit SHA or other key-value pairs that you want to insert\nfor analytics purposes.\n\n#### Example[â\x80\x8b](/concepts/evaluation_and_monitoring#example ""Direct link to\nExample"")\n\nSetting up and running an evaluation can be done using the higher level\n`Analyze` decorator in Python or the low level API that offers more control.\n\nHere is an example of running an evaluation\n\n  * Python\n  * TypeScript\n\n    \n    \n    from aimon import AnalyzeEval, Application, Model  \n      \n    analyze_eval = AnalyzeEval(  \n        Application(""my_first_llm_app""),  \n        Model(""my_first_model"", ""GPT-4o""),   \n        evaluation_name=""your_first_evaluation"",  \n        dataset_collection_name=""my_first_dataset_collection"",  \n    )  \n      \n    # Lanchain app example  \n    from langchain.text_splitter import CharacterTextSplitter  \n    from langchain.docstore.document import Document  \n    from langchain.llms.openai import OpenAI  \n    from langchain.chains.summarize import load_summarize_chain  \n      \n    # The analyze_eval decorator will automatically stream through  \n    # records in the specified data collection and run it against   \n    # this function. The signature of this function should necessarily   \n    # contain context_docs, user_query and prompt as the first 3   \n    # arguments.  \n    @analyze_eval  \n    def run_application_eval_mode(context_docs=None, user_query=None, prompt=None):  \n        # Split the source text  \n        text_splitter = CharacterTextSplitter()  \n        texts = text_splitter.split_text(context_docs)  \n          \n        # Create Document objects for the texts  \n        docs = [Document(page_content=t) for t in texts[:3]]  \n          \n        # Initialize the OpenAI module, load and run the summarize chain  \n        llm = OpenAI(temperature=0, openai_api_key=openai_api_key)  \n        chain = load_summarize_chain(llm, chain_type=""map_reduce"")  \n        return chain.run(docs)  \n      \n    # This will automatically run an evaluation using records from the specified dataset collection asynchronously.  \n    aimon_eval_res = run_application_eval_mode()  \n    print(aimon_eval_res)  \n    \n    \n    \n    import Client from ""aimon"";  \n    import { OpenAI } from ""@langchain/openai"";  \n    import { loadSummarizationChain } from ""langchain/chains"";  \n    import { RecursiveCharacterTextSplitter } from ""langchain/text_splitter"";  \n    import { fileFromPath } from ""formdata-node/file-from-path"";  \n      \n    // Create the AIMon client. You would need an API Key (that can be retrieved from the UI in your user profile).  \n    const aimon = new Client({  \n      authHeader: \'Bearer: <AIMON_API_KEY>\',  \n    });  \n      \n    // Initialize OpenAI configuration  \n    const openaiApiKey = ""OPENAI_API_KEY"";  \n      \n    // Analyzes the dataset record and model output offline.  \n    const runApplication: any = async (  \n      application: any,  \n      sourceText: any,  \n      prompt: string | null = null,  \n      userQuery: string | null = null,  \n      evaluationRun: any = null  \n    ) => {  \n      // Split the source text  \n      const textSplitter = new RecursiveCharacterTextSplitter({ chunkSize: 1000 });  \n      const docs = await textSplitter.createDocuments([sourceText]);  \n      const contextDocs = docs.map((doc) => doc.pageContent);  \n      \n      // Summarize the texts  \n      const llm = new OpenAI({ temperature: 0, openAIApiKey: openaiApiKey });  \n      const chain = loadSummarizationChain(llm, { type: ""map_reduce"" });  \n      const output = await chain.invoke({  \n        input_documents: docs,  \n      });  \n      \n      // Analyze quality of the generated output using AIMon  \n      const aimonResponse: Client.AnalyzeCreateResponse =  \n        await aimon.analyze.create([  \n          {  \n            application_id: application.id,  \n            version: application.version,  \n            prompt: prompt !== null ? prompt : """",  \n            user_query: userQuery !== null ? userQuery : """",  \n            context_docs: contextDocs,  \n            output: output.text,  \n            evaluation_id: evaluationRun.evaluation_id,  \n            evaluation_run_id: evaluationRun.id,  \n          },  \n        ]);  \n    };  \n      \n      \n    for (const record of datasetCollectionRecords) {  \n        await runApplication(  \n            myApplication,  \n            record.context_docs,  \n            record.prompt,  \n            record.user_query,  \n            newEvaluationRun  \n        );  \n    }  \n      \n    \n\n### Continuous Monitoring[â\x80\x8b](/concepts/evaluation_and_monitoring#continuous-\nmonitoring ""Direct link to Continuous Monitoring"")\n\nOnce your application is ready for production, you can set up continuous\nmonitoring to track the quality of the generated text. This can also be done\nusing the `Analyze` decorator in Python or the `analyze.production` API in\nTypescript as follows:\n\n  * Python\n  * TypeScript\n\n    \n    \n    from aimon import AnalyzeProd, Application, Model  \n    analyze_prod = AnalyzeProd(  \n        Application(""my_first_llm_app""),   \n        Model(""my_best_model"", ""Llama3""),  \n        values_returned=[""context"", ""generated_text""],  \n    )  \n      \n    # Lanchain app example  \n    from langchain.text_splitter import CharacterTextSplitter  \n    from langchain.docstore.document import Document  \n    from langchain.llms.openai import OpenAI  \n    from langchain.chains.summarize import load_summarize_chain  \n      \n    @analyze_prod  \n    def run_application(context_docs=None, user_query=None, prompt=None):  \n        # Split the source text  \n        text_splitter = CharacterTextSplitter()  \n        texts = text_splitter.split_text(context_docs)  \n          \n        # Create Document objects for the texts  \n        docs = [Document(page_content=t) for t in texts[:3]]  \n          \n        # Initialize the OpenAI module, load and run the summarize chain  \n        llm = OpenAI(temperature=0, openai_api_key=openai_api_key)  \n        chain = load_summarize_chain(llm, chain_type=""map_reduce"")  \n        return context_docs, chain.run(docs)  \n      \n    source_text = ""Sample document to summarize""  \n      \n    # This will automatically run the application against the source text and prompt. It will also  \n    # asynchronously run detections for the quality of the generated text.  \n    context, res, aimon_res = run_application(source_text, prompt=""Langhchain based summarization of documents"")  \n    print(aimon_res)  \n    \n    \n    \n    import Client from ""aimon"";  \n    import { OpenAI } from ""@langchain/openai"";  \n    import { loadSummarizationChain } from ""langchain/chains"";  \n    import { RecursiveCharacterTextSplitter } from ""langchain/text_splitter"";  \n    import { fileFromPath } from ""formdata-node/file-from-path"";  \n      \n    // Create the AIMon client. You would need an API Key (that can be retrieved from the UI in your user profile).  \n    const aimon = new Client({  \n      authHeader: \'Bearer: <AIMON_API_KEY>\',  \n    });  \n      \n    // Initialize OpenAI configuration  \n    const openaiApiKey = ""OPENAI_API_KEY"";  \n      \n    const runApplication: any = async (  \n      applicationName: string,  \n      modelName: string,  \n      sourceText: any,  \n      prompt: string | null = null,  \n      userQuery: string | null = null,  \n    ) => {  \n      // Split the source text  \n      const textSplitter = new RecursiveCharacterTextSplitter({ chunkSize: 1000 });  \n      const docs = await textSplitter.createDocuments([sourceText]);  \n      const contextDocs = docs.map((doc) => doc.pageContent);  \n      \n      // Summarize the texts  \n      const llm = new OpenAI({ temperature: 0, openAIApiKey: openaiApiKey });  \n      const chain = loadSummarizationChain(llm, { type: ""map_reduce"" });  \n      const output = await chain.invoke({  \n        input_documents: docs,  \n      });  \n      \n      const payload = {  \n        context_docs: contextDocs,  \n        output: String(output.text),  \n        prompt: prompt ?? """",  \n        user_query: userQuery ?? """",  \n        instructions: ""These are the instructions"",  \n      };  \n      \n      const config = {  \n        hallucination: { detector_name: ""default"" },  \n        conciseness: { detector_name: ""default"" },  \n        completeness: { detector_name: ""default"" },  \n        instruction_adherence: { detector_name: ""default"" },  \n      };  \n      \n      // Analyze quality of the generated output using AIMon  \n      const response: Client.AnalyzeCreateResponse = await aimon.analyze.production(  \n        applicationName,  \n        modelName,  \n        payload,  \n        config  \n      );  \n    };  \n    \n\n### Lower level API[â\x80\x8b](/concepts/evaluation_and_monitoring#lower-level-api\n""Direct link to Lower level API"")\n\nIf you need more control over the evaluation or continuous monitoring process,\nyou can use the lower level API described in this\n[notebook](https://github.com/aimonlabs/aimon-python-\nsdk/blob/main/examples/notebooks/aimon_sdk_langchain_summarization_low_level_api.ipynb).\n\n[PreviousToxicity](/concepts/detectors/toxicity)[NextExample\nApplications](/category/example-applications)\n\n  * [Model](/concepts/evaluation_and_monitoring#model)\n  * [Application](/concepts/evaluation_and_monitoring#application)\n  * [Evaluation](/concepts/evaluation_and_monitoring#evaluation)\n  * [Continuous Monitoring](/concepts/evaluation_and_monitoring#continuous-monitoring)\n  * [Lower level API](/concepts/evaluation_and_monitoring#lower-level-api)\n\nDocs\n\n  * [Tutorial](/)\n\nCommunity\n\n  * [Slack](https://join.slack.com/t/generativeair/shared_invite/zt-2m3v8oddx-qz9S2ep_xL4sYvLuOhU39Q)\n\nCopyright Â© 2024 Aimon Labs, Inc. All rights reserved\n\n', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\n\n{content}', metadata_template='{key}: {value}', metadata_seperator='\n')]]",Name all the seven detectors that AIMon offers as a service.,Please explain all the detectors that you are able to find in the documentation,The response should be in English and under 200 words.
"[[Document(id_='https://docs.aimon.ai/markdown-page', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text=""Skip to main content\n\n[![Aimon Logo](/img/logo.png)![Aimon Logo](/img/logo.png)](/)\n\n[GitHub](https://github.com/aimonlabs/aimon-python-sdk)\n\n# Markdown page example\n\nYou don't need React to write simple standalone pages.\n\nDocs\n\n  * [Tutorial](/)\n\nCommunity\n\n  * [Slack](https://join.slack.com/t/generativeair/shared_invite/zt-2m3v8oddx-qz9S2ep_xL4sYvLuOhU39Q)\n\nCopyright Â© 2024 Aimon Labs, Inc. All rights reserved\n\n"", mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\n\n{content}', metadata_template='{key}: {value}', metadata_seperator='\n'), Document(id_='https://docs.aimon.ai/category/concepts', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='Skip to main content\n\n[![Aimon Logo](/img/logo.png)![Aimon Logo](/img/logo.png)](/)\n\n[GitHub](https://github.com/aimonlabs/aimon-python-sdk)\n\n  * [Welcome to AIMon](/)\n  * [Introduction](/category/introduction)\n\n  * [Getting Started](/category/getting-started)\n\n  * [Concepts](/category/concepts)\n\n    * [Detectors](/category/detectors)\n\n    * [Evaluation and Continuous Monitoring](/concepts/evaluation_and_monitoring)\n  * [Example Applications](/category/example-applications)\n\n  * [](/)\n  * Concepts\n\n# Concepts\n\n## [ð\x9f\x97\x83ï¸\x8f Detectors5 items](/category/detectors)## [ð\x9f\x93\x84ï¸\x8f Evaluation and\nContinuous MonitoringWith AIMon, you can evaluate and continuously monitor the\nquality of the generated text. In this section, we\nwill](/concepts/evaluation_and_monitoring)[PreviousQuick Start](/getting-\nstarted/quick-start)[NextDetectors](/category/detectors)\n\nDocs\n\n  * [Tutorial](/)\n\nCommunity\n\n  * [Slack](https://join.slack.com/t/generativeair/shared_invite/zt-2m3v8oddx-qz9S2ep_xL4sYvLuOhU39Q)\n\nCopyright Â© 2024 Aimon Labs, Inc. All rights reserved\n\n', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\n\n{content}', metadata_template='{key}: {value}', metadata_seperator='\n'), Document(id_='https://docs.aimon.ai/category/detectors', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='Skip to main content\n\n[![Aimon Logo](/img/logo.png)![Aimon Logo](/img/logo.png)](/)\n\n[GitHub](https://github.com/aimonlabs/aimon-python-sdk)\n\n  * [Welcome to AIMon](/)\n  * [Introduction](/category/introduction)\n\n  * [Getting Started](/category/getting-started)\n\n  * [Concepts](/category/concepts)\n\n    * [Detectors](/category/detectors)\n\n      * [Hallucination](/concepts/detectors/hallucination)\n      * [Instruction Adherence](/concepts/detectors/instruction_adherence)\n      * [Conciseness](/concepts/detectors/conciseness)\n      * [Completeness](/concepts/detectors/completeness)\n      * [Toxicity](/concepts/detectors/toxicity)\n    * [Evaluation and Continuous Monitoring](/concepts/evaluation_and_monitoring)\n  * [Example Applications](/category/example-applications)\n\n  * [](/)\n  * [Concepts](/category/concepts)\n  * Detectors\n\n# Detectors\n\n## [ð\x9f\x93\x84ï¸\x8f HallucinationGiven a context, a generated text and optionally a\nuser query, we are able to detect 2 different types\nof](/concepts/detectors/hallucination)## [ð\x9f\x93\x84ï¸\x8f Instruction AdherenceGiven a\nset of â\x80\x9cinstructionsâ\x80\x9d, the generated text, the input context and the user\nquery, this API is able](/concepts/detectors/instruction_adherence)## [ð\x9f\x93\x84ï¸\x8f\nConcisenessGiven a context, generated text and optionally a user query or a\nreference text, this API is able to detect if\nthe](/concepts/detectors/conciseness)## [ð\x9f\x93\x84ï¸\x8f CompletenessGiven a context,\ngenerated text and optionally a user query or a reference text, this API is\nable to detect](/concepts/detectors/completeness)## [ð\x9f\x93\x84ï¸\x8f ToxicityGiven a\ncontext, generated text and optionally a user query or reference text, this\nAPI is able to generate\nvarious](/concepts/detectors/toxicity)[PreviousConcepts](/category/concepts)[NextHallucination](/concepts/detectors/hallucination)\n\nDocs\n\n  * [Tutorial](/)\n\nCommunity\n\n  * [Slack](https://join.slack.com/t/generativeair/shared_invite/zt-2m3v8oddx-qz9S2ep_xL4sYvLuOhU39Q)\n\nCopyright Â© 2024 Aimon Labs, Inc. All rights reserved\n\n', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\n\n{content}', metadata_template='{key}: {value}', metadata_seperator='\n'), Document(id_='https://docs.aimon.ai/category/example-applications', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='Skip to main content\n\n[![Aimon Logo](/img/logo.png)![Aimon Logo](/img/logo.png)](/)\n\n[GitHub](https://github.com/aimonlabs/aimon-python-sdk)\n\n  * [Welcome to AIMon](/)\n  * [Introduction](/category/introduction)\n\n  * [Getting Started](/category/getting-started)\n\n  * [Concepts](/category/concepts)\n\n  * [Example Applications](/category/example-applications)\n\n    * [Chatbot](/example-applications/chatbot)\n    * [Summarization](/example-applications/summarization)\n    * [More Examples](/example-applications/more_examples)\n\n  * [](/)\n  * Example Applications\n\n# Example Applications\n\n## [ð\x9f\x93\x84ï¸\x8f Chatbotimg.png](/example-applications/chatbot)## [ð\x9f\x93\x84ï¸\x8f\nSummarizationimg.png](/example-applications/summarization)## [ð\x9f\x93\x84ï¸\x8f More\nExamples* If you are a Metaflow user, you can refer to this example Metaflow\nflow that integrates with AIMon.](/example-\napplications/more_examples)[PreviousEvaluation and Continuous\nMonitoring](/concepts/evaluation_and_monitoring)[NextChatbot](/example-\napplications/chatbot)\n\nDocs\n\n  * [Tutorial](/)\n\nCommunity\n\n  * [Slack](https://join.slack.com/t/generativeair/shared_invite/zt-2m3v8oddx-qz9S2ep_xL4sYvLuOhU39Q)\n\nCopyright Â© 2024 Aimon Labs, Inc. All rights reserved\n\n', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\n\n{content}', metadata_template='{key}: {value}', metadata_seperator='\n'), Document(id_='https://docs.aimon.ai/category/getting-started', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='Skip to main content\n\n[![Aimon Logo](/img/logo.png)![Aimon Logo](/img/logo.png)](/)\n\n[GitHub](https://github.com/aimonlabs/aimon-python-sdk)\n\n  * [Welcome to AIMon](/)\n  * [Introduction](/category/introduction)\n\n  * [Getting Started](/category/getting-started)\n\n    * [Installing AIMon](/getting-started/installing-aimon)\n    * [Quick Start](/getting-started/quick-start)\n  * [Concepts](/category/concepts)\n\n  * [Example Applications](/category/example-applications)\n\n  * [](/)\n  * Getting Started\n\n# Getting Started\n\n## [ð\x9f\x93\x84ï¸\x8f Installing AIMonAPI key](/getting-started/installing-aimon)##\n[ð\x9f\x93\x84ï¸\x8f Quick StartThis guide will help you get started with AIMon. Before\ngetting started, make sure you have AIMon installed.](/getting-started/quick-\nstart)[PreviousWhat is AIMon](/introduction/whats-aimon)[NextInstalling\nAIMon](/getting-started/installing-aimon)\n\nDocs\n\n  * [Tutorial](/)\n\nCommunity\n\n  * [Slack](https://join.slack.com/t/generativeair/shared_invite/zt-2m3v8oddx-qz9S2ep_xL4sYvLuOhU39Q)\n\nCopyright Â© 2024 Aimon Labs, Inc. All rights reserved\n\n', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\n\n{content}', metadata_template='{key}: {value}', metadata_seperator='\n'), Document(id_='https://docs.aimon.ai/category/introduction', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='Skip to main content\n\n[![Aimon Logo](/img/logo.png)![Aimon Logo](/img/logo.png)](/)\n\n[GitHub](https://github.com/aimonlabs/aimon-python-sdk)\n\n  * [Welcome to AIMon](/)\n  * [Introduction](/category/introduction)\n\n    * [Why AIMon](/introduction/why-aimon)\n    * [What is AIMon](/introduction/whats-aimon)\n  * [Getting Started](/category/getting-started)\n\n  * [Concepts](/category/concepts)\n\n  * [Example Applications](/category/example-applications)\n\n  * [](/)\n  * Introduction\n\n# Introduction\n\nIntroduction to AIMon\n\n## [ð\x9f\x93\x84ï¸\x8f Why AIMon1\\. With the advent of Generative AI, engineers are able\nto build AI applications easily without needing deep ML\nexpertise.](/introduction/why-aimon)## [ð\x9f\x93\x84ï¸\x8f What is AIMonAIMon helps\ndevelopers build robust and reliable generative AI applications. AIMon\nprovides a suite of detectors that](/introduction/whats-aimon)[PreviousWelcome\nto AIMon](/)[NextWhy AIMon](/introduction/why-aimon)\n\nDocs\n\n  * [Tutorial](/)\n\nCommunity\n\n  * [Slack](https://join.slack.com/t/generativeair/shared_invite/zt-2m3v8oddx-qz9S2ep_xL4sYvLuOhU39Q)\n\nCopyright Â© 2024 Aimon Labs, Inc. All rights reserved\n\n', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\n\n{content}', metadata_template='{key}: {value}', metadata_seperator='\n'), Document(id_='https://docs.aimon.ai/concepts/detectors/completeness', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='Skip to main content\n\n[![Aimon Logo](/img/logo.png)![Aimon Logo](/img/logo.png)](/)\n\n[GitHub](https://github.com/aimonlabs/aimon-python-sdk)\n\n  * [Welcome to AIMon](/)\n  * [Introduction](/category/introduction)\n\n  * [Getting Started](/category/getting-started)\n\n  * [Concepts](/category/concepts)\n\n    * [Detectors](/category/detectors)\n\n      * [Hallucination](/concepts/detectors/hallucination)\n      * [Instruction Adherence](/concepts/detectors/instruction_adherence)\n      * [Conciseness](/concepts/detectors/conciseness)\n      * [Completeness](/concepts/detectors/completeness)\n      * [Toxicity](/concepts/detectors/toxicity)\n    * [Evaluation and Continuous Monitoring](/concepts/evaluation_and_monitoring)\n  * [Example Applications](/category/example-applications)\n\n  * [](/)\n  * [Concepts](/category/concepts)\n  * [Detectors](/category/detectors)\n  * Completeness\n\nOn this page\n\n# Completeness\n\nGiven a context, generated text and optionally a user query or a reference\ntext, this API is able to detect if the generated text completely answered the\nuser\'s question. The context should include the context documents as passed in\nto the LLM. The output contains a ""score"" that is between 0.0 and 1.0 which\nindicates the degree of completeness. If the generated answer is not at all\nrelevant to the user query, a score between 0.0 to 0.2 is possible. If the\ngenerated answer is relevant but misses some information, a score between 0.2\nand 0.7 is possible. If the generated answer is relevant and fully captures\nall of the information, a score between 0.7 and 1.0 is possible. The API also\nincludes a ""reasoning"" field that is a text based explanation of the score. It\nalso does a best effort method of pointing out the points that were missed\nfrom the expected answer.\n\n### Example Request[â\x80\x8b](/concepts/detectors/completeness#example-request\n""Direct link to Example Request"")\n\n    \n    \n    [  \n      {  \n        ""context"": ""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News."",  \n        ""generated_text"": ""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade. In addition, he has also been involved in writing essays and sharing his thoughts on technology, startups, and programming."",  \n        ""config"": {  \n          ""completeness"": {  \n            ""detector_name"": ""default""  \n          }  \n        }  \n      }  \n    ]  \n    \n\n#### Example Response[â\x80\x8b](/concepts/detectors/completeness#example-response\n""Direct link to Example Response"")\n\n    \n    \n    [  \n        {  \n            ""completeness"": {  \n                ""reasoning"": ""The generated answer is somewhat relevant to the query but omits significant information from the context documents, particularly about Paul Graham\'s contributions to Lisp, co-founding Y Combinator, and his work with Viaweb. It also includes details like the IBM 1401 that are not mentioned in the context, leading to inaccuracies and potential confusion. Thus, it doesn\'t provide a complete understanding of his career and achievements."",  \n                ""score"": 0.227  \n            }  \n        }  \n    ]  \n    \n\n### Example (Synchronous\ndetection)[â\x80\x8b](/concepts/detectors/completeness#example-synchronous-detection\n""Direct link to Example \\(Synchronous detection\\)"")\n\nThe below example demonstrates how to use the instruction adherence detector\nin a synchronous manner.\n\n  * Python\n  * TypeScript\n\n    \n    \n    from aimon import Detect  \n      \n    detect = Detect(values_returned=[\'context\', \'generated_text\'], config={""completeness"": {""detector_name"": ""default""}})  \n      \n    @detect  \n    def my_llm_app(context, query):  \n        generated_text = my_llm_model(context, query)  \n        return context, generated_text  \n    \n    \n    \n    import Client from ""aimon"";  \n      \n    const aimon_client = new Client({  \n      authHeader: `Bearer API_KEY`,  \n    });  \n      \n    const completeness_config = {  \n        completeness: {  \n          detector_name: ""default""  \n        }  \n    };  \n      \n    // Detect quality of the generated output using AIMon  \n    const detectParams: Client.InferenceDetectParams.Body[] = [  \n      {  \n        context: contextDocs,  \n        generated_text: output.text,  \n        config: completeness_config  \n      },  \n    ];  \n      \n    // Call the API  \n    const aimonResponse: Client.InferenceDetectResponse =  \n      await aimon_client.inference.detect(detectParams);  \n      \n    \n\n[PreviousConciseness](/concepts/detectors/conciseness)[NextToxicity](/concepts/detectors/toxicity)\n\n  * [Example Request](/concepts/detectors/completeness#example-request)\n  * [Example (Synchronous detection)](/concepts/detectors/completeness#example-synchronous-detection)\n\nDocs\n\n  * [Tutorial](/)\n\nCommunity\n\n  * [Slack](https://join.slack.com/t/generativeair/shared_invite/zt-2m3v8oddx-qz9S2ep_xL4sYvLuOhU39Q)\n\nCopyright Â© 2024 Aimon Labs, Inc. All rights reserved\n\n', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\n\n{content}', metadata_template='{key}: {value}', metadata_seperator='\n'), Document(id_='https://docs.aimon.ai/concepts/detectors/conciseness', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='Skip to main content\n\n[![Aimon Logo](/img/logo.png)![Aimon Logo](/img/logo.png)](/)\n\n[GitHub](https://github.com/aimonlabs/aimon-python-sdk)\n\n  * [Welcome to AIMon](/)\n  * [Introduction](/category/introduction)\n\n  * [Getting Started](/category/getting-started)\n\n  * [Concepts](/category/concepts)\n\n    * [Detectors](/category/detectors)\n\n      * [Hallucination](/concepts/detectors/hallucination)\n      * [Instruction Adherence](/concepts/detectors/instruction_adherence)\n      * [Conciseness](/concepts/detectors/conciseness)\n      * [Completeness](/concepts/detectors/completeness)\n      * [Toxicity](/concepts/detectors/toxicity)\n    * [Evaluation and Continuous Monitoring](/concepts/evaluation_and_monitoring)\n  * [Example Applications](/category/example-applications)\n\n  * [](/)\n  * [Concepts](/category/concepts)\n  * [Detectors](/category/detectors)\n  * Conciseness\n\nOn this page\n\n# Conciseness\n\nGiven a context, generated text and optionally a user query or a reference\ntext, this API is able to detect if the generated text was concise or verbose\nin terms of addressing the user query. The context should include the context\ndocuments along with the user query as passed in to the LLM. The output\ncontains a ""score"" that is between 0.0 and 1.0 which indicates the degree of\nconciseness. If the generated answer is very verbose and contains a lot of un-\nnecessary information that is not relevant to the user query, a score between\n0.0 to 0.2 is possible. If the generated answer is mostly relevant to the user\nquery but has some amount of text that is not necessary for the user query a\nscore between 0.2 and 0.7 is possible. If the generated answer is very concise\nand properly addresses all important points for the user query, a score\nbetween 0.7 and 1.0 is possible. The API also includes a ""reasoning"" field\nthat is a text based explanation of the score. It also does a best effort\nmethod of pointing out the unnecessary information that was included in the\noutput.\n\n### Example Request[â\x80\x8b](/concepts/detectors/conciseness#example-request\n""Direct link to Example Request"")\n\n    \n    \n    [  \n      {  \n        ""context"": ""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News."",  \n        ""generated_text"": ""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade. In addition, he has also been involved in writing essays and sharing his thoughts on technology, startups, and programming."",  \n        ""config"": {  \n          ""conciseness"": {  \n            ""detector_name"": ""default""  \n          }  \n        }  \n      }  \n    ]  \n    \n\n#### Example Response[â\x80\x8b](/concepts/detectors/conciseness#example-response\n""Direct link to Example Response"")\n\n    \n    \n    [  \n        {  \n            ""conciseness"": {  \n                ""reasoning"": ""The generated answer includes relevant information about Paul Graham\'s background but contains unnecessary details that do not directly relate to the user query, which is unspecified. While it touches on his programming beginnings and writing, it lacks emphasis on the key aspects of his impact and contributions, making it less concise than it could be."",  \n                ""score"": 0.25  \n            }  \n        }  \n    ]  \n    \n\n### Example (Synchronous\ndetection)[â\x80\x8b](/concepts/detectors/conciseness#example-synchronous-detection\n""Direct link to Example \\(Synchronous detection\\)"")\n\nThe below example demonstrates how to use the instruction adherence detector\nin a synchronous manner.\n\n  * Python\n  * TypeScript\n\n    \n    \n    from aimon import Detect  \n      \n    detect = Detect(values_returned=[\'context\', \'generated_text\'], config={""conciseness"": {""detector_name"": ""default""}})  \n      \n    @detect  \n    def my_llm_app(context, query):  \n        generated_text = my_llm_model(context, query)  \n        return context, generated_text  \n    \n    \n    \n    import Client from ""aimon"";  \n      \n    const aimon_client = new Client({  \n      authHeader: `Bearer API_KEY`,  \n    });  \n      \n    const concisness_config = {  \n        conciseness: {  \n          detector_name: ""default""  \n        }  \n    };  \n      \n    // Detect quality of the generated output using AIMon  \n    const detectParams: Client.InferenceDetectParams.Body[] = [  \n      {  \n        context: contextDocs,  \n        generated_text: output.text,  \n        config: concisness_config  \n      },  \n    ];  \n      \n    // Call the API  \n    const aimonResponse: Client.InferenceDetectResponse =  \n      await aimon_client.inference.detect(detectParams);  \n      \n    \n\n[PreviousInstruction\nAdherence](/concepts/detectors/instruction_adherence)[NextCompleteness](/concepts/detectors/completeness)\n\n  * [Example Request](/concepts/detectors/conciseness#example-request)\n  * [Example (Synchronous detection)](/concepts/detectors/conciseness#example-synchronous-detection)\n\nDocs\n\n  * [Tutorial](/)\n\nCommunity\n\n  * [Slack](https://join.slack.com/t/generativeair/shared_invite/zt-2m3v8oddx-qz9S2ep_xL4sYvLuOhU39Q)\n\nCopyright Â© 2024 Aimon Labs, Inc. All rights reserved\n\n', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\n\n{content}', metadata_template='{key}: {value}', metadata_seperator='\n'), Document(id_='https://docs.aimon.ai/concepts/detectors/hallucination', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='Skip to main content\n\n[![Aimon Logo](/img/logo.png)![Aimon Logo](/img/logo.png)](/)\n\n[GitHub](https://github.com/aimonlabs/aimon-python-sdk)\n\n  * [Welcome to AIMon](/)\n  * [Introduction](/category/introduction)\n\n  * [Getting Started](/category/getting-started)\n\n  * [Concepts](/category/concepts)\n\n    * [Detectors](/category/detectors)\n\n      * [Hallucination](/concepts/detectors/hallucination)\n      * [Instruction Adherence](/concepts/detectors/instruction_adherence)\n      * [Conciseness](/concepts/detectors/conciseness)\n      * [Completeness](/concepts/detectors/completeness)\n      * [Toxicity](/concepts/detectors/toxicity)\n    * [Evaluation and Continuous Monitoring](/concepts/evaluation_and_monitoring)\n  * [Example Applications](/category/example-applications)\n\n  * [](/)\n  * [Concepts](/category/concepts)\n  * [Detectors](/category/detectors)\n  * Hallucination\n\nOn this page\n\n# Hallucination\n\nGiven a context, a generated text and optionally a user query, we are able to\ndetect 2 different types of model hallucinations: intrinsic and extrinsic.\nIntrinsic Hallucinations are hallucinations where the models manipulate\noriginal information and slightly misrepresent true facts. For example,\nâ\x80\x9cEiffel Tower is the tallest building in France\'\' or â\x80\x9cThe first man on the\nmoon was Yuri Gagarinâ\x80\x9d. Extrinsic Hallucinations are the ones where models\ncompletely fabricate new false information. This canâ\x80\x99t be inferred from or\ntraced back to original sources. For example, â\x80\x9cCristiano Ronaldo is a\nCricket playerâ\x80\x9d. The ""is_hallucinated"" field indicates whether the\n""generated_text"" (passed in the input) is hallucinated. A top level ""score""\nfield indicates if the entire paragraph contained any hallucinations. The\nscore is a probability measure of how hallucinated the text is compared to the\ncontext. A score >= 0.5 can be classified as a hallucination. We also provide\nsentence level scores to help with explainability.\n\n### Example Request[â\x80\x8b](/concepts/detectors/hallucination#example-request\n""Direct link to Example Request"")\n\n    \n    \n    [  \n      {  \n        ""context"": ""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News."",  \n        ""generated_text"": ""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade. In addition, he has also been involved in writing essays and sharing his thoughts on technology, startups, and programming."",  \n        ""config"": {  \n          ""hallucination"": {  \n            ""detector_name"": ""default""  \n          }  \n        }  \n      }  \n    ]  \n    \n\n#### Example Response[â\x80\x8b](/concepts/detectors/hallucination#example-response\n""Direct link to Example Response"")\n\n    \n    \n    [  \n      {  \n        ""hallucination"": {  \n          ""is_hallucinated"": ""True"",  \n          ""score"": 0.7407,  \n          ""sentences"": [  \n            {  \n              ""score"": 0.7407,  \n              ""text"": ""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade.""  \n            },  \n            {  \n              ""score"": 0.03326,  \n              ""text"": ""In addition, he has also been involved in writing essays and sharing his thoughts on technology, startups, and programming.""  \n            }  \n          ]  \n        }  \n      }  \n    ]  \n    \n\n### Example (Synchronous\ndetection)[â\x80\x8b](/concepts/detectors/hallucination#example-synchronous-\ndetection ""Direct link to Example \\(Synchronous detection\\)"")\n\nThe below example demonstrates how to use the hallucination detector in a\nsynchronous manner. We also support asynchronous computation. Refer to the\n[evaluation and monitoring section](/concepts/evaluation_and_monitoring) for\ndetails.\n\n  * Python\n  * TypeScript\n\n    \n    \n    from aimon import Detect  \n      \n    # See analyze_prod for the asynchronous version  \n    # that can be used for continuous monitoring  \n    detect = Detect(values_returned=[\'context\', \'generated_text\'], config={""hallucination"": {""detector_name"": ""default""}})  \n      \n    @detect  \n    def my_llm_app(context, query):  \n        generated_text = my_llm_model(context, query)  \n        return context, generated_text  \n      \n    \n    \n    \n    import Client from ""aimon"";  \n      \n    const aimon_client = new Client({  \n      authHeader: `Bearer API_KEY`,  \n    });  \n      \n    const detectMetrics: any = async (sourceText: any) => {  \n      // Split the source text  \n      const textSplitter = new RecursiveCharacterTextSplitter({ chunkSize: 1000 });  \n      const docs = await textSplitter.createDocuments([sourceText]);  \n      const contextDocs = docs.map((doc) => doc.pageContent);  \n      \n      // Summarize the texts  \n      const llm = new OpenAI({ temperature: 0, openAIApiKey: openaiApiKey });  \n      const chain = loadSummarizationChain(llm, { type: ""map_reduce"" });  \n      const output = await chain.invoke({  \n        input_documents: docs,  \n      });  \n      \n      const hall_config = {  \n          hallucination: {  \n          detector_name: ""default""  \n        }  \n      };  \n      \n      // Detect quality of the generated output using AIMon  \n      const detectParams: Client.InferenceDetectParams.Body[] = [  \n        {  \n          context: contextDocs,  \n          generated_text: output.text,  \n          config: hall_config  \n        },  \n      ];  \n      \n      // Call the API  \n      const aimonResponse: Client.InferenceDetectResponse =  \n        await aimon_client.inference.detect(detectParams);  \n    };  \n    \n\n[PreviousDetectors](/category/detectors)[NextInstruction\nAdherence](/concepts/detectors/instruction_adherence)\n\n  * [Example Request](/concepts/detectors/hallucination#example-request)\n  * [Example (Synchronous detection)](/concepts/detectors/hallucination#example-synchronous-detection)\n\nDocs\n\n  * [Tutorial](/)\n\nCommunity\n\n  * [Slack](https://join.slack.com/t/generativeair/shared_invite/zt-2m3v8oddx-qz9S2ep_xL4sYvLuOhU39Q)\n\nCopyright Â© 2024 Aimon Labs, Inc. All rights reserved\n\n', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\n\n{content}', metadata_template='{key}: {value}', metadata_seperator='\n'), Document(id_='https://docs.aimon.ai/concepts/detectors/instruction_adherence', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='Skip to main content\n\n[![Aimon Logo](/img/logo.png)![Aimon Logo](/img/logo.png)](/)\n\n[GitHub](https://github.com/aimonlabs/aimon-python-sdk)\n\n  * [Welcome to AIMon](/)\n  * [Introduction](/category/introduction)\n\n  * [Getting Started](/category/getting-started)\n\n  * [Concepts](/category/concepts)\n\n    * [Detectors](/category/detectors)\n\n      * [Hallucination](/concepts/detectors/hallucination)\n      * [Instruction Adherence](/concepts/detectors/instruction_adherence)\n      * [Conciseness](/concepts/detectors/conciseness)\n      * [Completeness](/concepts/detectors/completeness)\n      * [Toxicity](/concepts/detectors/toxicity)\n    * [Evaluation and Continuous Monitoring](/concepts/evaluation_and_monitoring)\n  * [Example Applications](/category/example-applications)\n\n  * [](/)\n  * [Concepts](/category/concepts)\n  * [Detectors](/category/detectors)\n  * Instruction Adherence\n\nOn this page\n\n# Instruction Adherence\n\nGiven a set of â\x80\x9cinstructionsâ\x80\x9d, the generated text, the input context and\nthe user query, this API is able to check whether the generated text followed\nall the instructions specified. in the â\x80\x9cinstructionsâ\x80\x9d field.\n\nAn LLM (Large Language Model) following instructions in the prompt is crucial\nfor several reasons. Firstly, it ensures the generation of content that aligns\nwith the user\'s needs and expectations, providing relevant and accurate\ninformation or responses. This adherence to instructions enhances the utility\nand effectiveness of the model, making it a reliable tool for various\napplications such as customer support, content creation, and educational\nassistance. Moreover, following prompts precisely helps maintain coherence and\ncontext, preventing misunderstandings or the generation of irrelevant\ninformation. It also ensures ethical compliance, avoiding the creation of\ninappropriate or harmful content. Ultimately, prompt adherence maximizes the\nvalue of the LLM, fostering user trust and satisfaction.\n\n### Example Request[â\x80\x8b](/concepts/detectors/instruction_adherence#example-\nrequest ""Direct link to Example Request"")\n\n    \n    \n    [  \n      {  \n        ""context"": ""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News."",  \n        ""instructions"": ""Write a summary of Paul Graham\'s career and achievements."",  \n        ""generated_text"": ""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade. In addition, he has also been involved in writing essays and sharing his thoughts on technology, startups, and programming."",  \n        ""config"": {  \n          ""instruction_adherence"": {  \n            ""detector_name"": ""default""  \n          }  \n        }  \n      }  \n    ]  \n    \n\n#### Example Response[â\x80\x8b](/concepts/detectors/instruction_adherence#example-\nresponse ""Direct link to Example Response"")\n\n    \n    \n    [  \n      {  \n        ""instruction_adherence"": {  \n          ""results"": [  \n            {  \n              ""adherence"": false,  \n              ""detailed_explanation"": ""The response provides a very limited overview of Paul Graham\'s career, only mentioning his early programming on the IBM 1401 and general involvement in writing essays. It fails to cover significant achievements such as his work on Lisp, co-founding Y Combinator, and his influence in the tech and startup world."",  \n              ""instruction"": ""Write a summary of Paul Graham\'s career and achievements.""  \n            }  \n          ],  \n          ""score"": 0.0  \n        }  \n      }  \n    ]  \n    \n\n### Example (Synchronous\ndetection)[â\x80\x8b](/concepts/detectors/instruction_adherence#example-synchronous-\ndetection ""Direct link to Example \\(Synchronous detection\\)"")\n\nThe below example demonstrates how to use the instruction adherence detector\nin a synchronous manner.\n\n  * Python\n  * TypeScript\n\n    \n    \n    from aimon import Detect  \n      \n    detect = Detect(values_returned=[\'context\', \'generated_text\', \'instructions\'], config={""instruction_adherence"": {""detector_name"": ""default""}})  \n      \n    @detect  \n    def my_llm_app(context, query, instructions):  \n        generated_text = my_llm_model(context, query)  \n        return context, generated_text, instructions  \n    \n    \n    \n    import Client from ""aimon"";  \n      \n    const aimon_client = new Client({  \n      authHeader: `Bearer API_KEY`,  \n    });  \n      \n    const instruction_adherence_config = {  \n        instruction_adherence: {  \n          detector_name: ""default""  \n        }  \n    };  \n      \n    // Detect quality of the generated output using AIMon  \n    const detectParams: Client.InferenceDetectParams.Body[] = [  \n      {  \n        context: contextDocs,  \n        generated_text: output.text,  \n        instructions: instructions,  \n        config: instruction_adherence_config  \n      },  \n    ];  \n      \n    // Call the API  \n    const aimonResponse: Client.InferenceDetectResponse =  \n      await aimon_client.inference.detect(detectParams);  \n      \n    \n\n[PreviousHallucination](/concepts/detectors/hallucination)[NextConciseness](/concepts/detectors/conciseness)\n\n  * [Example Request](/concepts/detectors/instruction_adherence#example-request)\n  * [Example (Synchronous detection)](/concepts/detectors/instruction_adherence#example-synchronous-detection)\n\nDocs\n\n  * [Tutorial](/)\n\nCommunity\n\n  * [Slack](https://join.slack.com/t/generativeair/shared_invite/zt-2m3v8oddx-qz9S2ep_xL4sYvLuOhU39Q)\n\nCopyright Â© 2024 Aimon Labs, Inc. All rights reserved\n\n', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\n\n{content}', metadata_template='{key}: {value}', metadata_seperator='\n'), Document(id_='https://docs.aimon.ai/concepts/detectors/toxicity', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='Skip to main content\n\n[![Aimon Logo](/img/logo.png)![Aimon Logo](/img/logo.png)](/)\n\n[GitHub](https://github.com/aimonlabs/aimon-python-sdk)\n\n  * [Welcome to AIMon](/)\n  * [Introduction](/category/introduction)\n\n  * [Getting Started](/category/getting-started)\n\n  * [Concepts](/category/concepts)\n\n    * [Detectors](/category/detectors)\n\n      * [Hallucination](/concepts/detectors/hallucination)\n      * [Instruction Adherence](/concepts/detectors/instruction_adherence)\n      * [Conciseness](/concepts/detectors/conciseness)\n      * [Completeness](/concepts/detectors/completeness)\n      * [Toxicity](/concepts/detectors/toxicity)\n    * [Evaluation and Continuous Monitoring](/concepts/evaluation_and_monitoring)\n  * [Example Applications](/category/example-applications)\n\n  * [](/)\n  * [Concepts](/category/concepts)\n  * [Detectors](/category/detectors)\n  * Toxicity\n\nOn this page\n\n# Toxicity\n\nGiven a context, generated text and optionally a user query or reference text,\nthis API is able to generate various toxicity scores. The context should\ninclude the context documents along with the user query as passed in to the\nLLM. The output contains multiple labels with a value between 0.0 and 1.0\nwhich indicates the likelihood of the label.\n\nThere are 6 different possible labels:\n\n  * `identity_hate`: Indicates possible hateful language that targets a personâ\x80\x99s identity.\n  * `toxic`: Content that is generally considered unsafe for a broad audience.\n  * `severe_toxic`: Extremely harmful content that should not be shown to a general audience.\n  * `obscene`: Content that is offensive or disgusting by accepted standards of morality and decency.\n  * `threat`: Content that contains threatening language.\n  * `insult`: Content that contains disrespectful or scornfully abusive language.\n\n### Example Request[â\x80\x8b](/concepts/detectors/toxicity#example-request ""Direct\nlink to Example Request"")\n\n    \n    \n    [  \n      {  \n        ""context"": ""Paul Graham is an English-born computer scientist, entrepreneur, venture capitalist, author, and essayist. He is best known for his work on Lisp, his former startup Viaweb (later renamed Yahoo! Store), co-founding the influential startup accelerator and seed capital firm Y Combinator, his blog, and Hacker News."",  \n        ""generated_text"": ""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade. In addition, he has also been involved in writing essays and sharing his thoughts on technology, startups, and programming."",  \n        ""config"": {  \n          ""toxicity"": {  \n            ""detector_name"": ""default""  \n          }  \n        }  \n      }  \n    ]  \n    \n\n#### Example Response[â\x80\x8b](/concepts/detectors/toxicity#example-response\n""Direct link to Example Response"")\n\n    \n    \n    [  \n      {  \n        ""toxicity"": {  \n          ""results"": {  \n            ""generated_text"": {  \n              ""detected_labels"": {  \n                ""identity_hate"": 0.11749652028083801,  \n                ""insult"": 0.35200783610343933,  \n                ""obscene"": 0.24614322185516357,  \n                ""severe_toxic"": 0.05233444273471832,  \n                ""threat"": 0.119813933968544,  \n                ""toxic"": 0.11220399290323257  \n              },  \n              ""text"": ""Paul Graham has worked in several key areas throughout his career: IBM 1401: He began programming on the IBM 1401 during his school years, specifically in 9th grade. In addition, he has also been involved in writing essays and sharing his thoughts on technology, startups, and programming.""  \n            }  \n          },  \n          ""score"": 0.35200783610343933  \n        }  \n      }  \n    ]  \n    \n\n### Example (Synchronous detection)[â\x80\x8b](/concepts/detectors/toxicity#example-\nsynchronous-detection ""Direct link to Example \\(Synchronous detection\\)"")\n\nThe below example demonstrates how to use the instruction adherence detector\nin a synchronous manner.\n\n  * Python\n  * TypeScript\n\n    \n    \n    from aimon import Detect  \n      \n    detect = Detect(values_returned=[\'context\', \'generated_text\'],config={""toxicity"": {""detector_name"": ""default""}})  \n      \n    @detect  \n    def my_llm_app(context, query):  \n        generated_text = my_llm_model(context, query)  \n        return context, generated_text  \n    \n    \n    \n    import Client from ""aimon"";  \n      \n    const aimon_client = new Client({  \n      authHeader: `Bearer API_KEY`,  \n    });  \n      \n    const toxicity_config = {  \n        toxicity: {  \n          detector_name: ""default""  \n        }  \n    };  \n      \n    // Detect quality of the generated output using AIMon  \n    const detectParams: Client.InferenceDetectParams.Body[] = [  \n      {  \n        context: contextDocs,  \n        generated_text: output.text,  \n        config: toxicity_config  \n      },  \n    ];  \n      \n    // Call the API  \n    const aimonResponse: Client.InferenceDetectResponse =  \n      await aimon_client.inference.detect(detectParams);  \n      \n    \n\n[PreviousCompleteness](/concepts/detectors/completeness)[NextEvaluation and\nContinuous Monitoring](/concepts/evaluation_and_monitoring)\n\n  * [Example Request](/concepts/detectors/toxicity#example-request)\n  * [Example (Synchronous detection)](/concepts/detectors/toxicity#example-synchronous-detection)\n\nDocs\n\n  * [Tutorial](/)\n\nCommunity\n\n  * [Slack](https://join.slack.com/t/generativeair/shared_invite/zt-2m3v8oddx-qz9S2ep_xL4sYvLuOhU39Q)\n\nCopyright Â© 2024 Aimon Labs, Inc. All rights reserved\n\n', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\n\n{content}', metadata_template='{key}: {value}', metadata_seperator='\n'), Document(id_='https://docs.aimon.ai/concepts/evaluation_and_monitoring', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='Skip to main content\n\n[![Aimon Logo](/img/logo.png)![Aimon Logo](/img/logo.png)](/)\n\n[GitHub](https://github.com/aimonlabs/aimon-python-sdk)\n\n  * [Welcome to AIMon](/)\n  * [Introduction](/category/introduction)\n\n  * [Getting Started](/category/getting-started)\n\n  * [Concepts](/category/concepts)\n\n    * [Detectors](/category/detectors)\n\n    * [Evaluation and Continuous Monitoring](/concepts/evaluation_and_monitoring)\n  * [Example Applications](/category/example-applications)\n\n  * [](/)\n  * [Concepts](/category/concepts)\n  * Evaluation and Continuous Monitoring\n\nOn this page\n\n# Evaluation and Continuous Monitoring\n\nWith AIMon, you can evaluate and continuously monitor the quality of the\ngenerated text. In this section, we will demonstrate how to quickly and easily\nsetup evaluation and/or monitoring for your LLM applications. Let\'s start with\nsome basic concepts that will be useful to understand before instrumenting\nyour LLM application.\n\n### Model[â\x80\x8b](/concepts/evaluation_and_monitoring#model ""Direct link to\nModel"")\n\nA model is a generative model, typically an LLM, that generates text based on\nan input query, context and user provided instructions. The model can be a\nvanilla model, a fine-tuned model or a prompt-engineered model.\n\n### Application[â\x80\x8b](/concepts/evaluation_and_monitoring#application ""Direct\nlink to Application"")\n\nAn application is a specific use-case or a task that is associated a model.\nFor example, a summarization application. Each application is versioned i.e.,\neach application is associated with a particular model for a given version of\nthe application. When you use a different model for the same application,\nAIMon will automatically create a new version of the application.\n\n### Evaluation[â\x80\x8b](/concepts/evaluation_and_monitoring#evaluation ""Direct\nlink to Evaluation"")\n\nEvaluation is the process of assessing the quality of the generated text\ntypically in an offline setup. This can be done using various detectors\nprovided by the AIMon platform. AIMon adopts a ""batteries included"" approach\ni.e., you do not have to use another third-party API for the various\ndetectors.\n\nBefore deploying the application to production, it is a good idea to test it\nwith either a curated golden dataset or a snapshot of production traffic. In\nthis section, we will demonstrate how AIMon can assist you to perform these\ntests.\n\n#### Evaluation Dataset[â\x80\x8b](/concepts/evaluation_and_monitoring#evaluation-\ndataset ""Direct link to Evaluation Dataset"")\n\nAIMon can manage datasets for you. The dataset should be a CSV file with these\ncolumns:\n\n  * ""prompt"": This is the prompt used for the LLM\n  * ""user_query"": This the query specified by the user\n  * ""context_docs"": These are context documents that are either retrieved from a RAG or through other methods. For tasks like summarization, these documents could be directly specified by the user.\n\nA dataset can be created using the AIMon client as follows:\n\n  * Python\n  * TypeScript\n\n    \n    \n    from aimon import Client  \n    import json  \n      \n    aimon_client = Client(auth_header=""Bearer <AIMON API KEY>"")  \n    # Create a new datasets  \n    file_path = ""evaluation_dataset.csv""  \n      \n    dataset = json.dumps({  \n        ""name"": ""evaluation_dataset.csv"",  \n        ""description"": ""This is a golden dataset""  \n    })  \n      \n    with open(file_path, \'rb\') as file1:  \n        aimon_dataset = aimon_client.datasets.create(  \n            file=file1,  \n            json_data=dataset  \n        )  \n    \n    \n    \n    import Client from ""aimon"";  \n      \n    const aimon_client = new Client({  \n      authHeader: `Bearer API_KEY`,  \n    });  \n      \n      \n    // Creates a new dataset from the local path csv file  \n    const createDataset = async (  \n      path: string,  \n      datasetName: string,  \n      description: string  \n    ): Promise<Client.Dataset> => {  \n      const file = await fileFromPath(path);  \n      const json_data = JSON.stringify({  \n        name: datasetName,  \n        description: description,  \n      });  \n      \n      const params = {  \n        file: file,  \n        json_data: json_data,  \n      };  \n      \n      const dataset: Client.Dataset = await aimon.datasets.create(params);  \n      return dataset;  \n    };  \n    \n\n##### Dataset Collection[â\x80\x8b](/concepts/evaluation_and_monitoring#dataset-\ncollection ""Direct link to Dataset Collection"")\n\nYou can group a collection of evaluation datasets into a `dataset collection`\nfor ease of use. A dataset collection can be created as follows:\n\n  * Python\n  * TypeScript\n\n    \n    \n    dataset_collection = aimon_client.datasets.collection.create(  \n        name=""my_first_dataset_collection"",   \n        dataset_ids=[aimon_dataset1.sha, aimon_dataset2.sha],   \n        description=""This is a collection of two datasets.""  \n    )  \n    \n    \n    \n    const dataset1 = await createDataset(  \n        ""/path/to/file/filename_1.csv"",  \n        ""filename1.csv"",  \n        ""description""  \n    );  \n      \n    const dataset2 = await createDataset(  \n        ""/path/to/file/filename_2.csv"",  \n        ""filename2.csv"",  \n        ""description""  \n    );  \n      \n    let datasetCollection: Client.Datasets.CollectionCreateResponse | undefined;  \n      \n    // Ensures that dataset1.sha and dataset2.sha are defined  \n    if (dataset1.sha && dataset2.sha) {  \n        // Creates dataset collection  \n        datasetCollection = await aimon.datasets.collection.create({  \n        name: ""my_first_dataset_collection"",  \n        dataset_ids: [dataset1.sha, dataset2.sha],  \n        description: ""This is a collection of two datasets."",  \n        });  \n    } else {  \n        throw new Error(""Dataset sha is undefined"");  \n    }  \n      \n    \n\nThis allows you to then access records from the dataset collection as follows:\n\n  * Python\n  * TypeScript\n\n    \n    \n    # Get all records from the datasets in this collection  \n    dataset_collection_records = []  \n    for dataset_id in dataset_collection.dataset_ids:  \n        dataset_records = aimon_client.datasets.records.list(sha=dataset_id)  \n        dataset_collection_records.extend(dataset_records)  \n    \n    \n    \n      \n    const datasetCollectionRecords: any[] = [];  \n      \n    for (const datasetId of datasetCollection.dataset_ids) {  \n      const datasetRecords = await aimonClient.datasets.records.list({ sha: datasetId });  \n      datasetCollectionRecords.push(...datasetRecords);  \n    }  \n    \n\n#### Creating an Evaluation[â\x80\x8b](/concepts/evaluation_and_monitoring#creating-\nan-evaluation ""Direct link to Creating an Evaluation"")\n\nAn evaluation is associated with a specific dataset collection and a\nparticular version of an application (and its corresponding model).\n\n#### Running an Evaluation[â\x80\x8b](/concepts/evaluation_and_monitoring#running-\nan-evaluation ""Direct link to Running an Evaluation"")\n\nA ""run"" is an instance of an evaluation that you would like to track metrics\nagainst. You could have multiple runs of the same evaluation. This is\ntypically done in a CI/CD context where the same evaluation would run at\nregular intervals. Since LLMs are probabilistic in nature, they could produce\ndifferent outputs for the same query and context. It is a good idea to run the\nevaluations regularly to understand the variations of outputs produced by your\nLLMs. In addition, runs give you the ability to choose different metrics for\neach run.\n\nDetectors can be specified using the `config` parameter in the payload as\nshown below. The keys indicate the type of metric computed and the value of\n`detector_name` is the specific algorithm used to compute those metrics. For\nmost cases, we recommend using the `default` algorithm for each detector.\n\n  * Python\n  * TypeScript\n\n    \n    \n    config={  \n        \'hallucination\': {\'detector_name\':\'default\'},   \n        \'toxicity\': {\'detector_name\':\'default\'},   \n        \'conciseness\': {\'detector_name\':\'default\'},   \n        \'completeness\': {\'detector_name\':\'default\'}  \n    }  \n    \n    \n    \n    const config = {  \n      hallucination: { detector_name: ""default"" },  \n      toxicity: { detector_name: ""default"" },  \n      conciseness: { detector_name: ""default"" },  \n      completeness: { detector_name: ""default"" }  \n    };  \n    \n\nYou can also `tag` a particular run. Tags allow you to specify metadata like\nthe application commit SHA or other key-value pairs that you want to insert\nfor analytics purposes.\n\n#### Example[â\x80\x8b](/concepts/evaluation_and_monitoring#example ""Direct link to\nExample"")\n\nSetting up and running an evaluation can be done using the higher level\n`Analyze` decorator in Python or the low level API that offers more control.\n\nHere is an example of running an evaluation\n\n  * Python\n  * TypeScript\n\n    \n    \n    from aimon import AnalyzeEval, Application, Model  \n      \n    analyze_eval = AnalyzeEval(  \n        Application(""my_first_llm_app""),  \n        Model(""my_first_model"", ""GPT-4o""),   \n        evaluation_name=""your_first_evaluation"",  \n        dataset_collection_name=""my_first_dataset_collection"",  \n    )  \n      \n    # Lanchain app example  \n    from langchain.text_splitter import CharacterTextSplitter  \n    from langchain.docstore.document import Document  \n    from langchain.llms.openai import OpenAI  \n    from langchain.chains.summarize import load_summarize_chain  \n      \n    # The analyze_eval decorator will automatically stream through  \n    # records in the specified data collection and run it against   \n    # this function. The signature of this function should necessarily   \n    # contain context_docs, user_query and prompt as the first 3   \n    # arguments.  \n    @analyze_eval  \n    def run_application_eval_mode(context_docs=None, user_query=None, prompt=None):  \n        # Split the source text  \n        text_splitter = CharacterTextSplitter()  \n        texts = text_splitter.split_text(context_docs)  \n          \n        # Create Document objects for the texts  \n        docs = [Document(page_content=t) for t in texts[:3]]  \n          \n        # Initialize the OpenAI module, load and run the summarize chain  \n        llm = OpenAI(temperature=0, openai_api_key=openai_api_key)  \n        chain = load_summarize_chain(llm, chain_type=""map_reduce"")  \n        return chain.run(docs)  \n      \n    # This will automatically run an evaluation using records from the specified dataset collection asynchronously.  \n    aimon_eval_res = run_application_eval_mode()  \n    print(aimon_eval_res)  \n    \n    \n    \n    import Client from ""aimon"";  \n    import { OpenAI } from ""@langchain/openai"";  \n    import { loadSummarizationChain } from ""langchain/chains"";  \n    import { RecursiveCharacterTextSplitter } from ""langchain/text_splitter"";  \n    import { fileFromPath } from ""formdata-node/file-from-path"";  \n      \n    // Create the AIMon client. You would need an API Key (that can be retrieved from the UI in your user profile).  \n    const aimon = new Client({  \n      authHeader: \'Bearer: <AIMON_API_KEY>\',  \n    });  \n      \n    // Initialize OpenAI configuration  \n    const openaiApiKey = ""OPENAI_API_KEY"";  \n      \n    // Analyzes the dataset record and model output offline.  \n    const runApplication: any = async (  \n      application: any,  \n      sourceText: any,  \n      prompt: string | null = null,  \n      userQuery: string | null = null,  \n      evaluationRun: any = null  \n    ) => {  \n      // Split the source text  \n      const textSplitter = new RecursiveCharacterTextSplitter({ chunkSize: 1000 });  \n      const docs = await textSplitter.createDocuments([sourceText]);  \n      const contextDocs = docs.map((doc) => doc.pageContent);  \n      \n      // Summarize the texts  \n      const llm = new OpenAI({ temperature: 0, openAIApiKey: openaiApiKey });  \n      const chain = loadSummarizationChain(llm, { type: ""map_reduce"" });  \n      const output = await chain.invoke({  \n        input_documents: docs,  \n      });  \n      \n      // Analyze quality of the generated output using AIMon  \n      const aimonResponse: Client.AnalyzeCreateResponse =  \n        await aimon.analyze.create([  \n          {  \n            application_id: application.id,  \n            version: application.version,  \n            prompt: prompt !== null ? prompt : """",  \n            user_query: userQuery !== null ? userQuery : """",  \n            context_docs: contextDocs,  \n            output: output.text,  \n            evaluation_id: evaluationRun.evaluation_id,  \n            evaluation_run_id: evaluationRun.id,  \n          },  \n        ]);  \n    };  \n      \n      \n    for (const record of datasetCollectionRecords) {  \n        await runApplication(  \n            myApplication,  \n            record.context_docs,  \n            record.prompt,  \n            record.user_query,  \n            newEvaluationRun  \n        );  \n    }  \n      \n    \n\n### Continuous Monitoring[â\x80\x8b](/concepts/evaluation_and_monitoring#continuous-\nmonitoring ""Direct link to Continuous Monitoring"")\n\nOnce your application is ready for production, you can set up continuous\nmonitoring to track the quality of the generated text. This can also be done\nusing the `Analyze` decorator in Python or the `analyze.production` API in\nTypescript as follows:\n\n  * Python\n  * TypeScript\n\n    \n    \n    from aimon import AnalyzeProd, Application, Model  \n    analyze_prod = AnalyzeProd(  \n        Application(""my_first_llm_app""),   \n        Model(""my_best_model"", ""Llama3""),  \n        values_returned=[""context"", ""generated_text""],  \n    )  \n      \n    # Lanchain app example  \n    from langchain.text_splitter import CharacterTextSplitter  \n    from langchain.docstore.document import Document  \n    from langchain.llms.openai import OpenAI  \n    from langchain.chains.summarize import load_summarize_chain  \n      \n    @analyze_prod  \n    def run_application(context_docs=None, user_query=None, prompt=None):  \n        # Split the source text  \n        text_splitter = CharacterTextSplitter()  \n        texts = text_splitter.split_text(context_docs)  \n          \n        # Create Document objects for the texts  \n        docs = [Document(page_content=t) for t in texts[:3]]  \n          \n        # Initialize the OpenAI module, load and run the summarize chain  \n        llm = OpenAI(temperature=0, openai_api_key=openai_api_key)  \n        chain = load_summarize_chain(llm, chain_type=""map_reduce"")  \n        return context_docs, chain.run(docs)  \n      \n    source_text = ""Sample document to summarize""  \n      \n    # This will automatically run the application against the source text and prompt. It will also  \n    # asynchronously run detections for the quality of the generated text.  \n    context, res, aimon_res = run_application(source_text, prompt=""Langhchain based summarization of documents"")  \n    print(aimon_res)  \n    \n    \n    \n    import Client from ""aimon"";  \n    import { OpenAI } from ""@langchain/openai"";  \n    import { loadSummarizationChain } from ""langchain/chains"";  \n    import { RecursiveCharacterTextSplitter } from ""langchain/text_splitter"";  \n    import { fileFromPath } from ""formdata-node/file-from-path"";  \n      \n    // Create the AIMon client. You would need an API Key (that can be retrieved from the UI in your user profile).  \n    const aimon = new Client({  \n      authHeader: \'Bearer: <AIMON_API_KEY>\',  \n    });  \n      \n    // Initialize OpenAI configuration  \n    const openaiApiKey = ""OPENAI_API_KEY"";  \n      \n    const runApplication: any = async (  \n      applicationName: string,  \n      modelName: string,  \n      sourceText: any,  \n      prompt: string | null = null,  \n      userQuery: string | null = null,  \n    ) => {  \n      // Split the source text  \n      const textSplitter = new RecursiveCharacterTextSplitter({ chunkSize: 1000 });  \n      const docs = await textSplitter.createDocuments([sourceText]);  \n      const contextDocs = docs.map((doc) => doc.pageContent);  \n      \n      // Summarize the texts  \n      const llm = new OpenAI({ temperature: 0, openAIApiKey: openaiApiKey });  \n      const chain = loadSummarizationChain(llm, { type: ""map_reduce"" });  \n      const output = await chain.invoke({  \n        input_documents: docs,  \n      });  \n      \n      const payload = {  \n        context_docs: contextDocs,  \n        output: String(output.text),  \n        prompt: prompt ?? """",  \n        user_query: userQuery ?? """",  \n        instructions: ""These are the instructions"",  \n      };  \n      \n      const config = {  \n        hallucination: { detector_name: ""default"" },  \n        conciseness: { detector_name: ""default"" },  \n        completeness: { detector_name: ""default"" },  \n        instruction_adherence: { detector_name: ""default"" },  \n      };  \n      \n      // Analyze quality of the generated output using AIMon  \n      const response: Client.AnalyzeCreateResponse = await aimon.analyze.production(  \n        applicationName,  \n        modelName,  \n        payload,  \n        config  \n      );  \n    };  \n    \n\n### Lower level API[â\x80\x8b](/concepts/evaluation_and_monitoring#lower-level-api\n""Direct link to Lower level API"")\n\nIf you need more control over the evaluation or continuous monitoring process,\nyou can use the lower level API described in this\n[notebook](https://github.com/aimonlabs/aimon-python-\nsdk/blob/main/examples/notebooks/aimon_sdk_langchain_summarization_low_level_api.ipynb).\n\n[PreviousToxicity](/concepts/detectors/toxicity)[NextExample\nApplications](/category/example-applications)\n\n  * [Model](/concepts/evaluation_and_monitoring#model)\n  * [Application](/concepts/evaluation_and_monitoring#application)\n  * [Evaluation](/concepts/evaluation_and_monitoring#evaluation)\n  * [Continuous Monitoring](/concepts/evaluation_and_monitoring#continuous-monitoring)\n  * [Lower level API](/concepts/evaluation_and_monitoring#lower-level-api)\n\nDocs\n\n  * [Tutorial](/)\n\nCommunity\n\n  * [Slack](https://join.slack.com/t/generativeair/shared_invite/zt-2m3v8oddx-qz9S2ep_xL4sYvLuOhU39Q)\n\nCopyright Â© 2024 Aimon Labs, Inc. All rights reserved\n\n', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\n\n{content}', metadata_template='{key}: {value}', metadata_seperator='\n'), Document(id_='https://docs.aimon.ai/example-applications/chatbot', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='Skip to main content\n\n[![Aimon Logo](/img/logo.png)![Aimon Logo](/img/logo.png)](/)\n\n[GitHub](https://github.com/aimonlabs/aimon-python-sdk)\n\n  * [Welcome to AIMon](/)\n  * [Introduction](/category/introduction)\n\n  * [Getting Started](/category/getting-started)\n\n  * [Concepts](/category/concepts)\n\n  * [Example Applications](/category/example-applications)\n\n    * [Chatbot](/example-applications/chatbot)\n    * [Summarization](/example-applications/summarization)\n    * [More Examples](/example-applications/more_examples)\n\n  * [](/)\n  * [Example Applications](/category/example-applications)\n  * Chatbot\n\nOn this page\n\n# Chatbot\n\n![img.png](/assets/images/chatbot_img-1317ff163a3d167b5d0ee52165ea2f89.png)\n\nThis is a simple chatbot demo that uses AIMon to check responses to user\nqueries. The chatbot is built using LLamaIndex. This chatbot application\nintentionally crawls a [single webpage](http://paulgraham.com/worked.html).\nThis way we can demonstrate how AIMon\'s hallucination detector works when the\nchatbot is asked questions that are not related to the webpage, in which case\nit is likely to answer out of its own learned knowledge.\n\n## Code[â\x80\x8b](/example-applications/chatbot#code ""Direct link to Code"")\n\nThe code for the summarization app can be found in the [github\nrepository](https://github.com/aimonlabs/aimon-python-\nsdk/tree/main/examples/streamlit_apps/chatbot).\n\n## Setup[â\x80\x8b](/example-applications/chatbot#setup ""Direct link to Setup"")\n\nMake sure you have the AIMon API key which can be obtained by signing up on\nthe AIMon website.\n\n### Installation[â\x80\x8b](/example-applications/chatbot#installation ""Direct link\nto Installation"")\n\n  1. First install AIMon\'s Python SDK and get the API key as described in the [Installation](/getting-started/installing-aimon) section.\n\n  2. Clone the repository.\n    \n        git clone https://github.com/aimonlabs/aimon-python-sdk.git  \n    \n\n  3. Install the required packages from the `requirements.txt` file specified in this directory.\n    \n        cd examples/streamlit_apps/chatbot  \n    pip install -r requirements.txt  \n    \n\n### API Keys[â\x80\x8b](/example-applications/chatbot#api-keys ""Direct link to API\nKeys"")\n\nAfter signing up on the AIMon website, you can obtain the key by navigating to\n`My Account -> Keys -> Copy API Key` on the UI:\n\n![copy_api_key_ui.png](/assets/images/copy_api_key_ui-39b9d9e6ffd1f75e19f4f3c85a98f257.png)\n\nYou will need to specify AIMon and OpenAI API keys as part of their respective\nenvironment variables.\n\n    \n    \n    export OPENAI_API_KEY=YOUR_OPENAI_API_KEY  \n    export AIMON_API_KEY=YOUR_AIMON_API_KEY  \n    \n\n### Running the Chatbot[â\x80\x8b](/example-applications/chatbot#running-the-chatbot\n""Direct link to Running the Chatbot"")\n\nThe chatbot is a streamlit app. You can run it using this command:\n\n    \n    \n    python -m streamlit run aimon_chatbot_demo.py  \n    \n\nNow, you can navigate to the [UI](https://app.aimon.ai) and see the metrics\npopulated for your application as shown below:\n\n![ui_with_metrics.png](/assets/images/ui_with_metrics-7dad687a028b4a6d1cba0c8201ef729f.png)\n\n[PreviousExample Applications](/category/example-\napplications)[NextSummarization](/example-applications/summarization)\n\n  * [Code](/example-applications/chatbot#code)\n  * [Setup](/example-applications/chatbot#setup)\n    * [Installation](/example-applications/chatbot#installation)\n    * [API Keys](/example-applications/chatbot#api-keys)\n    * [Running the Chatbot](/example-applications/chatbot#running-the-chatbot)\n\nDocs\n\n  * [Tutorial](/)\n\nCommunity\n\n  * [Slack](https://join.slack.com/t/generativeair/shared_invite/zt-2m3v8oddx-qz9S2ep_xL4sYvLuOhU39Q)\n\nCopyright Â© 2024 Aimon Labs, Inc. All rights reserved\n\n', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\n\n{content}', metadata_template='{key}: {value}', metadata_seperator='\n'), Document(id_='https://docs.aimon.ai/example-applications/more_examples', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='Skip to main content\n\n[![Aimon Logo](/img/logo.png)![Aimon Logo](/img/logo.png)](/)\n\n[GitHub](https://github.com/aimonlabs/aimon-python-sdk)\n\n  * [Welcome to AIMon](/)\n  * [Introduction](/category/introduction)\n\n  * [Getting Started](/category/getting-started)\n\n  * [Concepts](/category/concepts)\n\n  * [Example Applications](/category/example-applications)\n\n    * [Chatbot](/example-applications/chatbot)\n    * [Summarization](/example-applications/summarization)\n    * [More Examples](/example-applications/more_examples)\n\n  * [](/)\n  * [Example Applications](/category/example-applications)\n  * More Examples\n\n# More Examples\n\n  * If you are a Metaflow user, you can refer to this [example Metaflow flow](https://github.com/aimonlabs/aimon-python-sdk/tree/main/examples/metaflow) that integrates with AIMon.\n\n  * Additionally, this [Github repo](https://github.com/aimonlabs/aimon-python-sdk/tree/main/examples/notebooks) has some example notebooks that you can refer to.\n\n[PreviousSummarization](/example-applications/summarization)\n\nDocs\n\n  * [Tutorial](/)\n\nCommunity\n\n  * [Slack](https://join.slack.com/t/generativeair/shared_invite/zt-2m3v8oddx-qz9S2ep_xL4sYvLuOhU39Q)\n\nCopyright Â© 2024 Aimon Labs, Inc. All rights reserved\n\n', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\n\n{content}', metadata_template='{key}: {value}', metadata_seperator='\n'), Document(id_='https://docs.aimon.ai/example-applications/summarization', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='Skip to main content\n\n[![Aimon Logo](/img/logo.png)![Aimon Logo](/img/logo.png)](/)\n\n[GitHub](https://github.com/aimonlabs/aimon-python-sdk)\n\n  * [Welcome to AIMon](/)\n  * [Introduction](/category/introduction)\n\n  * [Getting Started](/category/getting-started)\n\n  * [Concepts](/category/concepts)\n\n  * [Example Applications](/category/example-applications)\n\n    * [Chatbot](/example-applications/chatbot)\n    * [Summarization](/example-applications/summarization)\n    * [More Examples](/example-applications/more_examples)\n\n  * [](/)\n  * [Example Applications](/category/example-applications)\n  * Summarization\n\nOn this page\n\n# Summarization\n\n![img.png](/assets/images/summarization_img-89052d7ce62485d72c440fa904cd2f86.png)\n\nThis is a simple streamlit based Langchain Summarization application with an\ninline AIMon detector.\n\n## Code[â\x80\x8b](/example-applications/summarization#code ""Direct link to Code"")\n\nThe code for the summarization app can be found in the [summarization\ndirectory](https://github.com/aimonlabs/aimon-python-\nsdk/tree/main/examples/streamlit_apps/summarization).\n\n## Setup[â\x80\x8b](/example-applications/summarization#setup ""Direct link to\nSetup"")\n\nMake sure you have the AIMon API key which can be obtained by signing up on\nthe AIMon website.\n\n### Installation[â\x80\x8b](/example-applications/summarization#installation ""Direct\nlink to Installation"")\n\n  1. Clone the repository.\n    \n        git clone https://github.com/aimonlabs/aimon-python-sdk.git  \n    \n\n  2. Install the required packages from the `requirements.txt` file specified in this directory.\n    \n        cd examples/streamlit_apps/summarization  \n    pip install -r requirements.txt  \n    \n\n### API Keys[â\x80\x8b](/example-applications/summarization#api-keys ""Direct link to\nAPI Keys"")\n\nAfter signing up on the AIMon website, you can obtain the key by navigating to\n`My Account -> Keys -> Copy API Key` on the UI:\n\n![copy_api_key_ui.png](/assets/images/copy_api_key_ui-39b9d9e6ffd1f75e19f4f3c85a98f257.png)\n\nYou will need to specify AIMon and OpenAI API keys in a `secrets.toml` file\ninside the `.streamlit` directory.\n\n    \n    \n    openai_key=YOUR_OPENAI_API_KEY  \n    aimon_api_key=YOUR_AIMON_API_KEY  \n    \n\n### Running the Summarization App[â\x80\x8b](/example-\napplications/summarization#running-the-summarization-app ""Direct link to\nRunning the Summarization App"")\n\nThe summarization app is a streamlit app. You can run it using this command:\n\n    \n    \n    python -m streamlit run langchain_summarization_app.py  \n    \n\n[PreviousChatbot](/example-applications/chatbot)[NextMore Examples](/example-\napplications/more_examples)\n\n  * [Code](/example-applications/summarization#code)\n  * [Setup](/example-applications/summarization#setup)\n    * [Installation](/example-applications/summarization#installation)\n    * [API Keys](/example-applications/summarization#api-keys)\n    * [Running the Summarization App](/example-applications/summarization#running-the-summarization-app)\n\nDocs\n\n  * [Tutorial](/)\n\nCommunity\n\n  * [Slack](https://join.slack.com/t/generativeair/shared_invite/zt-2m3v8oddx-qz9S2ep_xL4sYvLuOhU39Q)\n\nCopyright Â© 2024 Aimon Labs, Inc. All rights reserved\n\n', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\n\n{content}', metadata_template='{key}: {value}', metadata_seperator='\n'), Document(id_='https://docs.aimon.ai/getting-started/installing-aimon', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='Skip to main content\n\n[![Aimon Logo](/img/logo.png)![Aimon Logo](/img/logo.png)](/)\n\n[GitHub](https://github.com/aimonlabs/aimon-python-sdk)\n\n  * [Welcome to AIMon](/)\n  * [Introduction](/category/introduction)\n\n  * [Getting Started](/category/getting-started)\n\n    * [Installing AIMon](/getting-started/installing-aimon)\n    * [Quick Start](/getting-started/quick-start)\n  * [Concepts](/category/concepts)\n\n  * [Example Applications](/category/example-applications)\n\n  * [](/)\n  * [Getting Started](/category/getting-started)\n  * Installing AIMon\n\nOn this page\n\n# Installing AIMon\n\n## API key[â\x80\x8b](/getting-started/installing-aimon#api-key ""Direct link to API\nkey"")\n\nTo use AIMon, you will need an API key. You can get an API key by signing up\non the [AIMon app](https://app.aimon.ai/?screen=signup).\n\n## Installation[â\x80\x8b](/getting-started/installing-aimon#installation ""Direct\nlink to Installation"")\n\nAIMon supports a Python and a Typescript SDK. Both SDKs are open-source and\ncan be installed via pip and npm respectively. You will need an API key to use\nthe SDKs. You can get an API key by signing up on the [AIMon\napp](https://app.aimon.ai/?screen=signup).\n\nAfter signing up on the [AIMon app](https://app.aimon.ai/?screen=signup), you\ncan obtain the key by navigating to `My Account -> Keys -> Copy API Key` on\nthe UI:\n\n![copy_api_key_ui.png](/assets/images/copy_api_key_ui-39b9d9e6ffd1f75e19f4f3c85a98f257.png)\n\n### Python SDK[â\x80\x8b](/getting-started/installing-aimon#python-sdk ""Direct link\nto Python SDK"")\n\nTo install the Python SDK, run the following command (Python 3.8+):\n\n    \n    \n    pip install -U aimon  \n    \n\n### Typescript SDK[â\x80\x8b](/getting-started/installing-aimon#typescript-sdk\n""Direct link to Typescript SDK"")\n\nTo install the Typescript SDK, run the following command:\n\n    \n    \n    npm install aimon  \n    \n\n[PreviousGetting Started](/category/getting-started)[NextQuick\nStart](/getting-started/quick-start)\n\n  * [API key](/getting-started/installing-aimon#api-key)\n  * [Installation](/getting-started/installing-aimon#installation)\n    * [Python SDK](/getting-started/installing-aimon#python-sdk)\n    * [Typescript SDK](/getting-started/installing-aimon#typescript-sdk)\n\nDocs\n\n  * [Tutorial](/)\n\nCommunity\n\n  * [Slack](https://join.slack.com/t/generativeair/shared_invite/zt-2m3v8oddx-qz9S2ep_xL4sYvLuOhU39Q)\n\nCopyright Â© 2024 Aimon Labs, Inc. All rights reserved\n\n', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\n\n{content}', metadata_template='{key}: {value}', metadata_seperator='\n'), Document(id_='https://docs.aimon.ai/getting-started/quick-start', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='Skip to main content\n\n[![Aimon Logo](/img/logo.png)![Aimon Logo](/img/logo.png)](/)\n\n[GitHub](https://github.com/aimonlabs/aimon-python-sdk)\n\n  * [Welcome to AIMon](/)\n  * [Introduction](/category/introduction)\n\n  * [Getting Started](/category/getting-started)\n\n    * [Installing AIMon](/getting-started/installing-aimon)\n    * [Quick Start](/getting-started/quick-start)\n  * [Concepts](/category/concepts)\n\n  * [Example Applications](/category/example-applications)\n\n  * [](/)\n  * [Getting Started](/category/getting-started)\n  * Quick Start\n\n# Quick Start\n\nThis guide will help you get started with AIMon. Before getting started, make\nsure you have AIMon installed. If not, follow the [installation\nguide](/getting-started/installing-aimon).\n\nIt is straightforward to use AIMon. Set the `AIMON_API_KEY` environment\nvariable with your API key. Here is an example using the `detect` decorator\nwhich is synchronous:\n\n  * Python\n  * TypeScript\n\n    \n    \n    from aimon import Detect  \n      \n    # See analyze_prod for the asynchronous version  \n    # that can be used for continuous monitoring  \n    detect = Detect(values_returned=[\'context\', \'generated_text\'], config={""hallucination"": {""detector_name"": ""default""}})  \n      \n    @detect  \n    def my_llm_app(context, query):  \n        generated_text = my_llm_model(context, query)  \n        return context, generated_text  \n      \n    \n    \n    \n    import Client from ""aimon"";  \n      \n    const aimon_client = new Client({  \n      authHeader: `Bearer API_KEY`,  \n    });  \n      \n    const detectMetrics: any = async (sourceText: any) => {  \n      // Split the source text  \n      const textSplitter = new RecursiveCharacterTextSplitter({ chunkSize: 1000 });  \n      const docs = await textSplitter.createDocuments([sourceText]);  \n      const contextDocs = docs.map((doc) => doc.pageContent);  \n      \n      // Summarize the texts  \n      const llm = new OpenAI({ temperature: 0, openAIApiKey: openaiApiKey });  \n      const chain = loadSummarizationChain(llm, { type: ""map_reduce"" });  \n      const output = await chain.invoke({  \n        input_documents: docs,  \n      });  \n      \n      const hall_config = {  \n          hallucination: {  \n          detector_name: ""default""  \n        }  \n      };  \n      \n      // Detect quality of the generated output using AIMon  \n      const detectParams: Client.InferenceDetectParams.Body[] = [  \n        {  \n          context: contextDocs,  \n          generated_text: output.text,  \n          config: hall_config  \n        },  \n      ];  \n      \n      // Call the API  \n      const aimonResponse: Client.InferenceDetectResponse =  \n        await aimon_client.inference.detect(detectParams);  \n    };  \n    \n\n[PreviousInstalling AIMon](/getting-started/installing-\naimon)[NextConcepts](/category/concepts)\n\nDocs\n\n  * [Tutorial](/)\n\nCommunity\n\n  * [Slack](https://join.slack.com/t/generativeair/shared_invite/zt-2m3v8oddx-qz9S2ep_xL4sYvLuOhU39Q)\n\nCopyright Â© 2024 Aimon Labs, Inc. All rights reserved\n\n', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\n\n{content}', metadata_template='{key}: {value}', metadata_seperator='\n'), Document(id_='https://docs.aimon.ai/introduction/whats-aimon', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='Skip to main content\n\n[![Aimon Logo](/img/logo.png)![Aimon Logo](/img/logo.png)](/)\n\n[GitHub](https://github.com/aimonlabs/aimon-python-sdk)\n\n  * [Welcome to AIMon](/)\n  * [Introduction](/category/introduction)\n\n    * [Why AIMon](/introduction/why-aimon)\n    * [What is AIMon](/introduction/whats-aimon)\n  * [Getting Started](/category/getting-started)\n\n  * [Concepts](/category/concepts)\n\n  * [Example Applications](/category/example-applications)\n\n  * [](/)\n  * [Introduction](/category/introduction)\n  * What is AIMon\n\nOn this page\n\n# What is AIMon\n\nAIMon helps developers build robust and reliable generative AI applications.\nAIMon provides a suite of detectors that help detect issues like\nhallucinations, adherence of the generated text to the provided LLM\ninstructions, conciseness and completeness of the generated text, and more.\nAIMon is agnostic to the underlying generative model and can be used both in\noffline evaluations, continuous monitoring and some detectors can be used as a\nguardrail in production systems.\n\n## What exactly does AIMon provide?[â\x80\x8b](/introduction/whats-aimon#what-\nexactly-does-aimon-provide ""Direct link to What exactly does AIMon provide?"")\n\nAIMon\'s platform includes detectors, a user-friendly SDK and a UI that aids in\nmonitoring of offline evaluation and production systems. Here is a quick\noverview of the detectors:\n\n  * **Hallucination Detector** : Given a context, query and a generated text, it detects if the output of a generative model was not generated from the provided context. This detector operates at low latency and has accuracy comparable to LLM based judging approaches.\n  * **Conciseness Detector** : Given a context, query and a generated text, it detects if the output of a generative model is concise and does not contain unnecessary information.\n  * **Completeness Detector** : Given a context, query and a generated text, it detects if the output of a generative model is complete and does not miss any important information.\n  * **Adherence Detector** : Given a context, query and a generated text, it detects if the output of a generative model adheres to the provided instructions.\n  * **Toxicity Detector** : Given a generated text, it detects if the text contains toxic content. We have a taxonomy of toxic content that includes hate speech, obscenity, threatening language, profanity, etc.\n\n### Reference Architecture of a Generative AI Application using\nAIMon[â\x80\x8b](/introduction/whats-aimon#reference-architecture-of-a-generative-\nai-application-using-aimon ""Direct link to Reference Architecture of a\nGenerative AI Application using AIMon"")\n\nThe figure below shows a typical generative AI application architecture that\nuses AIMon\'s hallucination detector.\n\n![aimon_llm_architecture_halldet_example](/assets/images/aimon_llm_architecture_halldet_example-c5e95acf179a70c405ebd531eaafa81b.png)\n\n## What\'s next?[â\x80\x8b](/introduction/whats-aimon#whats-next ""Direct link to\nWhat\'s next?"")\n\n  * Go to the [Quickstart](/getting-started/quick-start) guide to get started with AIMon.\n  * Read about the different [concepts](/category/detectors) of the AIMon Platform.\n  * Check out example applications that use AIMon\'s detectors:\n    * [Chatbot with an inline AIMon detector](/example-applications/chatbot)\n    * [Summarization with an inline AIMon detector](/example-applications/summarization)\n    * [Summarization with continuous monitoring](https://github.com/aimonlabs/aimon-python-sdk/blob/main/examples/notebooks/aimon_continuous_mon_decorators_langchain_summarization.ipynb)\n    * [Summarization with evaluation](https://github.com/aimonlabs/aimon-python-sdk/blob/main/examples/notebooks/aimon_evaluation_decorators_langchain_summarization.ipynb)\n\n[PreviousWhy AIMon](/introduction/why-aimon)[NextGetting\nStarted](/category/getting-started)\n\n  * [What exactly does AIMon provide?](/introduction/whats-aimon#what-exactly-does-aimon-provide)\n    * [Reference Architecture of a Generative AI Application using AIMon](/introduction/whats-aimon#reference-architecture-of-a-generative-ai-application-using-aimon)\n  * [What\'s next?](/introduction/whats-aimon#whats-next)\n\nDocs\n\n  * [Tutorial](/)\n\nCommunity\n\n  * [Slack](https://join.slack.com/t/generativeair/shared_invite/zt-2m3v8oddx-qz9S2ep_xL4sYvLuOhU39Q)\n\nCopyright Â© 2024 Aimon Labs, Inc. All rights reserved\n\n', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\n\n{content}', metadata_template='{key}: {value}', metadata_seperator='\n'), Document(id_='https://docs.aimon.ai/introduction/why-aimon', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='Skip to main content\n\n[![Aimon Logo](/img/logo.png)![Aimon Logo](/img/logo.png)](/)\n\n[GitHub](https://github.com/aimonlabs/aimon-python-sdk)\n\n  * [Welcome to AIMon](/)\n  * [Introduction](/category/introduction)\n\n    * [Why AIMon](/introduction/why-aimon)\n    * [What is AIMon](/introduction/whats-aimon)\n  * [Getting Started](/category/getting-started)\n\n  * [Concepts](/category/concepts)\n\n  * [Example Applications](/category/example-applications)\n\n  * [](/)\n  * [Introduction](/category/introduction)\n  * Why AIMon\n\n# Why AIMon\n\n  1. With the advent of Generative AI, engineers are able to build AI applications easily without needing deep ML expertise. They can build applications like chatbots, summarizers, and more, with just a few lines of code.\n\n![engineers-ai-apps](/assets/images/engineers-ai-\napps-307325465cf994e8dd4dfc60d8a6f996.png)\n![arrow](/assets/images/arrow-54b766244f5e96914e2ceff3943df54d.png) ![chatbot-\nimg](/assets/images/chatbot-img-d5f4a9cb11c8151b2d3ac83077db66fe.png)\n\n  2. However, these applications can sometimes generate incorrect, incomplete, or toxic content. This can lead to a poor user experience,\n\n![life-on-mars-chatbot](/assets/images/life-on-mars-\nchatbot-660db53d5afdc19b23f89e461bf2a914.png)\n\n  3. AIMon provides a suite of detectors that help detect issues like hallucinations, adherence of the generated text to the provided LLM instructions, conciseness and completeness of the generated text, and more.\n\n![aimon-helps](/assets/images/aimon-\nhelps-78002ae795f6798f7a7e62a3ce405d1b.png)\n\n[PreviousIntroduction](/category/introduction)[NextWhat is\nAIMon](/introduction/whats-aimon)\n\nDocs\n\n  * [Tutorial](/)\n\nCommunity\n\n  * [Slack](https://join.slack.com/t/generativeair/shared_invite/zt-2m3v8oddx-qz9S2ep_xL4sYvLuOhU39Q)\n\nCopyright Â© 2024 Aimon Labs, Inc. All rights reserved\n\n', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\n\n{content}', metadata_template='{key}: {value}', metadata_seperator='\n'), Document(id_='https://docs.aimon.ai/', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='Skip to main content\n\n[![Aimon Logo](/img/logo.png)![Aimon Logo](/img/logo.png)](/)\n\n[GitHub](https://github.com/aimonlabs/aimon-python-sdk)\n\n  * [Welcome to AIMon](/)\n  * [Introduction](/category/introduction)\n\n  * [Getting Started](/category/getting-started)\n\n  * [Concepts](/category/concepts)\n\n  * [Example Applications](/category/example-applications)\n\n  * [](/)\n  * Welcome to AIMon\n\nOn this page\n\n# Welcome to AIMon\n\nAIMon helps developers build robust and reliable generative AI applications.\n\n### Motivation[â\x80\x8b](/#motivation ""Direct link to Motivation"")\n\n  * [What is AIMon](/introduction/whats-aimon)\n\n  * [Why AIMon](/introduction/why-aimon)\n\n### Getting Started[â\x80\x8b](/#getting-started ""Direct link to Getting Started"")\n\n  * [Installation](/getting-started/installing-aimon)\n  * [Quickstart](/getting-started/quick-start)\n\n### Concepts[â\x80\x8b](/#concepts ""Direct link to Concepts"")\n\n  * [Detectors](/category/detectors)\n  * [Evaluation and Continuous Monitoring](/concepts/evaluation_and_monitoring)\n\n### Example Applications[â\x80\x8b](/#example-applications ""Direct link to Example\nApplications"")\n\n#### Chatbot[â\x80\x8b](/#chatbot ""Direct link to Chatbot"")\n\n  * [A simple chatbot application with an inline AIMon detector.](/example-applications/chatbot)\n\n#### Summarization with an inline AIMon detector[â\x80\x8b](/#summarization-with-an-\ninline-aimon-detector ""Direct link to Summarization with an inline AIMon\ndetector"")\n\n  * [A simple summarization application with an inline AIMon detector.](/example-applications/summarization)\n\n#### Summarization with continuous monitoring[â\x80\x8b](/#summarization-with-\ncontinuous-monitoring ""Direct link to Summarization with continuous\nmonitoring"")\n\n  * [Notebook](https://github.com/aimonlabs/aimon-python-sdk/blob/main/examples/notebooks/aimon_continuous_mon_decorators_langchain_summarization.ipynb)\n\n#### Summarization with evaluation[â\x80\x8b](/#summarization-with-evaluation\n""Direct link to Summarization with evaluation"")\n\n  * [Notebook](https://github.com/aimonlabs/aimon-python-sdk/blob/main/examples/notebooks/aimon_evaluation_decorators_langchain_summarization.ipynb)\n\n[NextIntroduction](/category/introduction)\n\n  * [Motivation](/#motivation)\n  * [Getting Started](/#getting-started)\n  * [Concepts](/#concepts)\n  * [Example Applications](/#example-applications)\n\nDocs\n\n  * [Tutorial](/)\n\nCommunity\n\n  * [Slack](https://join.slack.com/t/generativeair/shared_invite/zt-2m3v8oddx-qz9S2ep_xL4sYvLuOhU39Q)\n\nCopyright Â© 2024 Aimon Labs, Inc. All rights reserved\n\n', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\n\n{content}', metadata_template='{key}: {value}', metadata_seperator='\n')]]",How would AIMon respond to a toxic response from LLMs?,Please answer from a humanitarian perspective and let the user know about the ethical considerations that take place in this process.,Convert passive voice to active voice and make sure the response is under 150 words.
